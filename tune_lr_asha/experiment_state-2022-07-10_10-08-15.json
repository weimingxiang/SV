{
  "checkpoints": [
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"250b04f4\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.013895369498714e-06,\n    \"weight_decay\": 0.009334692901793855,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.013895369498714e-06,\n    \"weight_decay\": 0.009334692901793855,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"3___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.0139e-06,weight_decay=0.0093347\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.47109079360961914,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.4874153733253479,\n    \"validation_2_f1\": 0.0,\n    \"validation_mean\": 0.32224008440971375,\n    \"time_this_iter_s\": 2436.0184683799744,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"250b04f4\",\n    \"experiment_id\": \"2cc0f0a73b494d439f6b9d8c50ee99bb\",\n    \"date\": \"2022-07-11_07-45-29\",\n    \"timestamp\": 1657496729,\n    \"time_total_s\": 2436.0184683799744,\n    \"pid\": 11321,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 1.013895369498714e-06,\n      \"weight_decay\": 0.009334692901793855,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 2436.0184683799744,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"3___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.0139e-06,weight_decay=0.0093347\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657496729.822426,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.47109079360961914,\n      \"min\": 0.47109079360961914,\n      \"avg\": 0.47109079360961914,\n      \"last\": 0.47109079360961914,\n      \"last-5-avg\": 0.47109079360961914,\n      \"last-10-avg\": 0.47109079360961914\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.4874153733253479,\n      \"min\": 0.4874153733253479,\n      \"avg\": 0.4874153733253479,\n      \"last\": 0.4874153733253479,\n      \"last-5-avg\": 0.4874153733253479,\n      \"last-10-avg\": 0.4874153733253479\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_mean\": {\n      \"max\": 0.32224008440971375,\n      \"min\": 0.32224008440971375,\n      \"avg\": 0.32224008440971375,\n      \"last\": 0.32224008440971375,\n      \"last-5-avg\": 0.32224008440971375,\n      \"last-10-avg\": 0.32224008440971375\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2436.0184683799744,\n      \"min\": 2436.0184683799744,\n      \"avg\": 2436.0184683799744,\n      \"last\": 2436.0184683799744,\n      \"last-5-avg\": 2436.0184683799744,\n      \"last-10-avg\": 2436.0184683799744\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 2436.0184683799744,\n      \"min\": 2436.0184683799744,\n      \"avg\": 2436.0184683799744,\n      \"last\": 2436.0184683799744,\n      \"last-5-avg\": 2436.0184683799744,\n      \"last-10-avg\": 2436.0184683799744\n    },\n    \"time_since_restore\": {\n      \"max\": 2436.0184683799744,\n      \"min\": 2436.0184683799744,\n      \"avg\": 2436.0184683799744,\n      \"last\": 2436.0184683799744,\n      \"last-5-avg\": 2436.0184683799744,\n      \"last-10-avg\": 2436.0184683799744\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fde265a00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fde265a00000000612e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294470000000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294470000000000000000612e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fdf31d040000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fdf31d040000000612e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294470000000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294470000000000000000612e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd49f94e0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd49f94e0000000612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a3080974b00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a3080974b00000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a3080974b00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a3080974b00000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a3080974b00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a3080974b00000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657349933.7987325,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_250b04f4_3___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.0139e-06,weight_decay=0.0093347_2022-07-08_20-11-49\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_250b04f4_3___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.0139e-06,weight_decay=0.0093347_2022-07-08_20-11-49/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1765, in get\\n    raise value\\nray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\\n\\tclass_name: ImplicitFunc\\n\\tactor_id: 94abf17711ff8973818e7afb01000000\\n\\tpid: 63503\\n\\tnamespace: b7dc3d4e-627b-4541-a953-e8e501c3c70e\\n\\tip: 192.168.249.74\\nThe actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR_EXIT\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"24f3f020\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.8343467758600695e-06,\n    \"weight_decay\": 0.002179910296938443,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.8343467758600695e-06,\n    \"weight_decay\": 0.002179910296938443,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"2___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.8343e-06,weight_decay=0.0021799\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.47088149189949036,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.487765371799469,\n    \"validation_2_f1\": 0.0,\n    \"validation_mean\": 0.3225460946559906,\n    \"time_this_iter_s\": 2420.716032743454,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"24f3f020\",\n    \"experiment_id\": \"09876252994a4100b4fed3bbd5658fd2\",\n    \"date\": \"2022-07-11_08-26-06\",\n    \"timestamp\": 1657499166,\n    \"time_total_s\": 2420.716032743454,\n    \"pid\": 11320,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 1.8343467758600695e-06,\n      \"weight_decay\": 0.002179910296938443,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 2420.716032743454,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"2___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.8343e-06,weight_decay=0.0021799\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657499166.4697063,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.47088149189949036,\n      \"min\": 0.35847583413124084,\n      \"avg\": 0.47088149189949036,\n      \"last\": 0.47088149189949036,\n      \"last-5-avg\": 0.4013611912727356,\n      \"last-10-avg\": 0.3885276556015015\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.8865683674812317,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.6547798871994018,\n      \"last-10-avg\": 0.7526684463024139\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.8296346664428711,\n      \"min\": 0.487765371799469,\n      \"avg\": 0.487765371799469,\n      \"last\": 0.487765371799469,\n      \"last-5-avg\": 0.696799898147583,\n      \"last-10-avg\": 0.7283902764320374\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.8300384879112244,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.6119373440742493,\n      \"last-10-avg\": 0.6883790850639343\n    },\n    \"validation_mean\": {\n      \"max\": 0.84194016456604,\n      \"min\": 0.3225460946559906,\n      \"avg\": 0.3225460946559906,\n      \"last\": 0.3225460946559906,\n      \"last-5-avg\": 0.6864662230014801,\n      \"last-10-avg\": 0.740693137049675\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2812.2815260887146,\n      \"min\": 2420.716032743454,\n      \"avg\": 2420.716032743454,\n      \"last\": 2420.716032743454,\n      \"last-5-avg\": 2559.7985088348387,\n      \"last-10-avg\": 2602.672433233261\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 1.0,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 29,\n      \"min\": 1,\n      \"avg\": 1.0,\n      \"last\": 1,\n      \"last-5-avg\": 22.2,\n      \"last-10-avg\": 22.6\n    },\n    \"time_total_s\": {\n      \"max\": 74661.43902373314,\n      \"min\": 2420.716032743454,\n      \"avg\": 2420.716032743454,\n      \"last\": 2420.716032743454,\n      \"last-5-avg\": 57156.64023008347,\n      \"last-10-avg\": 58017.18895478248\n    },\n    \"time_since_restore\": {\n      \"max\": 74661.43902373314,\n      \"min\": 2420.716032743454,\n      \"avg\": 2420.716032743454,\n      \"last\": 2420.716032743454,\n      \"last-5-avg\": 57156.64023008347,\n      \"last-10-avg\": 58017.18895478248\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 29,\n      \"min\": 1,\n      \"avg\": 1.0,\n      \"last\": 1,\n      \"last-5-avg\": 22.2,\n      \"last-10-avg\": 22.6\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd6f144a0000000473fd8b37880000000473fd94f8740000000473fd95851c0000000473fde22ec20000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd7630420000000473fd90b5c80000000473fd846f3e0000000473fd78328a0000000473fd8005fa0000000473fd6f144a0000000473fd8b37880000000473fd94f8740000000473fd95851c0000000473fde22ec20000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fec3da140000000473feb142dc0000000473fe847eb60000000473fe92a0e60000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473febe720a0000000473fea776fa0000000473fea490080000000473febe3b3e0000000473feb8b8c00000000473fec3da140000000473feb142dc0000000473fe847eb60000000473fe92a0e60000000470000000000000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fea8c5e00000000473fe6e6a7c0000000473fe7aa7600000000473fe6c3aaa0000000473fdf378c40000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe9f85160000000473fe5d90560000000473fe7fc4900000000473fe9650660000000473fe86628a0000000473fea8c5e00000000473fe6e6a7c0000000473fe7aa7600000000473fe6c3aaa0000000473fdf378c40000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe9a3dfa0000000473fe5c78a00000000473fea8face0000000473fe7eddda0000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe9c8c7c0000000473fe2e8aae0000000473fe9ff9700000000473fea53e800000000473fe95a1e00000000473fe9a3dfa0000000473fe5c78a00000000473fea8face0000000473fe7eddda0000000470000000000000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473feaf12c80000000473fe810c3e0000000473fe8af5400000000473fe7d21780000000473fd4a49860000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473feaa2d520000000473fe6b62ec0000000473fe979c320000000473fea9aaf60000000473fe9c27680000000473feaf12c80000000473fe810c3e0000000473fe8af5400000000473fe7d21780000000473fd4a49860000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a58c1543a000004740a39882bf6000004740a401d8b19000004740a3ee1cde5800004740a2e96e9bd80000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a40ec5db0000004740a428d6c8f800004740a451e6724000004740a4de3275e800004740a5efc120d000004740a58c1543a000004740a39882bf6000004740a401d8b19000004740a3ee1cde5800004740a2e96e9bd80000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b01652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740f05e1343c380004740f0fad759be80004740f19ae61f4b00004740f23a57063dc0004740a2e96e9bd80000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740ea2eda262e00004740eb716792bd80004740ecb685f9e180004740ee0469214000004740ef6365334d00004740f05e1343c380004740f0fad759be80004740f19ae61f4b00004740f23a57063dc0004740a2e96e9bd80000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740f05e1343c380004740f0fad759be80004740f19ae61f4b00004740f23a57063dc0004740a2e96e9bd80000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740ea2eda262e00004740eb716792bd80004740ecb685f9e180004740ee0469214000004740ef6365334d00004740f05e1343c380004740f0fad759be80004740f19ae61f4b00004740f23a57063dc0004740a2e96e9bd80000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b01652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657282309.541766,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_24f3f020_2___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.8343e-06,weight_decay=0.0021799_2022-07-08_20-11-49\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_24f3f020_2___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.8343e-06,weight_decay=0.0021799_2022-07-08_20-11-49/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11321, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11321, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 575, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 321, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 401, in ff_chunk\\n    ffn_output = self.activation(ffn_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/activations.py\\\", line 34, in forward\\n    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\\nRuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 15.78 GiB total capacity; 14.10 GiB already allocated; 71.50 MiB free; 14.28 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"20576632\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 2.2677254422654865e-07,\n    \"weight_decay\": 0.006754057226249745,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 2.2677254422654865e-07,\n    \"weight_decay\": 0.006754057226249745,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"1___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.2677e-07,weight_decay=0.0067541\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.4546703100204468,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.0,\n    \"validation_2_f1\": 0.5019769668579102,\n    \"validation_mean\": 0.3350929617881775,\n    \"time_this_iter_s\": 2415.0128824710846,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"20576632\",\n    \"experiment_id\": \"2cc0f0a73b494d439f6b9d8c50ee99bb\",\n    \"date\": \"2022-07-11_07-04-53\",\n    \"timestamp\": 1657494293,\n    \"time_total_s\": 75386.09464716911,\n    \"pid\": 11321,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 2.2677254422654865e-07,\n      \"weight_decay\": 0.006754057226249745,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 75386.09464716911,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"experiment_tag\": \"1___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.2677e-07,weight_decay=0.0067541\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657494293.4915316,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.46927350759506226,\n      \"min\": 0.42689356207847595,\n      \"avg\": 0.4549837052822112,\n      \"last\": 0.4546703100204468,\n      \"last-5-avg\": 0.4370107173919678,\n      \"last-10-avg\": 0.43663200438022615\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.510087788105011,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.5019769668579102,\n      \"min\": 0.0,\n      \"avg\": 0.5019769668579102,\n      \"last\": 0.5019769668579102,\n      \"last-5-avg\": 0.5019769668579102,\n      \"last-10-avg\": 0.5019769668579102\n    },\n    \"validation_mean\": {\n      \"max\": 0.3423609435558319,\n      \"min\": 0.3350929617881775,\n      \"avg\": 0.3350929617881775,\n      \"last\": 0.3350929617881775,\n      \"last-5-avg\": 0.3350929617881775,\n      \"last-10-avg\": 0.3350929617881775\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3167.646394252777,\n      \"min\": 2399.181202173233,\n      \"avg\": 2512.8698215723034,\n      \"last\": 2415.0128824710846,\n      \"last-5-avg\": 2417.787618780136,\n      \"last-10-avg\": 2421.785351371765\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.03333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 75386.09464716911,\n      \"min\": 2426.9280412197113,\n      \"avg\": 40060.12549970943,\n      \"last\": 75386.09464716911,\n      \"last-5-avg\": 70553.65832715035,\n      \"last-10-avg\": 64499.46413378716\n    },\n    \"time_since_restore\": {\n      \"max\": 75386.09464716911,\n      \"min\": 2426.9280412197113,\n      \"avg\": 40060.12549970943,\n      \"last\": 75386.09464716911,\n      \"last-5-avg\": 70553.65832715035,\n      \"last-10-avg\": 64499.46413378716\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fdb523960000000473fdb800a80000000473fdc8a6d40000000473fdb61e860000000473fdd195180000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fdbc9c580000000473fdbecf100000000473fdc3d8020000000473fdc0afd60000000473fdb9aaaa0000000473fdb523960000000473fdb800a80000000473fdc8a6d40000000473fdb61e860000000473fdd195180000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a2ed73490000004740a2e1b921b000004740a2e37e690000004740a2e12ee1a000004740a2de0698880000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a2f83e8d7000004740a2ece3a7a800004740a2f4a2305000004740a2ef8b7fb000004740a2f884ccd000004740a2ed73490000004740a2e1b921b000004740a2e37e690000004740a2e12ee1a000004740a2de0698880000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740f00b7e1b8600004740f0a28be49380004740f139a7d7db80004740f1d0b14ee880004740f267a183acc000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740ea2b8ba03480004740eb5a59daaf00004740ec89a3fdb400004740edb89cb5af00004740eee825027c00004740f00b7e1b8600004740f0a28be49380004740f139a7d7db80004740f1d0b14ee880004740f267a183acc000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740f00b7e1b8600004740f0a28be49380004740f139a7d7db80004740f1d0b14ee880004740f267a183acc000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740ea2b8ba03480004740eb5a59daaf00004740ec89a3fdb400004740edb89cb5af00004740eee825027c00004740f00b7e1b8600004740f0a28be49380004740f139a7d7db80004740f1d0b14ee880004740f267a183acc000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657282301.8731766,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_20576632_1___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.2677e-07,weight_decay=0.0067541_2022-07-08_20-11-41\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_20576632_1___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.2677e-07,weight_decay=0.0067541_2022-07-08_20-11-41/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1765, in get\\n    raise value\\nray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\\n\\tclass_name: ImplicitFunc\\n\\tactor_id: c8b2d3817de6bed6f5db93ef01000000\\n\\tpid: 63487\\n\\tnamespace: b7dc3d4e-627b-4541-a953-e8e501c3c70e\\n\\tip: 192.168.249.74\\nThe actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR_EXIT\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 2,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"619e954e\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 5.217893466600545e-07,\n    \"weight_decay\": 0.00777584464470708,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 5.217893466600545e-07,\n    \"weight_decay\": 0.00777584464470708,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"4___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=5.2179e-07,weight_decay=0.0077758\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.4506742060184479,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.5311965346336365,\n    \"validation_2_f1\": 0.4833764135837555,\n    \"validation_mean\": 0.4281233251094818,\n    \"time_this_iter_s\": 2506.6739745140076,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"619e954e\",\n    \"experiment_id\": \"09876252994a4100b4fed3bbd5658fd2\",\n    \"date\": \"2022-07-12_04-54-33\",\n    \"timestamp\": 1657572873,\n    \"time_total_s\": 73707.26650834084,\n    \"pid\": 11320,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 5.217893466600545e-07,\n      \"weight_decay\": 0.00777584464470708,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 73707.26650834084,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"experiment_tag\": \"4___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=5.2179e-07,weight_decay=0.0077758\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657572873.9445224,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.47195303440093994,\n      \"min\": 0.4119834899902344,\n      \"avg\": 0.4449638038873672,\n      \"last\": 0.4506742060184479,\n      \"last-5-avg\": 0.4324562311172485,\n      \"last-10-avg\": 0.4260110408067703\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.06328843533992767,\n      \"min\": 0.0,\n      \"avg\": 0.0029460293745311597,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0028861035825684667,\n      \"last-10-avg\": 0.00883808812359348\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.7460684180259705,\n      \"min\": 0.0,\n      \"avg\": 0.3935219476077085,\n      \"last\": 0.5311965346336365,\n      \"last-5-avg\": 0.5609212875366211,\n      \"last-10-avg\": 0.5949211180210113\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.877356231212616,\n      \"min\": 0.3761094808578491,\n      \"avg\": 0.6275786628325778,\n      \"last\": 0.4833764135837555,\n      \"last-5-avg\": 0.631966370344162,\n      \"last-10-avg\": 0.6944386035203933\n    },\n    \"validation_mean\": {\n      \"max\": 0.5963583588600159,\n      \"min\": 0.3350929617881775,\n      \"avg\": 0.4559916327397028,\n      \"last\": 0.4281233251094818,\n      \"last-5-avg\": 0.48730777502059935,\n      \"last-10-avg\": 0.5257822573184967\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2688.5190868377686,\n      \"min\": 2409.0497357845306,\n      \"avg\": 2456.908883611361,\n      \"last\": 2506.6739745140076,\n      \"last-5-avg\": 2520.705794429779,\n      \"last-10-avg\": 2531.845523190498\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.03333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 73707.26650834084,\n      \"min\": 2419.104125022888,\n      \"avg\": 37679.42258053621,\n      \"last\": 73707.26650834084,\n      \"last-5-avg\": 68692.07915563583,\n      \"last-10-avg\": 62288.520645666125\n    },\n    \"time_since_restore\": {\n      \"max\": 73707.26650834084,\n      \"min\": 2419.104125022888,\n      \"avg\": 37679.42258053621,\n      \"last\": 73707.26650834084,\n      \"last-5-avg\": 68692.07915563583,\n      \"last-10-avg\": 62288.520645666125\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fdaaba3a0000000473fda854ee0000000473fdd459660000000473fdb146f00000000473fdcd7d8a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fdab5af00000000473fda6ff140000000473fdaf84260000000473fdb6c8e40000000473fdab864c0000000473fdaaba3a0000000473fda854ee0000000473fdd459660000000473fdb146f00000000473fdcd7d8a0000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f55c49780000000473f89ee0180000000470000000000000000473f3ce55c80000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000473f85d5ebc0000000470000000000000000473fb033abc0000000473f55c49780000000473f89ee0180000000470000000000000000473f3ce55c80000000470000000000000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe269cf60000000473fe3499400000000473fe096ce40000000473fe2759480000000473fe0ff8fe0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe3bdca40000000473fe47a3300000000473fe6516fa0000000473fe1e644a0000000473fe430e8a0000000473fe269cf60000000473fe3499400000000473fe096ce40000000473fe2759480000000473fe0ff8fe0000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe84f4f00000000473fea12e300000000473fd8122d80000000473fe73a3d20000000473fdeefa3a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe9bf8b80000000473fea818280000000473fe67063e0000000473fe67c2840000000473fe7ed7740000000473fe84f4f00000000473fea12e300000000473fd8122d80000000473fe73a3d20000000473fdeefa3a0000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe0da6a60000000473fe20a6160000000473fd98f1220000000473fe0989be0000000473fdb665f60000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe25dbc40000000473fe3155e20000000473fe2962420000000473fe00a5740000000473fe2345f00000000473fe0da6a60000000473fe20a6160000000473fd98f1220000000473fe0989be0000000473fdb665f60000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a3e5dcf48000004740a3eec01c7800004740a3838edd9800004740a38989d3b000004740a3955913300000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a315928e7000004740a34c4b9f5000004740a34d88918000004740a4a569b9b800004740a50109c5c000004740a3e5dcf48000004740a3eec01c7800004740a3838edd9800004740a38989d3b000004740a3955913300000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740ef1455692d80004740f029a0b57a80004740f0c5bd2c6740004740f162097b04c0004740f1feb4439e4000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e8d1f31ee100004740ea06b7d8d600004740eb3b9061ee00004740ec85e6fd8980004740edd5f799e580004740ef1455692d80004740f029a0b57a80004740f0c5bd2c6740004740f162097b04c0004740f1feb4439e4000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740ef1455692d80004740f029a0b57a80004740f0c5bd2c6740004740f162097b04c0004740f1feb4439e4000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e8d1f31ee100004740ea06b7d8d600004740eb3b9061ee00004740ec85e6fd8980004740edd5f799e580004740ef1455692d80004740f029a0b57a80004740f0c5bd2c6740004740f162097b04c0004740f1feb4439e4000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657499166.659991,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_619e954e_4___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=5.2179e-07,weight_decay=0.0077758_2022-07-11_07-45-42\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"0df3afd2\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 3.527204602413617e-07,\n    \"weight_decay\": 0.0032998352223865147,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 3.527204602413617e-07,\n    \"weight_decay\": 0.0032998352223865147,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"5___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.5272e-07,weight_decay=0.0032998\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.43743985891342163,\n    \"validation_0_f1\": 0.02944141998887062,\n    \"validation_1_f1\": 0.5687097907066345,\n    \"validation_2_f1\": 0.7023653984069824,\n    \"validation_mean\": 0.5016448497772217,\n    \"time_this_iter_s\": 2758.5412995815277,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"0df3afd2\",\n    \"experiment_id\": \"30e84f779eea4ab5b5d14b098d41d685\",\n    \"date\": \"2022-07-13_02-31-54\",\n    \"timestamp\": 1657650714,\n    \"time_total_s\": 75297.83004760742,\n    \"pid\": 11331,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 3.527204602413617e-07,\n      \"weight_decay\": 0.0032998352223865147,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 75297.83004760742,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"experiment_tag\": \"5___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.5272e-07,weight_decay=0.0032998\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657650714.745527,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.47192421555519104,\n      \"min\": 0.40915754437446594,\n      \"avg\": 0.43886068065961203,\n      \"last\": 0.43743985891342163,\n      \"last-5-avg\": 0.4207147479057312,\n      \"last-10-avg\": 0.4206258416175842\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.3781645596027374,\n      \"min\": 0.0,\n      \"avg\": 0.018855048047650296,\n      \"last\": 0.02944141998887062,\n      \"last-5-avg\": 0.10048438832163811,\n      \"last-10-avg\": 0.0563451859401539\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.6282253265380859,\n      \"min\": 0.0,\n      \"avg\": 0.46982814990527305,\n      \"last\": 0.5687097907066345,\n      \"last-5-avg\": 0.5988521933555603,\n      \"last-10-avg\": 0.5928559899330139\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.8752484917640686,\n      \"min\": 0.5019769668579102,\n      \"avg\": 0.7039835333824156,\n      \"last\": 0.7023653984069824,\n      \"last-5-avg\": 0.7957129001617431,\n      \"last-10-avg\": 0.801203453540802\n    },\n    \"validation_mean\": {\n      \"max\": 0.6154846549034119,\n      \"min\": 0.3350929617881775,\n      \"avg\": 0.4904954959948857,\n      \"last\": 0.5016448497772217,\n      \"last-5-avg\": 0.5619462847709655,\n      \"last-10-avg\": 0.5552597284317017\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2758.5412995815277,\n      \"min\": 2431.900208234787,\n      \"avg\": 2509.92766825358,\n      \"last\": 2758.5412995815277,\n      \"last-5-avg\": 2590.6506423950195,\n      \"last-10-avg\": 2524.270641994476\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.03333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 75297.83004760742,\n      \"min\": 2503.7849996089935,\n      \"avg\": 38731.74592356682,\n      \"last\": 75297.83004760742,\n      \"last-5-avg\": 69928.14154849053,\n      \"last-10-avg\": 63686.113322377205\n    },\n    \"time_since_restore\": {\n      \"max\": 75297.83004760742,\n      \"min\": 2503.7849996089935,\n      \"avg\": 38731.74592356682,\n      \"last\": 75297.83004760742,\n      \"last-5-avg\": 69928.14154849053,\n      \"last-10-avg\": 63686.113322377205\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fda2fa320000000473fda72d460000000473fdb656c80000000473fda9a0c00000000473fdbff03c0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fdb147fc0000000473fda78d1c0000000473fdb04ee40000000473fdb55aaa0000000473fdaaa7860000000473fda2fa320000000473fda72d460000000473fdb656c80000000473fda9a0c00000000473fdbff03c0000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fa22b1f60000000473f97e27840000000473fd833d920000000473fa26f5c40000000473f9e25e440000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f692f1b80000000473f61f90920000000473f88aa0180000000473f9d894fc0000000473f8e7696c0000000473fa22b1f60000000473f97e27840000000473fd833d920000000473fa26f5c40000000473f9e25e440000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe388ee20000000473fe322a680000000473fe41a6c00000000473fe2d81ce0000000473fe232dee0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe2784c80000000473fe3086980000000473fe2d8b320000000473fe2baa5a0000000473fe2d1b820000000473fe388ee20000000473fe322a680000000473fe41a6c00000000473fe2d81ce0000000473fe232dee0000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fec020920000000473fea6ac900000000473fe93da700000000473fe92c2660000000473fe679c700000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe874b840000000473fea9e2ac0000000473fea723680000000473fea138380000000473fe97992c0000000473fec020920000000473fea6ac900000000473fe93da700000000473fe92c2660000000473fe679c700000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe2d9d400000000473fe1ecec80000000473fe3b20ce0000000473fe1630b00000000473fe00d7980000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe0eab600000000473fe1f1f000000000473fe1ce36c0000000473fe1af8120000000473fe16b30c0000000473fe2d9d400000000473fe1ecec80000000473fe3b20ce0000000473fe1630b00000000473fe00d7980000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a307a83cf000004740a2ffcce81800004740a44d24fe7000004740a550d25c5000004740a58d1525380000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a36a07ade800004740a32394534000004740a3333f097800004740a3255b8ce000004740a31cb1736000004740a307a83cf000004740a2ffcce81800004740a44d24fe7000004740a550d25c5000004740a58d1525380000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740efa18cf93f00004740f068c4e3e040004740f10b2e0bd3c0004740f1b5b49eb640004740f2621d47e00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e9a7846fa080004740ead9bdb4d480004740ec0cf1a56c00004740ed3f475e3a00004740ee7112757000004740efa18cf93f00004740f068c4e3e040004740f10b2e0bd3c0004740f1b5b49eb640004740f2621d47e00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740efa18cf93f00004740f068c4e3e040004740f10b2e0bd3c0004740f1b5b49eb640004740f2621d47e00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e9a7846fa080004740ead9bdb4d480004740ec0cf1a56c00004740ed3f475e3a00004740ee7112757000004740efa18cf93f00004740f068c4e3e040004740f10b2e0bd3c0004740f1b5b49eb640004740f2621d47e00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657572874.3089383,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_0df3afd2_5___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.5272e-07,weight_decay=0.0032998_2022-07-11_08-26-06\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_0df3afd2_5___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.5272e-07,weight_decay=0.0032998_2022-07-11_08-26-06/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11320, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11320, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 575, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 321, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 401, in ff_chunk\\n    ffn_output = self.activation(ffn_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/activations.py\\\", line 34, in forward\\n    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\\nRuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 15.78 GiB total capacity; 14.10 GiB already allocated; 47.50 MiB free; 14.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"ab22d412\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.233068551621429e-07,\n    \"weight_decay\": 0.002491094396520254,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.233068551621429e-07,\n    \"weight_decay\": 0.002491094396520254,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"6___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.2331e-07,weight_decay=0.0024911\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.4726104438304901,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.487765371799469,\n    \"validation_2_f1\": 0.0,\n    \"validation_mean\": 0.3225460946559906,\n    \"time_this_iter_s\": 2524.3199651241302,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"ab22d412\",\n    \"experiment_id\": \"30e84f779eea4ab5b5d14b098d41d685\",\n    \"date\": \"2022-07-12_05-36-56\",\n    \"timestamp\": 1657575416,\n    \"time_total_s\": 2524.3199651241302,\n    \"pid\": 11331,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 1.233068551621429e-07,\n      \"weight_decay\": 0.002491094396520254,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 2524.3199651241302,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"6___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.2331e-07,weight_decay=0.0024911\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657575416.6892147,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.4726104438304901,\n      \"min\": 0.4726104438304901,\n      \"avg\": 0.4726104438304901,\n      \"last\": 0.4726104438304901,\n      \"last-5-avg\": 0.4726104438304901,\n      \"last-10-avg\": 0.4726104438304901\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.487765371799469,\n      \"min\": 0.487765371799469,\n      \"avg\": 0.487765371799469,\n      \"last\": 0.487765371799469,\n      \"last-5-avg\": 0.487765371799469,\n      \"last-10-avg\": 0.487765371799469\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_mean\": {\n      \"max\": 0.3225460946559906,\n      \"min\": 0.3225460946559906,\n      \"avg\": 0.3225460946559906,\n      \"last\": 0.3225460946559906,\n      \"last-5-avg\": 0.3225460946559906,\n      \"last-10-avg\": 0.3225460946559906\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2524.3199651241302,\n      \"min\": 2524.3199651241302,\n      \"avg\": 2524.3199651241302,\n      \"last\": 2524.3199651241302,\n      \"last-5-avg\": 2524.3199651241302,\n      \"last-10-avg\": 2524.3199651241302\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 2524.3199651241302,\n      \"min\": 2524.3199651241302,\n      \"avg\": 2524.3199651241302,\n      \"last\": 2524.3199651241302,\n      \"last-5-avg\": 2524.3199651241302,\n      \"last-10-avg\": 2524.3199651241302\n    },\n    \"time_since_restore\": {\n      \"max\": 2524.3199651241302,\n      \"min\": 2524.3199651241302,\n      \"avg\": 2524.3199651241302,\n      \"last\": 2524.3199651241302,\n      \"last-5-avg\": 2524.3199651241302,\n      \"last-10-avg\": 2524.3199651241302\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fde3f3fe0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fde3f3fe0000000612e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294470000000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294470000000000000000612e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fdf378c40000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fdf378c40000000612e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294470000000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294470000000000000000612e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd4a49860000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd4a49860000000612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a3b8a3d2780000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a3b8a3d2780000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a3b8a3d2780000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a3b8a3d2780000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a3b8a3d2780000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a3b8a3d2780000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657572888.2478175,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_ab22d412_6___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.2331e-07,weight_decay=0.0024911_2022-07-12_04-54-34\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"96a34b92\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 4.468907617864363e-07,\n    \"weight_decay\": 7.628697887825164e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 4.468907617864363e-07,\n    \"weight_decay\": 7.628697887825164e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"7___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=4.4689e-07,weight_decay=7.6287e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.4166012704372406,\n    \"validation_0_f1\": 0.682170569896698,\n    \"validation_1_f1\": 0.5429543256759644,\n    \"validation_2_f1\": 0.607559084892273,\n    \"validation_mean\": 0.6280314922332764,\n    \"time_this_iter_s\": 2437.690881729126,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"96a34b92\",\n    \"experiment_id\": \"09e72ee8cfb741a8aa18b84afae7a477\",\n    \"date\": \"2022-07-14_00-07-04\",\n    \"timestamp\": 1657728424,\n    \"time_total_s\": 74893.99710822105,\n    \"pid\": 11324,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 4.468907617864363e-07,\n      \"weight_decay\": 7.628697887825164e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 74893.99710822105,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"experiment_tag\": \"7___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=4.4689e-07,weight_decay=7.6287e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657728424.455653,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.45121046900749207,\n      \"min\": 0.34159454703330994,\n      \"avg\": 0.40252707401911403,\n      \"last\": 0.4166012704372406,\n      \"last-5-avg\": 0.3797976016998291,\n      \"last-10-avg\": 0.37703233063220976\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.844162106513977,\n      \"min\": 0.0,\n      \"avg\": 0.4468474555857634,\n      \"last\": 0.682170569896698,\n      \"last-5-avg\": 0.7565233588218689,\n      \"last-10-avg\": 0.7650359869003296\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.8191356658935547,\n      \"min\": 0.47112154960632324,\n      \"avg\": 0.6321896612644193,\n      \"last\": 0.5429543256759644,\n      \"last-5-avg\": 0.6787929654121398,\n      \"last-10-avg\": 0.6964899778366089\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.8299999833106995,\n      \"min\": 0.5394543409347534,\n      \"avg\": 0.6966861546039578,\n      \"last\": 0.607559084892273,\n      \"last-5-avg\": 0.6988261699676513,\n      \"last-10-avg\": 0.689971512556076\n    },\n    \"validation_mean\": {\n      \"max\": 0.8311529159545898,\n      \"min\": 0.4423533082008362,\n      \"avg\": 0.631425803899765,\n      \"last\": 0.6280314922332764,\n      \"last-5-avg\": 0.7204957485198975,\n      \"last-10-avg\": 0.7265396595001221\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2802.912791490555,\n      \"min\": 2419.234338760376,\n      \"avg\": 2496.466570274034,\n      \"last\": 2437.690881729126,\n      \"last-5-avg\": 2448.2226648807527,\n      \"last-10-avg\": 2449.228201889992\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.03333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 74893.99710822105,\n      \"min\": 2802.912791490555,\n      \"avg\": 39202.12050584952,\n      \"last\": 74893.99710822105,\n      \"last-5-avg\": 70009.70852823257,\n      \"last-10-avg\": 63889.20799431801\n    },\n    \"time_since_restore\": {\n      \"max\": 74893.99710822105,\n      \"min\": 2802.912791490555,\n      \"avg\": 39202.12050584952,\n      \"last\": 74893.99710822105,\n      \"last-5-avg\": 70009.70852823257,\n      \"last-10-avg\": 63889.20799431801\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd5dcaf60000000473fd7593860000000473fda44a6a0000000473fd764de40000000473fdaa99860000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd98b1a40000000473fd645b5e0000000473fd7a0d480000000473fd8fee740000000473fd7536940000000473fd5dcaf60000000473fd7593860000000473fda44a6a0000000473fd764de40000000473fdaa99860000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473feabcbf80000000473fe93e0da0000000473fe5e1b060000000473fe95a5d80000000473fe5d45760000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe67d1000000000473feb036040000000473fe904eb60000000473fe75fdfc0000000473fe9df51c0000000473feabcbf80000000473fe93e0da0000000473fe5e1b060000000473fe95a5d80000000473fe5d45760000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe9452840000000473fe80b1360000000473fe21757e0000000473fe7d3e6e0000000473fe15fe1c0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe4eb6a60000000473fe9cdca40000000473fe7d9d6a0000000473fe33422c0000000473fe87deb60000000473fe9452840000000473fe80b1360000000473fe21757e0000000473fe7d3e6e0000000473fe15fe1c0000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fea31b4c0000000473fe6fc9840000000473fe43b5820000000473fe6f526a0000000473fe3711fc0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe3784e00000000473fe74a8640000000473fe5a552a0000000473fe6eb8fa0000000473fe5a6d560000000473fea31b4c0000000473fe6fc9840000000473fe43b5820000000473fe6f526a0000000473fe3711fc0000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fea225a40000000473fe847eae0000000473fe484a1c0000000473fe83fc520000000473fe418d580000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe554b4e0000000473fe99d7c60000000473fe7c9f1c0000000473fe622e6a0000000473fe85795e0000000473fea225a40000000473fe847eae0000000473fe484a1c0000000473fe83fc520000000473fe418d580000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a3336d554000004740a3372ece0800004740a31e876ca000004740a30db4ba8000004740a30b61bb400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a35bd6e66800004740a33dc3f35000004740a3003b553000004740a2e677fb4000004740a3360834f800004740a3336d554000004740a3372ece0800004740a31e876ca000004740a30db4ba8000004740a30b61bb400000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740efcad31d4900004740f07f230514c0004740f118174079c0004740f1b084e64dc0004740f248dff427c000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e9d1f4506980004740eb05d08f9e80004740ec35d444f180004740ed643bc4a580004740ee979c47f500004740efcad31d4900004740f07f230514c0004740f118174079c0004740f1b084e64dc0004740f248dff427c000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740efcad31d4900004740f07f230514c0004740f118174079c0004740f1b084e64dc0004740f248dff427c000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e9d1f4506980004740eb05d08f9e80004740ec35d444f180004740ed643bc4a580004740ee979c47f500004740efcad31d4900004740f07f230514c0004740f118174079c0004740f1b084e64dc0004740f248dff427c000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657650715.1063342,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_96a34b92_7___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=4.4689e-07,weight_decay=7.6287e-05_2022-07-13_02-31-54\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_96a34b92_7___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=4.4689e-07,weight_decay=7.6287e-05_2022-07-13_02-31-54/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11331, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11331, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 575, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 321, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 401, in ff_chunk\\n    ffn_output = self.activation(ffn_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/activations.py\\\", line 34, in forward\\n    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\\nRuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 15.78 GiB total capacity; 14.10 GiB already allocated; 47.50 MiB free; 14.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"e7dd6060\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 3.670323626327793e-07,\n    \"weight_decay\": 0.0016721244250575062,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 3.670323626327793e-07,\n    \"weight_decay\": 0.0016721244250575062,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"8___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.6703e-07,weight_decay=0.0016721\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.4690552353858948,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.4872596561908722,\n    \"validation_2_f1\": 0.00045651677646674216,\n    \"validation_mean\": 0.3219340443611145,\n    \"time_this_iter_s\": 2788.397177696228,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"e7dd6060\",\n    \"experiment_id\": \"09e72ee8cfb741a8aa18b84afae7a477\",\n    \"date\": \"2022-07-13_03-18-50\",\n    \"timestamp\": 1657653530,\n    \"time_total_s\": 2788.397177696228,\n    \"pid\": 11324,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 3.670323626327793e-07,\n      \"weight_decay\": 0.0016721244250575062,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 2788.397177696228,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"8___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.6703e-07,weight_decay=0.0016721\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657653530.085061,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.4690552353858948,\n      \"min\": 0.4690552353858948,\n      \"avg\": 0.4690552353858948,\n      \"last\": 0.4690552353858948,\n      \"last-5-avg\": 0.4690552353858948,\n      \"last-10-avg\": 0.4690552353858948\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.4872596561908722,\n      \"min\": 0.4872596561908722,\n      \"avg\": 0.4872596561908722,\n      \"last\": 0.4872596561908722,\n      \"last-5-avg\": 0.4872596561908722,\n      \"last-10-avg\": 0.4872596561908722\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.00045651677646674216,\n      \"min\": 0.00045651677646674216,\n      \"avg\": 0.00045651677646674216,\n      \"last\": 0.00045651677646674216,\n      \"last-5-avg\": 0.00045651677646674216,\n      \"last-10-avg\": 0.00045651677646674216\n    },\n    \"validation_mean\": {\n      \"max\": 0.3219340443611145,\n      \"min\": 0.3219340443611145,\n      \"avg\": 0.3219340443611145,\n      \"last\": 0.3219340443611145,\n      \"last-5-avg\": 0.3219340443611145,\n      \"last-10-avg\": 0.3219340443611145\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2788.397177696228,\n      \"min\": 2788.397177696228,\n      \"avg\": 2788.397177696228,\n      \"last\": 2788.397177696228,\n      \"last-5-avg\": 2788.397177696228,\n      \"last-10-avg\": 2788.397177696228\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 2788.397177696228,\n      \"min\": 2788.397177696228,\n      \"avg\": 2788.397177696228,\n      \"last\": 2788.397177696228,\n      \"last-5-avg\": 2788.397177696228,\n      \"last-10-avg\": 2788.397177696228\n    },\n    \"time_since_restore\": {\n      \"max\": 2788.397177696228,\n      \"min\": 2788.397177696228,\n      \"avg\": 2788.397177696228,\n      \"last\": 2788.397177696228,\n      \"last-5-avg\": 2788.397177696228,\n      \"last-10-avg\": 2788.397177696228\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fde050040000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fde050040000000612e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294470000000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294470000000000000000612e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fdf2f4320000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fdf2f4320000000612e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f3deb14a0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f3deb14a0000000612e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd49a9140000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd49a9140000000612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a5c8cb5ae00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a5c8cb5ae00000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a5c8cb5ae00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a5c8cb5ae00000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a5c8cb5ae00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a5c8cb5ae00000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657650735.8813717,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_e7dd6060_8___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.6703e-07,weight_decay=0.0016721_2022-07-13_02-32-15\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"75f39120\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 3.058367056957645e-07,\n    \"weight_decay\": 0.007223633395075165,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 3.058367056957645e-07,\n    \"weight_decay\": 0.007223633395075165,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"9___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.0584e-07,weight_decay=0.0072236\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.4716818630695343,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.0,\n    \"validation_2_f1\": 0.5019769668579102,\n    \"validation_mean\": 0.3350929617881775,\n    \"time_this_iter_s\": 2472.8352172374725,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 8,\n    \"trial_id\": \"75f39120\",\n    \"experiment_id\": \"805b25cbb2ab472790044bed3770f09c\",\n    \"date\": \"2022-07-14_06-32-32\",\n    \"timestamp\": 1657751552,\n    \"time_total_s\": 20571.985881328583,\n    \"pid\": 11333,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 3.058367056957645e-07,\n      \"weight_decay\": 0.007223633395075165,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 20571.985881328583,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 8,\n    \"experiment_tag\": \"9___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.0584e-07,weight_decay=0.0072236\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657751552.4713497,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.4719979166984558,\n      \"min\": 0.4716818630695343,\n      \"avg\": 0.4718209393322468,\n      \"last\": 0.4716818630695343,\n      \"last-5-avg\": 0.47174887657165526,\n      \"last-10-avg\": 0.4718209393322468\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.5019769668579102,\n      \"min\": 0.5019769668579102,\n      \"avg\": 0.5019769668579102,\n      \"last\": 0.5019769668579102,\n      \"last-5-avg\": 0.5019769668579102,\n      \"last-10-avg\": 0.5019769668579102\n    },\n    \"validation_mean\": {\n      \"max\": 0.3350929617881775,\n      \"min\": 0.3350929617881775,\n      \"avg\": 0.3350929617881775,\n      \"last\": 0.3350929617881775,\n      \"last-5-avg\": 0.3350929617881775,\n      \"last-10-avg\": 0.3350929617881775\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2683.8950061798096,\n      \"min\": 2472.8352172374725,\n      \"avg\": 2571.498235166073,\n      \"last\": 2472.8352172374725,\n      \"last-5-avg\": 2512.7270605564117,\n      \"last-10-avg\": 2571.498235166073\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.125,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.125\n    },\n    \"training_iteration\": {\n      \"max\": 8,\n      \"min\": 1,\n      \"avg\": 4.5,\n      \"last\": 8,\n      \"last-5-avg\": 6.0,\n      \"last-10-avg\": 4.5\n    },\n    \"time_total_s\": {\n      \"max\": 20571.985881328583,\n      \"min\": 2670.550014734268,\n      \"avg\": 11756.032738536596,\n      \"last\": 20571.985881328583,\n      \"last-5-avg\": 15602.98325881958,\n      \"last-10-avg\": 11756.032738536596\n    },\n    \"time_since_restore\": {\n      \"max\": 20571.985881328583,\n      \"min\": 2670.550014734268,\n      \"avg\": 11756.032738536596,\n      \"last\": 20571.985881328583,\n      \"last-5-avg\": 15602.98325881958,\n      \"last-10-avg\": 11756.032738536596\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 8,\n      \"min\": 1,\n      \"avg\": 4.5,\n      \"last\": 8,\n      \"last-5-avg\": 6.0,\n      \"last-10-avg\": 4.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fde327020000000473fde31fd80000000473fde30cb60000000473fde3068e0000000473fde300920000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fde3536c0000000473fde346300000000473fde333ee0000000473fde327020000000473fde31fd80000000473fde30cb60000000473fde3068e0000000473fde300920000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a41cb1ed0000004740a3f988ea5800004740a3644d227000004740a35b11ab0800004740a351aba1980000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a4dd199b8800004740a4f7ca3e4000004740a4bbcfa54000004740a41cb1ed0000004740a3f988ea5800004740a3644d227000004740a35b11ab0800004740a351aba1980000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b044b054b064b074b08652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059532000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b08652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c4ab595b0200004740c9a9bb959800004740ce82cede3400004740d1acc9a47b00004740d416ff18ae0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a4dd199b8800004740b4ea71ece400004740bf4859bf8400004740c4ab595b0200004740c9a9bb959800004740ce82cede3400004740d1acc9a47b00004740d416ff18ae0000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c4ab595b0200004740c9a9bb959800004740ce82cede3400004740d1acc9a47b00004740d416ff18ae0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a4dd199b8800004740b4ea71ece400004740bf4859bf8400004740c4ab595b0200004740c9a9bb959800004740ce82cede3400004740d1acc9a47b00004740d416ff18ae0000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059532000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b044b054b064b074b08652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059532000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b08652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657728424.719892,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_75f39120_9___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.0584e-07,weight_decay=0.0072236_2022-07-13_03-18-50\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_75f39120_9___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.0584e-07,weight_decay=0.0072236_2022-07-13_03-18-50/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11324, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11324, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 575, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 321, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 401, in ff_chunk\\n    ffn_output = self.activation(ffn_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/activations.py\\\", line 34, in forward\\n    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\\nRuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 15.78 GiB total capacity; 14.10 GiB already allocated; 47.50 MiB free; 14.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"d667232e\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 2.0934952814232196e-07,\n    \"weight_decay\": 0.0022972719454273215,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 2.0934952814232196e-07,\n    \"weight_decay\": 0.0022972719454273215,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"10___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.0935e-07,weight_decay=0.0022973\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.4688817858695984,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.48468321561813354,\n    \"validation_2_f1\": 0.005416384432464838,\n    \"validation_mean\": 0.32048046588897705,\n    \"time_this_iter_s\": 2539.0722539424896,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"d667232e\",\n    \"experiment_id\": \"805b25cbb2ab472790044bed3770f09c\",\n    \"date\": \"2022-07-14_00-49-40\",\n    \"timestamp\": 1657730980,\n    \"time_total_s\": 2539.0722539424896,\n    \"pid\": 11333,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 2.0934952814232196e-07,\n      \"weight_decay\": 0.0022972719454273215,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 2539.0722539424896,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"10___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.0935e-07,weight_decay=0.0022973\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657730980.2475882,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.4688817858695984,\n      \"min\": 0.4688817858695984,\n      \"avg\": 0.4688817858695984,\n      \"last\": 0.4688817858695984,\n      \"last-5-avg\": 0.4688817858695984,\n      \"last-10-avg\": 0.4688817858695984\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.48468321561813354,\n      \"min\": 0.48468321561813354,\n      \"avg\": 0.48468321561813354,\n      \"last\": 0.48468321561813354,\n      \"last-5-avg\": 0.48468321561813354,\n      \"last-10-avg\": 0.48468321561813354\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.005416384432464838,\n      \"min\": 0.005416384432464838,\n      \"avg\": 0.005416384432464838,\n      \"last\": 0.005416384432464838,\n      \"last-5-avg\": 0.005416384432464838,\n      \"last-10-avg\": 0.005416384432464838\n    },\n    \"validation_mean\": {\n      \"max\": 0.32048046588897705,\n      \"min\": 0.32048046588897705,\n      \"avg\": 0.32048046588897705,\n      \"last\": 0.32048046588897705,\n      \"last-5-avg\": 0.32048046588897705,\n      \"last-10-avg\": 0.32048046588897705\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2539.0722539424896,\n      \"min\": 2539.0722539424896,\n      \"avg\": 2539.0722539424896,\n      \"last\": 2539.0722539424896,\n      \"last-5-avg\": 2539.0722539424896,\n      \"last-10-avg\": 2539.0722539424896\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 2539.0722539424896,\n      \"min\": 2539.0722539424896,\n      \"avg\": 2539.0722539424896,\n      \"last\": 2539.0722539424896,\n      \"last-5-avg\": 2539.0722539424896,\n      \"last-10-avg\": 2539.0722539424896\n    },\n    \"time_since_restore\": {\n      \"max\": 2539.0722539424896,\n      \"min\": 2539.0722539424896,\n      \"avg\": 2539.0722539424896,\n      \"last\": 2539.0722539424896,\n      \"last-5-avg\": 2539.0722539424896,\n      \"last-10-avg\": 2539.0722539424896\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fde0228c0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fde0228c0000000612e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294470000000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294470000000000000000612e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fdf050cc0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fdf050cc0000000612e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f762f7da0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f762f7da0000000612e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd482c080000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd482c080000000612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a3d624fe780000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a3d624fe780000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a3d624fe780000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a3d624fe780000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a3d624fe780000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a3d624fe780000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657728437.514692,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_d667232e_10___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.0935e-07,weight_decay=0.0022973_2022-07-14_00-07-04\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"c9bfa0aa\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.6786087991515405e-06,\n    \"weight_decay\": 0.006194357048041414,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.6786087991515405e-06,\n    \"weight_decay\": 0.006194357048041414,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"11___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.6786e-06,weight_decay=0.0061944\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.46959152817726135,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.487765371799469,\n    \"validation_2_f1\": 0.0,\n    \"validation_mean\": 0.3225460946559906,\n    \"time_this_iter_s\": 2437.2760095596313,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"c9bfa0aa\",\n    \"experiment_id\": \"65181e1ae0ac4424a9e0f846022b541f\",\n    \"date\": \"2022-07-14_18-01-24\",\n    \"timestamp\": 1657792884,\n    \"time_total_s\": 2437.2760095596313,\n    \"pid\": 11326,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 1.6786087991515405e-06,\n      \"weight_decay\": 0.006194357048041414,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 2437.2760095596313,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"11___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.6786e-06,weight_decay=0.0061944\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657792884.8216388,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.46959152817726135,\n      \"min\": 0.46959152817726135,\n      \"avg\": 0.46959152817726135,\n      \"last\": 0.46959152817726135,\n      \"last-5-avg\": 0.46959152817726135,\n      \"last-10-avg\": 0.46959152817726135\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.487765371799469,\n      \"min\": 0.487765371799469,\n      \"avg\": 0.487765371799469,\n      \"last\": 0.487765371799469,\n      \"last-5-avg\": 0.487765371799469,\n      \"last-10-avg\": 0.487765371799469\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_mean\": {\n      \"max\": 0.3225460946559906,\n      \"min\": 0.3225460946559906,\n      \"avg\": 0.3225460946559906,\n      \"last\": 0.3225460946559906,\n      \"last-5-avg\": 0.3225460946559906,\n      \"last-10-avg\": 0.3225460946559906\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2437.2760095596313,\n      \"min\": 2437.2760095596313,\n      \"avg\": 2437.2760095596313,\n      \"last\": 2437.2760095596313,\n      \"last-5-avg\": 2437.2760095596313,\n      \"last-10-avg\": 2437.2760095596313\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 2437.2760095596313,\n      \"min\": 2437.2760095596313,\n      \"avg\": 2437.2760095596313,\n      \"last\": 2437.2760095596313,\n      \"last-5-avg\": 2437.2760095596313,\n      \"last-10-avg\": 2437.2760095596313\n    },\n    \"time_since_restore\": {\n      \"max\": 2437.2760095596313,\n      \"min\": 2437.2760095596313,\n      \"avg\": 2437.2760095596313,\n      \"last\": 2437.2760095596313,\n      \"last-5-avg\": 2437.2760095596313,\n      \"last-10-avg\": 2437.2760095596313\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fde0dc9a0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fde0dc9a0000000612e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294470000000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294470000000000000000612e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fdf378c40000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fdf378c40000000612e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294470000000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294470000000000000000612e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd4a49860000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd4a49860000000612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a30a8d51200000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a30a8d51200000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a30a8d51200000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a30a8d51200000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a30a8d51200000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a30a8d51200000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657751552.7302434,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_c9bfa0aa_11___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.6786e-06,weight_decay=0.0061944_2022-07-14_06-32-32\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_c9bfa0aa_11___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.6786e-06,weight_decay=0.0061944_2022-07-14_06-32-32/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11333, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11333, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 575, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 321, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 401, in ff_chunk\\n    ffn_output = self.activation(ffn_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/activations.py\\\", line 34, in forward\\n    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\\nRuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 15.78 GiB total capacity; 14.10 GiB already allocated; 47.50 MiB free; 14.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"afc6c20c\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 2.172866349809914e-06,\n    \"weight_decay\": 0.005305954879986261,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 2.172866349809914e-06,\n    \"weight_decay\": 0.005305954879986261,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"12___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.1729e-06,weight_decay=0.005306\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.463144451379776,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.5777120590209961,\n    \"validation_2_f1\": 0.3402446508407593,\n    \"validation_mean\": 0.3741106390953064,\n    \"time_this_iter_s\": 2422.7190001010895,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 16,\n    \"trial_id\": \"afc6c20c\",\n    \"experiment_id\": \"65181e1ae0ac4424a9e0f846022b541f\",\n    \"date\": \"2022-07-14_17-20-47\",\n    \"timestamp\": 1657790447,\n    \"time_total_s\": 38876.49648761749,\n    \"pid\": 11326,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 2.172866349809914e-06,\n      \"weight_decay\": 0.005305954879986261,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 38876.49648761749,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 16,\n    \"experiment_tag\": \"12___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.1729e-06,weight_decay=0.005306\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657790447.3175397,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.4821043014526367,\n      \"min\": 0.43376779556274414,\n      \"avg\": 0.46043878048658365,\n      \"last\": 0.463144451379776,\n      \"last-5-avg\": 0.47373597621917723,\n      \"last-10-avg\": 0.4634819686412811\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.7439010739326477,\n      \"min\": 0.008932769298553467,\n      \"avg\": 0.5263009909540415,\n      \"last\": 0.5777120590209961,\n      \"last-5-avg\": 0.5223982989788055,\n      \"last-10-avg\": 0.5632601708173752\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.5075882077217102,\n      \"min\": 0.2209494262933731,\n      \"avg\": 0.3720546765252948,\n      \"last\": 0.3402446508407593,\n      \"last-5-avg\": 0.26990151703357695,\n      \"last-10-avg\": 0.3283973142504692\n    },\n    \"validation_mean\": {\n      \"max\": 0.49797260761260986,\n      \"min\": 0.2960752844810486,\n      \"avg\": 0.3720688913017512,\n      \"last\": 0.3741106390953064,\n      \"last-5-avg\": 0.32459643483161926,\n      \"last-10-avg\": 0.3604161858558655\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2467.1176660060883,\n      \"min\": 2413.826421737671,\n      \"avg\": 2429.7810304760933,\n      \"last\": 2422.7190001010895,\n      \"last-5-avg\": 2418.907300662994,\n      \"last-10-avg\": 2424.2854003190996\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.0625,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 16,\n      \"min\": 1,\n      \"avg\": 8.5,\n      \"last\": 16,\n      \"last-5-avg\": 14.0,\n      \"last-10-avg\": 11.5\n    },\n    \"time_total_s\": {\n      \"max\": 38876.49648761749,\n      \"min\": 2447.518670797348,\n      \"avg\": 20683.772373855114,\n      \"last\": 38876.49648761749,\n      \"last-5-avg\": 34039.66958327293,\n      \"last-10-avg\": 27984.50725121498\n    },\n    \"time_since_restore\": {\n      \"max\": 38876.49648761749,\n      \"min\": 2447.518670797348,\n      \"avg\": 20683.772373855114,\n      \"last\": 38876.49648761749,\n      \"last-5-avg\": 34039.66958327293,\n      \"last-10-avg\": 27984.50725121498\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 16,\n      \"min\": 1,\n      \"avg\": 8.5,\n      \"last\": 16,\n      \"last-5-avg\": 14.0,\n      \"last-10-avg\": 11.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fde251b40000000473fde65af20000000473fde8eb480000000473fdedacc00000000473fdda428a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fdcc657e0000000473fdd80b420000000473fdcecf580000000473fdda0c640000000473fdc33a780000000473fde251b40000000473fde65af20000000473fde8eb480000000473fdedacc00000000473fdda428a0000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fde7da080000000473fe1302d60000000473fdf4e2820000000473fe102bf80000000473fe27c9e00000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe4064560000000473fe07cd780000000473fe4d28e20000000473fe15fdd80000000473fe5f34e40000000473fde7da080000000473fe1302d60000000473fdf4e2820000000473fe102bf80000000473fe27c9e00000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd3513800000000473fcfa32760000000473fcea1dda0000000473fcc481220000000473fd5c69180000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fda07c520000000473fd7ce5320000000473fd789d7c0000000473fd58cfec0000000473fdce159e0000000473fd3513800000000473fcfa32760000000473fcea1dda0000000473fcc481220000000473fd5c69180000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd3f3db60000000473fd4a99be0000000473fd2f2e5c0000000473fd45d25e0000000473fd7f16dc0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fda4d98e0000000473fd6a18020000000473fda823e20000000473fd6691840000000473fdcf13680000000473fd3f3db60000000473fd4a99be0000000473fd2f2e5c0000000473fd45d25e0000000473fd7f16dc0000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a2ec28897000004740a2e816d08800004740a2dfbc151000004740a2dba720c000004740a2ed7020c80000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a3089d0c6000004740a30ea6f24800004740a2ee15031800004740a2e9d09dc000004740a2f978efd800004740a2ec28897000004740a2e816d08800004740a2dfbc151000004740a2dba720c000004740a2ed7020c80000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0c4b0d4b0e4b0f4b10652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b074b084b094b0a4b0b4b0c4b0d4b0e4b0f4b10652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740dc8502819000004740dee2055ba100004740e09efe6f2180004740e1ccb8e12d80004740e2fb8fe33a0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740d0ab7cc00300004740d30d519e4c00004740d56b143eaf00004740d7c84e526700004740da277d706200004740dc8502819000004740dee2055ba100004740e09efe6f2180004740e1ccb8e12d80004740e2fb8fe33a0000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740dc8502819000004740dee2055ba100004740e09efe6f2180004740e1ccb8e12d80004740e2fb8fe33a0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740d0ab7cc00300004740d30d519e4c00004740d56b143eaf00004740d7c84e526700004740da277d706200004740dc8502819000004740dee2055ba100004740e09efe6f2180004740e1ccb8e12d80004740e2fb8fe33a0000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0c4b0d4b0e4b0f4b10652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b074b084b094b0a4b0b4b0c4b0d4b0e4b0f4b10652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657751566.7058783,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_afc6c20c_12___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.1729e-06,weight_decay=0.005306_2022-07-14_06-32-46\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"3ee0ecb0\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.1511459478982988e-06,\n    \"weight_decay\": 0.008314269807685015,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.1511459478982988e-06,\n    \"weight_decay\": 0.008314269807685015,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"13___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.1511e-06,weight_decay=0.0083143\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.4697227478027344,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.487765371799469,\n    \"validation_2_f1\": 0.0,\n    \"validation_mean\": 0.3225460946559906,\n    \"time_this_iter_s\": 2427.1858723163605,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"3ee0ecb0\",\n    \"experiment_id\": \"b306756d3906481491e03139c611034f\",\n    \"date\": \"2022-07-15_06-13-13\",\n    \"timestamp\": 1657836793,\n    \"time_total_s\": 2427.1858723163605,\n    \"pid\": 11319,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 1.1511459478982988e-06,\n      \"weight_decay\": 0.008314269807685015,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 2427.1858723163605,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"13___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.1511e-06,weight_decay=0.0083143\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657836793.1462183,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.4697227478027344,\n      \"min\": 0.4697227478027344,\n      \"avg\": 0.4697227478027344,\n      \"last\": 0.4697227478027344,\n      \"last-5-avg\": 0.4697227478027344,\n      \"last-10-avg\": 0.4697227478027344\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.487765371799469,\n      \"min\": 0.487765371799469,\n      \"avg\": 0.487765371799469,\n      \"last\": 0.487765371799469,\n      \"last-5-avg\": 0.487765371799469,\n      \"last-10-avg\": 0.487765371799469\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_mean\": {\n      \"max\": 0.3225460946559906,\n      \"min\": 0.3225460946559906,\n      \"avg\": 0.3225460946559906,\n      \"last\": 0.3225460946559906,\n      \"last-5-avg\": 0.3225460946559906,\n      \"last-10-avg\": 0.3225460946559906\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2427.1858723163605,\n      \"min\": 2427.1858723163605,\n      \"avg\": 2427.1858723163605,\n      \"last\": 2427.1858723163605,\n      \"last-5-avg\": 2427.1858723163605,\n      \"last-10-avg\": 2427.1858723163605\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 2427.1858723163605,\n      \"min\": 2427.1858723163605,\n      \"avg\": 2427.1858723163605,\n      \"last\": 2427.1858723163605,\n      \"last-5-avg\": 2427.1858723163605,\n      \"last-10-avg\": 2427.1858723163605\n    },\n    \"time_since_restore\": {\n      \"max\": 2427.1858723163605,\n      \"min\": 2427.1858723163605,\n      \"avg\": 2427.1858723163605,\n      \"last\": 2427.1858723163605,\n      \"last-5-avg\": 2427.1858723163605,\n      \"last-10-avg\": 2427.1858723163605\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fde0ff000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fde0ff000000000612e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294470000000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294470000000000000000612e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fdf378c40000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fdf378c40000000612e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294470000000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294470000000000000000612e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd4a49860000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd4a49860000000612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a2f65f2aa80000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a2f65f2aa80000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a2f65f2aa80000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a2f65f2aa80000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a2f65f2aa80000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a2f65f2aa80000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657792885.0763304,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_3ee0ecb0_13___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.1511e-06,weight_decay=0.0083143_2022-07-14_18-01-24\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_3ee0ecb0_13___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.1511e-06,weight_decay=0.0083143_2022-07-14_18-01-24/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11326, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11326, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 575, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 321, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 401, in ff_chunk\\n    ffn_output = self.activation(ffn_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/activations.py\\\", line 34, in forward\\n    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\\nRuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 15.78 GiB total capacity; 14.02 GiB already allocated; 41.50 MiB free; 14.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"ebc57180\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 5.99196511048505e-07,\n    \"weight_decay\": 0.004412881557477912,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 5.99196511048505e-07,\n    \"weight_decay\": 0.004412881557477912,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"14___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=5.992e-07,weight_decay=0.0044129\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.45849886536598206,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.4320257902145386,\n    \"validation_2_f1\": 0.5284755229949951,\n    \"validation_mean\": 0.41741257905960083,\n    \"time_this_iter_s\": 2421.2501735687256,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 16,\n    \"trial_id\": \"ebc57180\",\n    \"experiment_id\": \"b306756d3906481491e03139c611034f\",\n    \"date\": \"2022-07-15_05-32-45\",\n    \"timestamp\": 1657834365,\n    \"time_total_s\": 41464.21819090843,\n    \"pid\": 11319,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 5.99196511048505e-07,\n      \"weight_decay\": 0.004412881557477912,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 41464.21819090843,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 16,\n    \"experiment_tag\": \"14___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=5.992e-07,weight_decay=0.0044129\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657834365.704279,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.47306209802627563,\n      \"min\": 0.4554086923599243,\n      \"avg\": 0.46634782478213305,\n      \"last\": 0.45849886536598206,\n      \"last-5-avg\": 0.46239259243011477,\n      \"last-10-avg\": 0.46252753734588625\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.5044368505477905,\n      \"min\": 0.0,\n      \"avg\": 0.2083735717460513,\n      \"last\": 0.4320257902145386,\n      \"last-5-avg\": 0.34681646823883056,\n      \"last-10-avg\": 0.3333977147936821\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.5381160378456116,\n      \"min\": 0.5019769668579102,\n      \"avg\": 0.5139027684926986,\n      \"last\": 0.5284755229949951,\n      \"last-5-avg\": 0.5198251724243164,\n      \"last-10-avg\": 0.5210582494735718\n    },\n    \"validation_mean\": {\n      \"max\": 0.43845152854919434,\n      \"min\": 0.3350929617881775,\n      \"avg\": 0.37308737076818943,\n      \"last\": 0.41741257905960083,\n      \"last-5-avg\": 0.3962818384170532,\n      \"last-10-avg\": 0.3958840161561966\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2898.445235490799,\n      \"min\": 2418.608295440674,\n      \"avg\": 2591.513636931776,\n      \"last\": 2421.2501735687256,\n      \"last-5-avg\": 2529.457525587082,\n      \"last-10-avg\": 2609.7257070064543\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.0625,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 16,\n      \"min\": 1,\n      \"avg\": 8.5,\n      \"last\": 16,\n      \"last-5-avg\": 14.0,\n      \"last-10-avg\": 11.5\n    },\n    \"time_total_s\": {\n      \"max\": 41464.21819090843,\n      \"min\": 2441.016155719757,\n      \"avg\": 22027.234403282404,\n      \"last\": 41464.21819090843,\n      \"last-5-avg\": 36557.355448150636,\n      \"last-10-avg\": 30027.513799571992\n    },\n    \"time_since_restore\": {\n      \"max\": 41464.21819090843,\n      \"min\": 2441.016155719757,\n      \"avg\": 22027.234403282404,\n      \"last\": 41464.21819090843,\n      \"last-5-avg\": 36557.355448150636,\n      \"last-10-avg\": 30027.513799571992\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 16,\n      \"min\": 1,\n      \"avg\": 8.5,\n      \"last\": 16,\n      \"last-5-avg\": 14.0,\n      \"last-10-avg\": 11.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fdd9ad520000000473fdda76d40000000473fdd933a80000000473fddc9ab00000000473fdd580ba0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fde25af60000000473fdddeb580000000473fdd4ec9a0000000473fdd94b680000000473fdd256a80000000473fdd9ad520000000473fdda76d40000000473fdd933a80000000473fddc9ab00000000473fdd580ba0000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd65d2bc0000000473fd560d700000000473fd6fb26e0000000473fd09bbb60000000473fdba64f80000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fb527f480000000473fcb44a6e0000000473fdcbc51e0000000473fd6735940000000473fe02458c0000000473fd65d2bc0000000473fd560d700000000473fd6fb26e0000000473fd09bbb60000000473fdba64f80000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe0baf9a0000000473fe090f3a0000000473fe095b0e0000000473fe0612660000000473fe0e94580000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe0184540000000473fe06bfcc0000000473fe10af120000000473fe0c99b40000000473fe1383f20000000473fe0baf9a0000000473fe090f3a0000000473fe095b0e0000000473fe0612660000000473fe0e94580000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd9828940000000473fd91d0180000000473fd9647400000000473fd8148680000000473fdab6e340000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd618dfa0000000473fd7b40240000000473fdb19e960000000473fd997d860000000473fdc0f9700000000473fd9828940000000473fd91d0180000000473fd9647400000000473fd8148680000000473fdab6e340000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a4ed0d870800004740a4d0a27ac800004740a3412bb8e800004740a2e537728000004740a2ea8016c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a61c4011c800004740a54ca2ce2000004740a38541949000004740a525c0076000004740a5000bdee000004740a4ed0d870800004740a4d0a27ac800004740a3412bb8e800004740a2e537728000004740a2ea8016c00000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0c4b0d4b0e4b0f4b10652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b074b084b094b0a4b0b4b0c4b0d4b0e4b0f4b10652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740dec1dd3f3900004740e0adf8c74900004740e1e20b82d780004740e3105ef9ff80004740e43f06fb6b8000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740d1c545853a00004740d46ed9defe00004740d6df82119000004740d9843a127c00004740dc243b8e5800004740dec1dd3f3900004740e0adf8c74900004740e1e20b82d780004740e3105ef9ff80004740e43f06fb6b8000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740dec1dd3f3900004740e0adf8c74900004740e1e20b82d780004740e3105ef9ff80004740e43f06fb6b8000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740d1c545853a00004740d46ed9defe00004740d6df82119000004740d9843a127c00004740dc243b8e5800004740dec1dd3f3900004740e0adf8c74900004740e1e20b82d780004740e3105ef9ff80004740e43f06fb6b8000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0c4b0d4b0e4b0f4b10652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b074b084b094b0a4b0b4b0c4b0d4b0e4b0f4b10652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657792897.8130586,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_ebc57180_14___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=5.992e-07,weight_decay=0.0044129_2022-07-14_18-01-37\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"804a98a2\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 2.1279383519243996e-07,\n    \"weight_decay\": 0.0015303410204614764,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 2.1279383519243996e-07,\n    \"weight_decay\": 0.0015303410204614764,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"15___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.1279e-07,weight_decay=0.0015303\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.4693058133125305,\n    \"validation_0_f1\": 0.5110781192779541,\n    \"validation_1_f1\": 0.009411764331161976,\n    \"validation_2_f1\": 0.0,\n    \"validation_mean\": 0.34389105439186096,\n    \"time_this_iter_s\": 2785.524362564087,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 8,\n    \"trial_id\": \"804a98a2\",\n    \"experiment_id\": \"f18001f105174064bc1dbdecd93a9105\",\n    \"date\": \"2022-07-15_17-20-43\",\n    \"timestamp\": 1657876843,\n    \"time_total_s\": 20691.270179986954,\n    \"pid\": 11314,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 2.1279383519243996e-07,\n      \"weight_decay\": 0.0015303410204614764,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 20691.270179986954,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 8,\n    \"experiment_tag\": \"15___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.1279e-07,weight_decay=0.0015303\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657876843.464735,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.4709828197956085,\n      \"min\": 0.4693058133125305,\n      \"avg\": 0.47049930691719055,\n      \"last\": 0.4693058133125305,\n      \"last-5-avg\": 0.4702234208583832,\n      \"last-10-avg\": 0.47049930691719055\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.5110781192779541,\n      \"min\": 0.510087788105011,\n      \"avg\": 0.5102297440171242,\n      \"last\": 0.5110781192779541,\n      \"last-5-avg\": 0.5103149175643921,\n      \"last-10-avg\": 0.5102297440171242\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.009411764331161976,\n      \"min\": 0.0,\n      \"avg\": 0.0013542518354370259,\n      \"last\": 0.009411764331161976,\n      \"last-5-avg\": 0.0021668029366992414,\n      \"last-10-avg\": 0.0013542518354370259\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_mean\": {\n      \"max\": 0.34389105439186096,\n      \"min\": 0.3423609435558319,\n      \"avg\": 0.342580895870924,\n      \"last\": 0.34389105439186096,\n      \"last-5-avg\": 0.34271286725997924,\n      \"last-10-avg\": 0.342580895870924\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2822.3477177619934,\n      \"min\": 2420.1945593357086,\n      \"avg\": 2586.408772498369,\n      \"last\": 2785.524362564087,\n      \"last-5-avg\": 2684.7402155399323,\n      \"last-10-avg\": 2586.408772498369\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.125,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.125\n    },\n    \"training_iteration\": {\n      \"max\": 8,\n      \"min\": 1,\n      \"avg\": 4.5,\n      \"last\": 8,\n      \"last-5-avg\": 6.0,\n      \"last-10-avg\": 4.5\n    },\n    \"time_total_s\": {\n      \"max\": 20691.270179986954,\n      \"min\": 2422.176505088806,\n      \"avg\": 11271.257181107998,\n      \"last\": 20691.270179986954,\n      \"last-5-avg\": 15127.588155412674,\n      \"last-10-avg\": 11271.257181107998\n    },\n    \"time_since_restore\": {\n      \"max\": 20691.270179986954,\n      \"min\": 2422.176505088806,\n      \"avg\": 11271.257181107998,\n      \"last\": 20691.270179986954,\n      \"last-5-avg\": 15127.588155412674,\n      \"last-10-avg\": 11271.257181107998\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 8,\n      \"min\": 1,\n      \"avg\": 4.5,\n      \"last\": 8,\n      \"last-5-avg\": 6.0,\n      \"last-10-avg\": 4.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fde223260000000473fde211e40000000473fde176f60000000473fde14d8a0000000473fde091b40000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fde249520000000473fde2464a0000000473fde239b60000000473fde223260000000473fde211e40000000473fde176f60000000473fde14d8a0000000473fde091b40000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe052a3a0000000473fe052a3a0000000473fe0531d80000000473fe0535a80000000473fe05ac080000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe052a3a0000000473fe052a3a0000000473fe052a3a0000000473fe052a3a0000000473fe052a3a0000000473fe0531d80000000473fe0535a80000000473fe05ac080000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000473f3f130ec0000000473f4f112c00000000473f834679a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000473f3f130ec0000000473f4f112c00000000473f834679a0000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd5e93de0000000473fd5e93de0000000473fd5ea7ec0000000473fd5ebbfa0000000473fd6024fa0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd5e93de0000000473fd5e93de0000000473fd5e93de0000000473fd5e93de0000000473fd5e93de0000000473fd5ea7ec0000000473fd5ebbfa0000000473fd6024fa0000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a2eaa3baf800004740a4277f705000004740a5fd85471000004740a60cb2081000004740a5c30c79400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a2ec5a5ee000004740a2e8639d4800004740a2f265653800004740a2eaa3baf800004740a4277f705000004740a5fd85471000004740a60cb2081000004740a5c30c79400000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b044b054b064b074b08652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059532000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b08652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c2ec71c71600004740c7f651a32a00004740cd75b2f4ee00004740d17c6fbb7900004740d434d14aa10000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a2ec5a5ee000004740b2ea5efe1400004740bc6391b0b000004740c2ec71c71600004740c7f651a32a00004740cd75b2f4ee00004740d17c6fbb7900004740d434d14aa10000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c2ec71c71600004740c7f651a32a00004740cd75b2f4ee00004740d17c6fbb7900004740d434d14aa10000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a2ec5a5ee000004740b2ea5efe1400004740bc6391b0b000004740c2ec71c71600004740c7f651a32a00004740cd75b2f4ee00004740d17c6fbb7900004740d434d14aa10000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059532000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b044b054b064b074b08652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059532000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b08652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657836793.396572,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_804a98a2_15___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.1279e-07,weight_decay=0.0015303_2022-07-15_05-32-45\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_804a98a2_15___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.1279e-07,weight_decay=0.0015303_2022-07-15_05-32-45/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11319, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11319, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 575, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 321, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 401, in ff_chunk\\n    ffn_output = self.activation(ffn_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/activations.py\\\", line 34, in forward\\n    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\\nRuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 15.78 GiB total capacity; 14.10 GiB already allocated; 71.50 MiB free; 14.28 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"272b4e64\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.266013623154677e-07,\n    \"weight_decay\": 0.007496970889759907,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.266013623154677e-07,\n    \"weight_decay\": 0.007496970889759907,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"16___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.266e-07,weight_decay=0.007497\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.47214391827583313,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.0,\n    \"validation_2_f1\": 0.5019769668579102,\n    \"validation_mean\": 0.3350929617881775,\n    \"time_this_iter_s\": 2419.6383199691772,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 8,\n    \"trial_id\": \"272b4e64\",\n    \"experiment_id\": \"f18001f105174064bc1dbdecd93a9105\",\n    \"date\": \"2022-07-15_11-35-51\",\n    \"timestamp\": 1657856151,\n    \"time_total_s\": 19341.479066848755,\n    \"pid\": 11314,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 1.266013623154677e-07,\n      \"weight_decay\": 0.007496970889759907,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 19341.479066848755,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 8,\n    \"experiment_tag\": \"16___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.266e-07,weight_decay=0.007497\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657856151.959069,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.47223904728889465,\n      \"min\": 0.47214391827583313,\n      \"avg\": 0.47218998894095415,\n      \"last\": 0.47214391827583313,\n      \"last-5-avg\": 0.47217113971710206,\n      \"last-10-avg\": 0.4721899889409542\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.5019769668579102,\n      \"min\": 0.5019769668579102,\n      \"avg\": 0.5019769668579102,\n      \"last\": 0.5019769668579102,\n      \"last-5-avg\": 0.5019769668579102,\n      \"last-10-avg\": 0.5019769668579102\n    },\n    \"validation_mean\": {\n      \"max\": 0.3350929617881775,\n      \"min\": 0.3350929617881775,\n      \"avg\": 0.3350929617881775,\n      \"last\": 0.3350929617881775,\n      \"last-5-avg\": 0.3350929617881775,\n      \"last-10-avg\": 0.3350929617881775\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2424.361991882324,\n      \"min\": 2414.6065225601196,\n      \"avg\": 2417.6848833560944,\n      \"last\": 2419.6383199691772,\n      \"last-5-avg\": 2417.4526031017303,\n      \"last-10-avg\": 2417.6848833560944\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.125,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.125\n    },\n    \"training_iteration\": {\n      \"max\": 8,\n      \"min\": 1,\n      \"avg\": 4.5,\n      \"last\": 8,\n      \"last-5-avg\": 6.0,\n      \"last-10-avg\": 4.5\n    },\n    \"time_total_s\": {\n      \"max\": 19341.479066848755,\n      \"min\": 2424.361991882324,\n      \"avg\": 10879.998695164919,\n      \"last\": 19341.479066848755,\n      \"last-5-avg\": 14504.488600730896,\n      \"last-10-avg\": 10879.998695164919\n    },\n    \"time_since_restore\": {\n      \"max\": 19341.479066848755,\n      \"min\": 2424.361991882324,\n      \"avg\": 10879.998695164919,\n      \"last\": 19341.479066848755,\n      \"last-5-avg\": 14504.488600730896,\n      \"last-10-avg\": 10879.998695164919\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 8,\n      \"min\": 1,\n      \"avg\": 4.5,\n      \"last\": 8,\n      \"last-5-avg\": 6.0,\n      \"last-10-avg\": 4.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fde38b780000000473fde385760000000473fde37cbe0000000473fde37cca0000000473fde379b20000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fde392a20000000473fde38ee60000000473fde3887e0000000473fde38b780000000473fde385760000000473fde37cbe0000000473fde37cca0000000473fde379b20000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a2dfb2d0b800004740a2dd4d522000004740a2e740218000004740a2e2ff93c000004740a2e746d1e00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a2f0b9570000004740a2dd368a2000004740a2de7ebd2800004740a2dfb2d0b800004740a2dd4d522000004740a2e740218000004740a2e2ff93c000004740a2e746d1e00000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b044b054b064b074b08652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059532000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b08652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c2e3085bc000004740c79a5bb04800004740cc542bb8a800004740d08675cecc00004740d2e35ea9080000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a2f0b9570000004740b2e6f7f09000004740bc56374f2400004740c2e3085bc000004740c79a5bb04800004740cc542bb8a800004740d08675cecc00004740d2e35ea9080000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c2e3085bc000004740c79a5bb04800004740cc542bb8a800004740d08675cecc00004740d2e35ea9080000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a2f0b9570000004740b2e6f7f09000004740bc56374f2400004740c2e3085bc000004740c79a5bb04800004740cc542bb8a800004740d08675cecc00004740d2e35ea9080000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059532000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b044b054b064b074b08652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059532000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b08652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657836806.393986,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_272b4e64_16___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.266e-07,weight_decay=0.007497_2022-07-15_06-13-13\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"39e8bb2c\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 2.3532860439119194e-07,\n    \"weight_decay\": 0.008112415690918017,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 2.3532860439119194e-07,\n    \"weight_decay\": 0.008112415690918017,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"17___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.3533e-07,weight_decay=0.0081124\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.47111964225769043,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.4874153733253479,\n    \"validation_2_f1\": 0.0,\n    \"validation_mean\": 0.32224008440971375,\n    \"time_this_iter_s\": 2432.686667203903,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"39e8bb2c\",\n    \"experiment_id\": \"0fad0c84818c4b44aa005cfb50f1c979\",\n    \"date\": \"2022-07-16_14-27-12\",\n    \"timestamp\": 1657952832,\n    \"time_total_s\": 2432.686667203903,\n    \"pid\": 11318,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 2.3532860439119194e-07,\n      \"weight_decay\": 0.008112415690918017,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 2432.686667203903,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"17___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.3533e-07,weight_decay=0.0081124\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657952832.332761,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.47111964225769043,\n      \"min\": 0.47111964225769043,\n      \"avg\": 0.47111964225769043,\n      \"last\": 0.47111964225769043,\n      \"last-5-avg\": 0.47111964225769043,\n      \"last-10-avg\": 0.47111964225769043\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.4874153733253479,\n      \"min\": 0.4874153733253479,\n      \"avg\": 0.4874153733253479,\n      \"last\": 0.4874153733253479,\n      \"last-5-avg\": 0.4874153733253479,\n      \"last-10-avg\": 0.4874153733253479\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_mean\": {\n      \"max\": 0.32224008440971375,\n      \"min\": 0.32224008440971375,\n      \"avg\": 0.32224008440971375,\n      \"last\": 0.32224008440971375,\n      \"last-5-avg\": 0.32224008440971375,\n      \"last-10-avg\": 0.32224008440971375\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2432.686667203903,\n      \"min\": 2432.686667203903,\n      \"avg\": 2432.686667203903,\n      \"last\": 2432.686667203903,\n      \"last-5-avg\": 2432.686667203903,\n      \"last-10-avg\": 2432.686667203903\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 2432.686667203903,\n      \"min\": 2432.686667203903,\n      \"avg\": 2432.686667203903,\n      \"last\": 2432.686667203903,\n      \"last-5-avg\": 2432.686667203903,\n      \"last-10-avg\": 2432.686667203903\n    },\n    \"time_since_restore\": {\n      \"max\": 2432.686667203903,\n      \"min\": 2432.686667203903,\n      \"avg\": 2432.686667203903,\n      \"last\": 2432.686667203903,\n      \"last-5-avg\": 2432.686667203903,\n      \"last-10-avg\": 2432.686667203903\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fde26d300000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fde26d300000000612e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294470000000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294470000000000000000612e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fdf31d040000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fdf31d040000000612e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294470000000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294470000000000000000612e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd49f94e0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd49f94e0000000612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a3015f92d80000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a3015f92d80000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a3015f92d80000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a3015f92d80000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a3015f92d80000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a3015f92d80000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657876843.7155683,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_39e8bb2c_17___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.3533e-07,weight_decay=0.0081124_2022-07-15_11-35-52\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_39e8bb2c_17___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.3533e-07,weight_decay=0.0081124_2022-07-15_11-35-52/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11314, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11314, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 575, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 321, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 401, in ff_chunk\\n    ffn_output = self.activation(ffn_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/activations.py\\\", line 34, in forward\\n    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\\nRuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 15.78 GiB total capacity; 14.10 GiB already allocated; 71.50 MiB free; 14.28 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"6706d53c\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 8.72596159329642e-07,\n    \"weight_decay\": 0.00942843972725673,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 8.72596159329642e-07,\n    \"weight_decay\": 0.00942843972725673,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"18___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=8.726e-07,weight_decay=0.0094284\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.4401673674583435,\n    \"validation_0_f1\": 0.5840349793434143,\n    \"validation_1_f1\": 0.0,\n    \"validation_2_f1\": 0.6519303321838379,\n    \"validation_mean\": 0.507000207901001,\n    \"time_this_iter_s\": 2410.5409841537476,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"6706d53c\",\n    \"experiment_id\": \"0fad0c84818c4b44aa005cfb50f1c979\",\n    \"date\": \"2022-07-16_13-46-39\",\n    \"timestamp\": 1657950399,\n    \"time_total_s\": 73538.04019021988,\n    \"pid\": 11318,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 8.72596159329642e-07,\n      \"weight_decay\": 0.00942843972725673,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 73538.04019021988,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"experiment_tag\": \"18___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=8.726e-07,weight_decay=0.0094284\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657950399.3809109,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.46818286180496216,\n      \"min\": 0.4250577390193939,\n      \"avg\": 0.44389689167340596,\n      \"last\": 0.4401673674583435,\n      \"last-5-avg\": 0.43571004271507263,\n      \"last-10-avg\": 0.440720397233963\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.6742892265319824,\n      \"min\": 0.5104950666427612,\n      \"avg\": 0.5979590892791748,\n      \"last\": 0.5840349793434143,\n      \"last-5-avg\": 0.6018704295158386,\n      \"last-10-avg\": 0.589581698179245\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.005200945772230625,\n      \"min\": 0.0,\n      \"avg\": 0.00033099919479961194,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.8236473202705383,\n      \"min\": 0.0,\n      \"avg\": 0.6311275667375109,\n      \"last\": 0.6519303321838379,\n      \"last-5-avg\": 0.7301251769065857,\n      \"last-10-avg\": 0.6729905664920807\n    },\n    \"validation_mean\": {\n      \"max\": 0.6168617606163025,\n      \"min\": 0.34312599897384644,\n      \"avg\": 0.5177364607652029,\n      \"last\": 0.507000207901001,\n      \"last-5-avg\": 0.5398362755775452,\n      \"last-10-avg\": 0.5169382601976394\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2805.677257537842,\n      \"min\": 2410.5409841537476,\n      \"avg\": 2451.2680063406615,\n      \"last\": 2410.5409841537476,\n      \"last-5-avg\": 2424.52445192337,\n      \"last-10-avg\": 2429.374093389511\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.03333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 73538.04019021988,\n      \"min\": 2454.305910587311,\n      \"avg\": 38214.26587623755,\n      \"last\": 73538.04019021988,\n      \"last-5-avg\": 68697.05578045845,\n      \"last-10-avg\": 62623.982934093474\n    },\n    \"time_since_restore\": {\n      \"max\": 73538.04019021988,\n      \"min\": 2454.305910587311,\n      \"avg\": 38214.26587623755,\n      \"last\": 73538.04019021988,\n      \"last-5-avg\": 68697.05578045845,\n      \"last-10-avg\": 62623.982934093474\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fdb7b13c0000000473fdbc89980000000473fdc0f1500000000473fdbeee7e0000000473fdc2bb3c0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fdc2cdda0000000473fdcfc4480000000473fdc847b80000000473fdcbd2f60000000473fdc377660000000473fdb7b13c0000000473fdbc89980000000473fdc0f1500000000473fdbeee7e0000000473fdc2bb3c0000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe3c9b5e0000000473fe3667f40000000473fe30e3aa0000000473fe35dc300000000473fe2b06a20000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe2c01460000000473fe21d5040000000473fe27de880000000473fe22ad920000000473fe2d7c540000000473fe3c9b5e0000000473fe3667f40000000473fe30e3aa0000000473fe35dc300000000473fe2b06a20000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe9a343c0000000473fe83520c0000000473fe6ab1ca0000000473fe771cf40000000473fe4dc9d00000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe4fe5880000000473fe1c52d60000000473fe3ffd760000000473fe21031e0000000473fe5b5e6a0000000473fe9a343c0000000473fe83520c0000000473fe6ab1ca0000000473fe771cf40000000473fe4dc9d00000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe2440a20000000473fe1970fc0000000473fe0efb980000000473fe15b85c0000000473fe0395880000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe04c25e0000000473fde399ec0000000473fdfc33500000000473fde6d0320000000473fe08ad220000000473fe2440a20000000473fe1970fc0000000473fe0efb980000000473fe15b85c0000000473fe0395880000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a3021daf6800004740a2ed063d9800004740a2fa93262000004740a2f67289d000004740a2d514fbe00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a3058f2ce000004740a31b0adaa000004740a2f9de986800004740a2f8c4836800004740a302ff9f9000004740a3021daf6800004740a2ed063d9800004740a2fa93262000004740a2f67289d000004740a2d514fbe00000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740ef2d0f3aa680004740f02defcf4000004740f0c5c4687100004740f15d77fcbf80004740f1f420a49e8000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e93be2865000004740ea6d9333fa00004740eb9d311d8080004740ecccbd65b700004740edfced5fb000004740ef2d0f3aa680004740f02defcf4000004740f0c5c4687100004740f15d77fcbf80004740f1f420a49e8000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740ef2d0f3aa680004740f02defcf4000004740f0c5c4687100004740f15d77fcbf80004740f1f420a49e8000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e93be2865000004740ea6d9333fa00004740eb9d311d8080004740ecccbd65b700004740edfced5fb000004740ef2d0f3aa680004740f02defcf4000004740f0c5c4687100004740f15d77fcbf80004740f1f420a49e8000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657876857.7282114,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_6706d53c_18___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=8.726e-07,weight_decay=0.0094284_2022-07-15_17-20-43\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"a9c207c4\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.6017570662606394e-06,\n    \"weight_decay\": 0.006286740635855888,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.6017570662606394e-06,\n    \"weight_decay\": 0.006286740635855888,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"19___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.6018e-06,weight_decay=0.0062867\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"trial_id\": \"a9c207c4\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"start_time\": 1657952832.5677545,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_a9c207c4_19___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.6018e-06,weight_decay=0.0062867_2022-07-16_13-46-39\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_a9c207c4_19___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.6018e-06,weight_decay=0.0062867_2022-07-16_13-46-39/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11318, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11318, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 575, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 321, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 401, in ff_chunk\\n    ffn_output = self.activation(ffn_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/activations.py\\\", line 34, in forward\\n    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\\nRuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 15.78 GiB total capacity; 14.10 GiB already allocated; 63.50 MiB free; 14.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"53e8307a\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 2.3974671018783985e-06,\n    \"weight_decay\": 0.004925981378922703,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 2.3974671018783985e-06,\n    \"weight_decay\": 0.004925981378922703,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"20___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.3975e-06,weight_decay=0.004926\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.4353266656398773,\n    \"validation_0_f1\": 0.6100770235061646,\n    \"validation_1_f1\": 0.0,\n    \"validation_2_f1\": 0.7667722702026367,\n    \"validation_mean\": 0.5551985502243042,\n    \"time_this_iter_s\": 2430.8554241657257,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 5,\n    \"trial_id\": \"53e8307a\",\n    \"experiment_id\": \"487c9af8803e4e0ab3486f7b8b4514cd\",\n    \"date\": \"2022-07-16_17-50-04\",\n    \"timestamp\": 1657965004,\n    \"time_total_s\": 12152.646223545074,\n    \"pid\": 11328,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 2.3974671018783985e-06,\n      \"weight_decay\": 0.004925981378922703,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 12152.646223545074,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 5,\n    \"experiment_tag\": \"20___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.3975e-06,weight_decay=0.004926\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657965004.3539193,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.46835511922836304,\n      \"min\": 0.4224204421043396,\n      \"avg\": 0.43896958231925964,\n      \"last\": 0.4353266656398773,\n      \"last-5-avg\": 0.43896958231925964,\n      \"last-10-avg\": 0.43896958231925964\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.6319881081581116,\n      \"min\": 0.5106989741325378,\n      \"avg\": 0.5955782055854798,\n      \"last\": 0.6100770235061646,\n      \"last-5-avg\": 0.5955782055854797,\n      \"last-10-avg\": 0.5955782055854797\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.8370236754417419,\n      \"min\": 0.0009088843362405896,\n      \"avg\": 0.6171946114161984,\n      \"last\": 0.7667722702026367,\n      \"last-5-avg\": 0.6171946114161984,\n      \"last-10-avg\": 0.6171946114161984\n    },\n    \"validation_mean\": {\n      \"max\": 0.5908499956130981,\n      \"min\": 0.34251394867897034,\n      \"avg\": 0.5179251849651337,\n      \"last\": 0.5551985502243042,\n      \"last-5-avg\": 0.5179251849651336,\n      \"last-10-avg\": 0.5179251849651336\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2437.5110852718353,\n      \"min\": 2427.747947692871,\n      \"avg\": 2430.529244709015,\n      \"last\": 2430.8554241657257,\n      \"last-5-avg\": 2430.529244709015,\n      \"last-10-avg\": 2430.529244709015\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 5,\n      \"min\": 1,\n      \"avg\": 3.0,\n      \"last\": 5,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 3.0\n    },\n    \"time_total_s\": {\n      \"max\": 12152.646223545074,\n      \"min\": 2437.5110852718353,\n      \"avg\": 7294.4474001407625,\n      \"last\": 12152.646223545074,\n      \"last-5-avg\": 7294.4474001407625,\n      \"last-10-avg\": 7294.4474001407625\n    },\n    \"time_since_restore\": {\n      \"max\": 12152.646223545074,\n      \"min\": 2437.5110852718353,\n      \"avg\": 7294.4474001407625,\n      \"last\": 12152.646223545074,\n      \"last-5-avg\": 7294.4474001407625,\n      \"last-10-avg\": 7294.4474001407625\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 5,\n      \"min\": 1,\n      \"avg\": 3.0,\n      \"last\": 5,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 3.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fddf987c0000000473fdc548ee0000000473fdb44f8a0000000473fdb08efc0000000473fdbdc6460000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fddf987c0000000473fdc548ee0000000473fdb44f8a0000000473fdb08efc0000000473fdbdc6460000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe057a560000000473fe2fd2080000000473fe4393f20000000473fe4371ce0000000473fe385c040000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe057a560000000473fe2fd2080000000473fe4393f20000000473fe4371ce0000000473fe385c040000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f4dc84640000000473fe595c0c0000000473fe9d0cbe0000000473feac8e5e0000000473fe8896600000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f4dc84640000000473fe595c0c0000000473fe9d0cbe0000000473feac8e5e0000000473fe8896600000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd5ebbfa0000000473fe09bbe20000000473fe2a02b40000000473fe2e83e40000000473fe1c42fc0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd5ebbfa0000000473fe09bbe20000000473fe2a02b40000000473fe2e83e40000000473fe1c42fc0000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a30b05acf800004740a2f9784c1800004740a2f797f79800004740a2f77ef30000004740a2fdb5fa280000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a30b05acf800004740a2f9784c1800004740a2f797f79800004740a2f77ef30000004740a2fdb5fa280000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b034b044b05652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b05652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a30b05acf800004740b3023efc8800004740bc7e0af85400004740c2fce538ea00004740c7bc52b7740000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a30b05acf800004740b3023efc8800004740bc7e0af85400004740c2fce538ea00004740c7bc52b7740000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a30b05acf800004740b3023efc8800004740bc7e0af85400004740c2fce538ea00004740c7bc52b7740000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a30b05acf800004740b3023efc8800004740bc7e0af85400004740c2fce538ea00004740c7bc52b7740000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b034b044b05652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b05652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1657952847.493939,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_53e8307a_20___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.3975e-06,weight_decay=0.004926_2022-07-16_14-27-12\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_insufficient_resources_manager": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "8005958c000000000000008c277261792e74756e652e696e73756666696369656e745f7265736f75726365735f6d616e61676572948c1c496e73756666696369656e745265736f75726365734d616e616765729493942981947d94288c185f6e6f5f72756e6e696e675f747269616c735f73696e63659447412491d5b3e8093e8c0f5f6c6173745f747269616c5f6e756d944b1475622e"
    },
    "_max_pending_trials": 1,
    "_metric": null,
    "_total_time": 694252.9453783035,
    "_iteration": 644192,
    "_has_errored": true,
    "_fail_fast": false,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_updated_queue": false,
    "_result_wait_time": 1,
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "/home/xwm/DeepSVFilter/code/tune_lr_asha",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059527000000000000008c107261792e74756e652e73746f70706572948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": true,
    "checkpoint_file": "/home/xwm/DeepSVFilter/code/tune_lr_asha/experiment_state-2022-07-10_10-08-15.json",
    "_session_str": "2022-07-10_10-08-15",
    "_start_time": 1657418895.4864109,
    "_last_checkpoint_time": -Infinity,
    "_checkpoint_period": "auto",
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1657418895.4864109,
    "timestamp": 1657966968.908391
  }
}