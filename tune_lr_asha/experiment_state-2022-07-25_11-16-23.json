{
  "checkpoints": [
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"24f3f020\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.8343467758600695e-06,\n    \"weight_decay\": 0.002179910296938443,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.8343467758600695e-06,\n    \"weight_decay\": 0.002179910296938443,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"2___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.8343e-06,weight_decay=0.0021799\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.47088149189949036,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.487765371799469,\n    \"validation_2_f1\": 0.0,\n    \"validation_mean\": 0.3225460946559906,\n    \"time_this_iter_s\": 2420.716032743454,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"24f3f020\",\n    \"experiment_id\": \"09876252994a4100b4fed3bbd5658fd2\",\n    \"date\": \"2022-07-11_08-26-06\",\n    \"timestamp\": 1657499166,\n    \"time_total_s\": 2420.716032743454,\n    \"pid\": 11320,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 1.8343467758600695e-06,\n      \"weight_decay\": 0.002179910296938443,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 2420.716032743454,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"2___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.8343e-06,weight_decay=0.0021799\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657499166.4697063,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.47088149189949036,\n      \"min\": 0.35847583413124084,\n      \"avg\": 0.47088149189949036,\n      \"last\": 0.47088149189949036,\n      \"last-5-avg\": 0.4013611912727356,\n      \"last-10-avg\": 0.3885276556015015\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.8865683674812317,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.6547798871994018,\n      \"last-10-avg\": 0.7526684463024139\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.8296346664428711,\n      \"min\": 0.487765371799469,\n      \"avg\": 0.487765371799469,\n      \"last\": 0.487765371799469,\n      \"last-5-avg\": 0.696799898147583,\n      \"last-10-avg\": 0.7283902764320374\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.8300384879112244,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.6119373440742493,\n      \"last-10-avg\": 0.6883790850639343\n    },\n    \"validation_mean\": {\n      \"max\": 0.84194016456604,\n      \"min\": 0.3225460946559906,\n      \"avg\": 0.3225460946559906,\n      \"last\": 0.3225460946559906,\n      \"last-5-avg\": 0.6864662230014801,\n      \"last-10-avg\": 0.740693137049675\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2812.2815260887146,\n      \"min\": 2420.716032743454,\n      \"avg\": 2420.716032743454,\n      \"last\": 2420.716032743454,\n      \"last-5-avg\": 2559.7985088348387,\n      \"last-10-avg\": 2602.672433233261\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 1.0,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 29,\n      \"min\": 1,\n      \"avg\": 1.0,\n      \"last\": 1,\n      \"last-5-avg\": 22.2,\n      \"last-10-avg\": 22.6\n    },\n    \"time_total_s\": {\n      \"max\": 74661.43902373314,\n      \"min\": 2420.716032743454,\n      \"avg\": 2420.716032743454,\n      \"last\": 2420.716032743454,\n      \"last-5-avg\": 57156.64023008347,\n      \"last-10-avg\": 58017.18895478248\n    },\n    \"time_since_restore\": {\n      \"max\": 74661.43902373314,\n      \"min\": 2420.716032743454,\n      \"avg\": 2420.716032743454,\n      \"last\": 2420.716032743454,\n      \"last-5-avg\": 57156.64023008347,\n      \"last-10-avg\": 58017.18895478248\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 29,\n      \"min\": 1,\n      \"avg\": 1.0,\n      \"last\": 1,\n      \"last-5-avg\": 22.2,\n      \"last-10-avg\": 22.6\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd6f144a0000000473fd8b37880000000473fd94f8740000000473fd95851c0000000473fde22ec20000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd7630420000000473fd90b5c80000000473fd846f3e0000000473fd78328a0000000473fd8005fa0000000473fd6f144a0000000473fd8b37880000000473fd94f8740000000473fd95851c0000000473fde22ec20000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fec3da140000000473feb142dc0000000473fe847eb60000000473fe92a0e60000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473febe720a0000000473fea776fa0000000473fea490080000000473febe3b3e0000000473feb8b8c00000000473fec3da140000000473feb142dc0000000473fe847eb60000000473fe92a0e60000000470000000000000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fea8c5e00000000473fe6e6a7c0000000473fe7aa7600000000473fe6c3aaa0000000473fdf378c40000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe9f85160000000473fe5d90560000000473fe7fc4900000000473fe9650660000000473fe86628a0000000473fea8c5e00000000473fe6e6a7c0000000473fe7aa7600000000473fe6c3aaa0000000473fdf378c40000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe9a3dfa0000000473fe5c78a00000000473fea8face0000000473fe7eddda0000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe9c8c7c0000000473fe2e8aae0000000473fe9ff9700000000473fea53e800000000473fe95a1e00000000473fe9a3dfa0000000473fe5c78a00000000473fea8face0000000473fe7eddda0000000470000000000000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473feaf12c80000000473fe810c3e0000000473fe8af5400000000473fe7d21780000000473fd4a49860000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473feaa2d520000000473fe6b62ec0000000473fe979c320000000473fea9aaf60000000473fe9c27680000000473feaf12c80000000473fe810c3e0000000473fe8af5400000000473fe7d21780000000473fd4a49860000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a58c1543a000004740a39882bf6000004740a401d8b19000004740a3ee1cde5800004740a2e96e9bd80000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a40ec5db0000004740a428d6c8f800004740a451e6724000004740a4de3275e800004740a5efc120d000004740a58c1543a000004740a39882bf6000004740a401d8b19000004740a3ee1cde5800004740a2e96e9bd80000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b01652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740f05e1343c380004740f0fad759be80004740f19ae61f4b00004740f23a57063dc0004740a2e96e9bd80000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740ea2eda262e00004740eb716792bd80004740ecb685f9e180004740ee0469214000004740ef6365334d00004740f05e1343c380004740f0fad759be80004740f19ae61f4b00004740f23a57063dc0004740a2e96e9bd80000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740f05e1343c380004740f0fad759be80004740f19ae61f4b00004740f23a57063dc0004740a2e96e9bd80000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740ea2eda262e00004740eb716792bd80004740ecb685f9e180004740ee0469214000004740ef6365334d00004740f05e1343c380004740f0fad759be80004740f19ae61f4b00004740f23a57063dc0004740a2e96e9bd80000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b01652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657282309.541766,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_24f3f020_2___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.8343e-06,weight_decay=0.0021799_2022-07-08_20-11-49\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_24f3f020_2___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.8343e-06,weight_decay=0.0021799_2022-07-08_20-11-49/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11321, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11321, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 575, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 321, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 401, in ff_chunk\\n    ffn_output = self.activation(ffn_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/activations.py\\\", line 34, in forward\\n    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\\nRuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 15.78 GiB total capacity; 14.10 GiB already allocated; 71.50 MiB free; 14.28 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"ab22d412\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.233068551621429e-07,\n    \"weight_decay\": 0.002491094396520254,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.233068551621429e-07,\n    \"weight_decay\": 0.002491094396520254,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"6___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.2331e-07,weight_decay=0.0024911\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.4726104438304901,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.487765371799469,\n    \"validation_2_f1\": 0.0,\n    \"validation_mean\": 0.3225460946559906,\n    \"time_this_iter_s\": 2524.3199651241302,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"ab22d412\",\n    \"experiment_id\": \"30e84f779eea4ab5b5d14b098d41d685\",\n    \"date\": \"2022-07-12_05-36-56\",\n    \"timestamp\": 1657575416,\n    \"time_total_s\": 2524.3199651241302,\n    \"pid\": 11331,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 1.233068551621429e-07,\n      \"weight_decay\": 0.002491094396520254,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 2524.3199651241302,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"6___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.2331e-07,weight_decay=0.0024911\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657575416.6892147,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.4726104438304901,\n      \"min\": 0.4726104438304901,\n      \"avg\": 0.4726104438304901,\n      \"last\": 0.4726104438304901,\n      \"last-5-avg\": 0.4726104438304901,\n      \"last-10-avg\": 0.4726104438304901\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.487765371799469,\n      \"min\": 0.487765371799469,\n      \"avg\": 0.487765371799469,\n      \"last\": 0.487765371799469,\n      \"last-5-avg\": 0.487765371799469,\n      \"last-10-avg\": 0.487765371799469\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_mean\": {\n      \"max\": 0.3225460946559906,\n      \"min\": 0.3225460946559906,\n      \"avg\": 0.3225460946559906,\n      \"last\": 0.3225460946559906,\n      \"last-5-avg\": 0.3225460946559906,\n      \"last-10-avg\": 0.3225460946559906\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2524.3199651241302,\n      \"min\": 2524.3199651241302,\n      \"avg\": 2524.3199651241302,\n      \"last\": 2524.3199651241302,\n      \"last-5-avg\": 2524.3199651241302,\n      \"last-10-avg\": 2524.3199651241302\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 2524.3199651241302,\n      \"min\": 2524.3199651241302,\n      \"avg\": 2524.3199651241302,\n      \"last\": 2524.3199651241302,\n      \"last-5-avg\": 2524.3199651241302,\n      \"last-10-avg\": 2524.3199651241302\n    },\n    \"time_since_restore\": {\n      \"max\": 2524.3199651241302,\n      \"min\": 2524.3199651241302,\n      \"avg\": 2524.3199651241302,\n      \"last\": 2524.3199651241302,\n      \"last-5-avg\": 2524.3199651241302,\n      \"last-10-avg\": 2524.3199651241302\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fde3f3fe0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fde3f3fe0000000612e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294470000000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294470000000000000000612e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fdf378c40000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fdf378c40000000612e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294470000000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294470000000000000000612e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd4a49860000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd4a49860000000612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a3b8a3d2780000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a3b8a3d2780000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a3b8a3d2780000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a3b8a3d2780000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a3b8a3d2780000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a3b8a3d2780000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657572888.2478175,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_ab22d412_6___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.2331e-07,weight_decay=0.0024911_2022-07-12_04-54-34\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"250b04f4\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.013895369498714e-06,\n    \"weight_decay\": 0.009334692901793855,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.013895369498714e-06,\n    \"weight_decay\": 0.009334692901793855,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"3___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.0139e-06,weight_decay=0.0093347\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.47109079360961914,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.4874153733253479,\n    \"validation_2_f1\": 0.0,\n    \"validation_mean\": 0.32224008440971375,\n    \"time_this_iter_s\": 2436.0184683799744,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"250b04f4\",\n    \"experiment_id\": \"2cc0f0a73b494d439f6b9d8c50ee99bb\",\n    \"date\": \"2022-07-11_07-45-29\",\n    \"timestamp\": 1657496729,\n    \"time_total_s\": 2436.0184683799744,\n    \"pid\": 11321,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 1.013895369498714e-06,\n      \"weight_decay\": 0.009334692901793855,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 2436.0184683799744,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"3___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.0139e-06,weight_decay=0.0093347\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657496729.822426,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.47109079360961914,\n      \"min\": 0.47109079360961914,\n      \"avg\": 0.47109079360961914,\n      \"last\": 0.47109079360961914,\n      \"last-5-avg\": 0.47109079360961914,\n      \"last-10-avg\": 0.47109079360961914\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.4874153733253479,\n      \"min\": 0.4874153733253479,\n      \"avg\": 0.4874153733253479,\n      \"last\": 0.4874153733253479,\n      \"last-5-avg\": 0.4874153733253479,\n      \"last-10-avg\": 0.4874153733253479\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_mean\": {\n      \"max\": 0.32224008440971375,\n      \"min\": 0.32224008440971375,\n      \"avg\": 0.32224008440971375,\n      \"last\": 0.32224008440971375,\n      \"last-5-avg\": 0.32224008440971375,\n      \"last-10-avg\": 0.32224008440971375\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2436.0184683799744,\n      \"min\": 2436.0184683799744,\n      \"avg\": 2436.0184683799744,\n      \"last\": 2436.0184683799744,\n      \"last-5-avg\": 2436.0184683799744,\n      \"last-10-avg\": 2436.0184683799744\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 2436.0184683799744,\n      \"min\": 2436.0184683799744,\n      \"avg\": 2436.0184683799744,\n      \"last\": 2436.0184683799744,\n      \"last-5-avg\": 2436.0184683799744,\n      \"last-10-avg\": 2436.0184683799744\n    },\n    \"time_since_restore\": {\n      \"max\": 2436.0184683799744,\n      \"min\": 2436.0184683799744,\n      \"avg\": 2436.0184683799744,\n      \"last\": 2436.0184683799744,\n      \"last-5-avg\": 2436.0184683799744,\n      \"last-10-avg\": 2436.0184683799744\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fde265a00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fde265a00000000612e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294470000000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294470000000000000000612e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fdf31d040000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fdf31d040000000612e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294470000000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294470000000000000000612e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd49f94e0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd49f94e0000000612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a3080974b00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a3080974b00000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a3080974b00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a3080974b00000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a3080974b00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a3080974b00000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657349933.7987325,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_250b04f4_3___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.0139e-06,weight_decay=0.0093347_2022-07-08_20-11-49\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_250b04f4_3___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.0139e-06,weight_decay=0.0093347_2022-07-08_20-11-49/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1765, in get\\n    raise value\\nray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\\n\\tclass_name: ImplicitFunc\\n\\tactor_id: 94abf17711ff8973818e7afb01000000\\n\\tpid: 63503\\n\\tnamespace: b7dc3d4e-627b-4541-a953-e8e501c3c70e\\n\\tip: 192.168.249.74\\nThe actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR_EXIT\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"96a34b92\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 4.468907617864363e-07,\n    \"weight_decay\": 7.628697887825164e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 4.468907617864363e-07,\n    \"weight_decay\": 7.628697887825164e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"7___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=4.4689e-07,weight_decay=7.6287e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.4166012704372406,\n    \"validation_0_f1\": 0.682170569896698,\n    \"validation_1_f1\": 0.5429543256759644,\n    \"validation_2_f1\": 0.607559084892273,\n    \"validation_mean\": 0.6280314922332764,\n    \"time_this_iter_s\": 2437.690881729126,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"96a34b92\",\n    \"experiment_id\": \"09e72ee8cfb741a8aa18b84afae7a477\",\n    \"date\": \"2022-07-14_00-07-04\",\n    \"timestamp\": 1657728424,\n    \"time_total_s\": 74893.99710822105,\n    \"pid\": 11324,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 4.468907617864363e-07,\n      \"weight_decay\": 7.628697887825164e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 74893.99710822105,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"experiment_tag\": \"7___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=4.4689e-07,weight_decay=7.6287e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657728424.455653,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.45121046900749207,\n      \"min\": 0.34159454703330994,\n      \"avg\": 0.40252707401911403,\n      \"last\": 0.4166012704372406,\n      \"last-5-avg\": 0.3797976016998291,\n      \"last-10-avg\": 0.37703233063220976\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.844162106513977,\n      \"min\": 0.0,\n      \"avg\": 0.4468474555857634,\n      \"last\": 0.682170569896698,\n      \"last-5-avg\": 0.7565233588218689,\n      \"last-10-avg\": 0.7650359869003296\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.8191356658935547,\n      \"min\": 0.47112154960632324,\n      \"avg\": 0.6321896612644193,\n      \"last\": 0.5429543256759644,\n      \"last-5-avg\": 0.6787929654121398,\n      \"last-10-avg\": 0.6964899778366089\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.8299999833106995,\n      \"min\": 0.5394543409347534,\n      \"avg\": 0.6966861546039578,\n      \"last\": 0.607559084892273,\n      \"last-5-avg\": 0.6988261699676513,\n      \"last-10-avg\": 0.689971512556076\n    },\n    \"validation_mean\": {\n      \"max\": 0.8311529159545898,\n      \"min\": 0.4423533082008362,\n      \"avg\": 0.631425803899765,\n      \"last\": 0.6280314922332764,\n      \"last-5-avg\": 0.7204957485198975,\n      \"last-10-avg\": 0.7265396595001221\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2802.912791490555,\n      \"min\": 2419.234338760376,\n      \"avg\": 2496.466570274034,\n      \"last\": 2437.690881729126,\n      \"last-5-avg\": 2448.2226648807527,\n      \"last-10-avg\": 2449.228201889992\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.03333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 74893.99710822105,\n      \"min\": 2802.912791490555,\n      \"avg\": 39202.12050584952,\n      \"last\": 74893.99710822105,\n      \"last-5-avg\": 70009.70852823257,\n      \"last-10-avg\": 63889.20799431801\n    },\n    \"time_since_restore\": {\n      \"max\": 74893.99710822105,\n      \"min\": 2802.912791490555,\n      \"avg\": 39202.12050584952,\n      \"last\": 74893.99710822105,\n      \"last-5-avg\": 70009.70852823257,\n      \"last-10-avg\": 63889.20799431801\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd5dcaf60000000473fd7593860000000473fda44a6a0000000473fd764de40000000473fdaa99860000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd98b1a40000000473fd645b5e0000000473fd7a0d480000000473fd8fee740000000473fd7536940000000473fd5dcaf60000000473fd7593860000000473fda44a6a0000000473fd764de40000000473fdaa99860000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473feabcbf80000000473fe93e0da0000000473fe5e1b060000000473fe95a5d80000000473fe5d45760000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe67d1000000000473feb036040000000473fe904eb60000000473fe75fdfc0000000473fe9df51c0000000473feabcbf80000000473fe93e0da0000000473fe5e1b060000000473fe95a5d80000000473fe5d45760000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe9452840000000473fe80b1360000000473fe21757e0000000473fe7d3e6e0000000473fe15fe1c0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe4eb6a60000000473fe9cdca40000000473fe7d9d6a0000000473fe33422c0000000473fe87deb60000000473fe9452840000000473fe80b1360000000473fe21757e0000000473fe7d3e6e0000000473fe15fe1c0000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fea31b4c0000000473fe6fc9840000000473fe43b5820000000473fe6f526a0000000473fe3711fc0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe3784e00000000473fe74a8640000000473fe5a552a0000000473fe6eb8fa0000000473fe5a6d560000000473fea31b4c0000000473fe6fc9840000000473fe43b5820000000473fe6f526a0000000473fe3711fc0000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fea225a40000000473fe847eae0000000473fe484a1c0000000473fe83fc520000000473fe418d580000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe554b4e0000000473fe99d7c60000000473fe7c9f1c0000000473fe622e6a0000000473fe85795e0000000473fea225a40000000473fe847eae0000000473fe484a1c0000000473fe83fc520000000473fe418d580000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a3336d554000004740a3372ece0800004740a31e876ca000004740a30db4ba8000004740a30b61bb400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a35bd6e66800004740a33dc3f35000004740a3003b553000004740a2e677fb4000004740a3360834f800004740a3336d554000004740a3372ece0800004740a31e876ca000004740a30db4ba8000004740a30b61bb400000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740efcad31d4900004740f07f230514c0004740f118174079c0004740f1b084e64dc0004740f248dff427c000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e9d1f4506980004740eb05d08f9e80004740ec35d444f180004740ed643bc4a580004740ee979c47f500004740efcad31d4900004740f07f230514c0004740f118174079c0004740f1b084e64dc0004740f248dff427c000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740efcad31d4900004740f07f230514c0004740f118174079c0004740f1b084e64dc0004740f248dff427c000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e9d1f4506980004740eb05d08f9e80004740ec35d444f180004740ed643bc4a580004740ee979c47f500004740efcad31d4900004740f07f230514c0004740f118174079c0004740f1b084e64dc0004740f248dff427c000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657650715.1063342,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_96a34b92_7___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=4.4689e-07,weight_decay=7.6287e-05_2022-07-13_02-31-54\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_96a34b92_7___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=4.4689e-07,weight_decay=7.6287e-05_2022-07-13_02-31-54/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11331, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11331, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 575, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 321, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 401, in ff_chunk\\n    ffn_output = self.activation(ffn_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/activations.py\\\", line 34, in forward\\n    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\\nRuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 15.78 GiB total capacity; 14.10 GiB already allocated; 47.50 MiB free; 14.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"e7dd6060\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 3.670323626327793e-07,\n    \"weight_decay\": 0.0016721244250575062,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 3.670323626327793e-07,\n    \"weight_decay\": 0.0016721244250575062,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"8___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.6703e-07,weight_decay=0.0016721\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.4690552353858948,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.4872596561908722,\n    \"validation_2_f1\": 0.00045651677646674216,\n    \"validation_mean\": 0.3219340443611145,\n    \"time_this_iter_s\": 2788.397177696228,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"e7dd6060\",\n    \"experiment_id\": \"09e72ee8cfb741a8aa18b84afae7a477\",\n    \"date\": \"2022-07-13_03-18-50\",\n    \"timestamp\": 1657653530,\n    \"time_total_s\": 2788.397177696228,\n    \"pid\": 11324,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 3.670323626327793e-07,\n      \"weight_decay\": 0.0016721244250575062,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 2788.397177696228,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"8___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.6703e-07,weight_decay=0.0016721\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657653530.085061,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.4690552353858948,\n      \"min\": 0.4690552353858948,\n      \"avg\": 0.4690552353858948,\n      \"last\": 0.4690552353858948,\n      \"last-5-avg\": 0.4690552353858948,\n      \"last-10-avg\": 0.4690552353858948\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.4872596561908722,\n      \"min\": 0.4872596561908722,\n      \"avg\": 0.4872596561908722,\n      \"last\": 0.4872596561908722,\n      \"last-5-avg\": 0.4872596561908722,\n      \"last-10-avg\": 0.4872596561908722\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.00045651677646674216,\n      \"min\": 0.00045651677646674216,\n      \"avg\": 0.00045651677646674216,\n      \"last\": 0.00045651677646674216,\n      \"last-5-avg\": 0.00045651677646674216,\n      \"last-10-avg\": 0.00045651677646674216\n    },\n    \"validation_mean\": {\n      \"max\": 0.3219340443611145,\n      \"min\": 0.3219340443611145,\n      \"avg\": 0.3219340443611145,\n      \"last\": 0.3219340443611145,\n      \"last-5-avg\": 0.3219340443611145,\n      \"last-10-avg\": 0.3219340443611145\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2788.397177696228,\n      \"min\": 2788.397177696228,\n      \"avg\": 2788.397177696228,\n      \"last\": 2788.397177696228,\n      \"last-5-avg\": 2788.397177696228,\n      \"last-10-avg\": 2788.397177696228\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 2788.397177696228,\n      \"min\": 2788.397177696228,\n      \"avg\": 2788.397177696228,\n      \"last\": 2788.397177696228,\n      \"last-5-avg\": 2788.397177696228,\n      \"last-10-avg\": 2788.397177696228\n    },\n    \"time_since_restore\": {\n      \"max\": 2788.397177696228,\n      \"min\": 2788.397177696228,\n      \"avg\": 2788.397177696228,\n      \"last\": 2788.397177696228,\n      \"last-5-avg\": 2788.397177696228,\n      \"last-10-avg\": 2788.397177696228\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fde050040000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fde050040000000612e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294470000000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294470000000000000000612e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fdf2f4320000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fdf2f4320000000612e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f3deb14a0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f3deb14a0000000612e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd49a9140000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd49a9140000000612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a5c8cb5ae00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a5c8cb5ae00000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a5c8cb5ae00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a5c8cb5ae00000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a5c8cb5ae00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a5c8cb5ae00000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657650735.8813717,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_e7dd6060_8___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.6703e-07,weight_decay=0.0016721_2022-07-13_02-32-15\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"56de27ac\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 3.2959101593437092e-06,\n    \"weight_decay\": 0.0039986995699163065,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 3.2959101593437092e-06,\n    \"weight_decay\": 0.0039986995699163065,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"28___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.2959e-06,weight_decay=0.0039987\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.4087260365486145,\n    \"validation_0_f1\": 0.6964174509048462,\n    \"validation_1_f1\": 0.4286411702632904,\n    \"validation_2_f1\": 0.764845609664917,\n    \"validation_mean\": 0.6522071957588196,\n    \"time_this_iter_s\": 3005.065320253372,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 23,\n    \"trial_id\": \"56de27ac\",\n    \"experiment_id\": \"5c9ead42b63248a5aaaf6b311e161389\",\n    \"date\": \"2022-07-22_17-05-48\",\n    \"timestamp\": 1658480748,\n    \"time_total_s\": 59304.0882332325,\n    \"pid\": 11329,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 3.2959101593437092e-06,\n      \"weight_decay\": 0.0039986995699163065,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 59304.0882332325,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 23,\n    \"experiment_tag\": \"28___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.2959e-06,weight_decay=0.0039987\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1658480748.7324486,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.43422016501426697,\n      \"min\": 0.3262940049171448,\n      \"avg\": 0.3969867695932801,\n      \"last\": 0.4087260365486145,\n      \"last-5-avg\": 0.3835045099258423,\n      \"last-10-avg\": 0.3828200131654739\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.871694028377533,\n      \"min\": 0.6811881065368652,\n      \"avg\": 0.7668874859809873,\n      \"last\": 0.6964174509048462,\n      \"last-5-avg\": 0.744544517993927,\n      \"last-10-avg\": 0.7571247518062592\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.829226016998291,\n      \"min\": 0.3774276375770569,\n      \"avg\": 0.5843286332876785,\n      \"last\": 0.4286411702632904,\n      \"last-5-avg\": 0.5662944853305817,\n      \"last-10-avg\": 0.5861656665802002\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.8842452168464661,\n      \"min\": 0.7052471041679382,\n      \"avg\": 0.8169757360997407,\n      \"last\": 0.764845609664917,\n      \"last-5-avg\": 0.793533730506897,\n      \"last-10-avg\": 0.8073479771614075\n    },\n    \"validation_mean\": {\n      \"max\": 0.8623670935630798,\n      \"min\": 0.6446331739425659,\n      \"avg\": 0.7376302688018135,\n      \"last\": 0.6522071957588196,\n      \"last-5-avg\": 0.7133042693138123,\n      \"last-10-avg\": 0.729079645872116\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3005.065320253372,\n      \"min\": 2414.188983440399,\n      \"avg\": 2578.4386188361955,\n      \"last\": 3005.065320253372,\n      \"last-5-avg\": 2936.7154714107514,\n      \"last-10-avg\": 2780.8346858263017\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 23,\n      \"min\": 1,\n      \"avg\": 12.0,\n      \"last\": 23,\n      \"last-5-avg\": 21.0,\n      \"last-10-avg\": 18.5\n    },\n    \"time_total_s\": {\n      \"max\": 59304.0882332325,\n      \"min\": 2468.1769227981567,\n      \"avg\": 29696.73216421708,\n      \"last\": 59304.0882332325,\n      \"last-5-avg\": 53379.60352692604,\n      \"last-10-avg\": 46228.65793874264\n    },\n    \"time_since_restore\": {\n      \"max\": 59304.0882332325,\n      \"min\": 2468.1769227981567,\n      \"avg\": 29696.73216421708,\n      \"last\": 59304.0882332325,\n      \"last-5-avg\": 53379.60352692604,\n      \"last-10-avg\": 46228.65793874264\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 23,\n      \"min\": 1,\n      \"avg\": 12.0,\n      \"last\": 23,\n      \"last-5-avg\": 21.0,\n      \"last-10-avg\": 18.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd9222240000000473fd7e40540000000473fd7b2d040000000473fd7d72780000000473fda289140000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fda4876e0000000473fdae987c0000000473fd80f7620000000473fd82515a0000000473fd4e20040000000473fd9222240000000473fd7e40540000000473fd7b2d040000000473fd7d72780000000473fda289140000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe75a0000000000473fe859bde0000000473fe8df6e60000000473fe84451a0000000473fe6490d40000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe7354a00000000473fe5cc4b00000000473fe8ffc0c0000000473fe940dd20000000473febe4eae0000000473fe75a0000000000473fe859bde0000000473fe8df6e60000000473fe84451a0000000473fe6490d40000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe019df40000000473fe3f7e240000000473fe53a5460000000473fe397e880000000473fdb6edb60000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fdabe70a0000000473fdeb96780000000473fe5d59000000000473fe3dcc3e0000000473fea890500000000473fe019df40000000473fe3f7e240000000473fe53a5460000000473fe397e880000000473fdb6edb60000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe9647680000000473fe9ec7940000000473fe8c07460000000473fea6c22a0000000473fe8799d80000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473feb1a0d20000000473fe6fe3320000000473feb0f8180000000473fe9ef4fa0000000473fec4bbca0000000473fe9647680000000473fe9ec7940000000473fe8c07460000000473fea6c22a0000000473fe8799d80000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe6210560000000473fe7a31640000000473fe7cbd320000000473fe7b22100000000473fe4dee1a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe64d84c0000000473fe4a0d5c0000000473fe8bf9f80000000473fe7e6c620000000473feb9882e0000000473fe6210560000000473fe7a31640000000473fe7cbd320000000473fe7b22100000000473fe4dee1a0000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a6a37e67b800004740a692144d7000004740a7241b988800004740a6e357dc0000004740a77a2171a80000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a2dc60c27000004740a2e111a26000004740a36666793000004740a6c0a6d34000004740a6a50a4ad000004740a6a37e67b800004740a692144d7000004740a7241b988800004740a6e357dc0000004740a77a2171a80000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b134b144b154b164b17652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b0e4b0f4b104b114b124b134b144b154b164b17652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740e733c83f9480004740e89ce9846b80004740ea0f2b3df400004740eb7d60bbb400004740ecf502d2ce8000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e08ebdc57f00004740e1bccedfa500004740e2f335473800004740e45f3fb46c00004740e5c990591900004740e733c83f9480004740e89ce9846b80004740ea0f2b3df400004740eb7d60bbb400004740ecf502d2ce8000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740e733c83f9480004740e89ce9846b80004740ea0f2b3df400004740eb7d60bbb400004740ecf502d2ce8000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e08ebdc57f00004740e1bccedfa500004740e2f335473800004740e45f3fb46c00004740e5c990591900004740e733c83f9480004740e89ce9846b80004740ea0f2b3df400004740eb7d60bbb400004740ecf502d2ce8000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b134b144b154b164b17652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b0e4b0f4b104b114b124b134b144b154b164b17652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"start_time\": 1658421440.922391,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_56de27ac_28___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.2959e-06,weight_decay=0.0039987_2022-07-22_00-37-20\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_56de27ac_28___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.2959e-06,weight_decay=0.0039987_2022-07-22_00-37-20/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=58513, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=58513, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"<ipython-input-10-eb878204f64d>\\\", line 27, in train_tune\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 321, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 400, in ff_chunk\\n    ffn_output = self.ffn(attention_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/linear.py\\\", line 103, in forward\\n    return F.linear(input, self.weight, self.bias)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/functional.py\\\", line 1848, in linear\\n    return torch._C._nn.linear(input, weight, bias)\\nRuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 15.78 GiB total capacity; 5.53 GiB already allocated; 73.50 MiB free; 5.61 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 11,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"d667232e\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 2.0934952814232196e-07,\n    \"weight_decay\": 0.0022972719454273215,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 2.0934952814232196e-07,\n    \"weight_decay\": 0.0022972719454273215,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"10___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.0935e-07,weight_decay=0.0022973\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.4688817858695984,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.48468321561813354,\n    \"validation_2_f1\": 0.005416384432464838,\n    \"validation_mean\": 0.32048046588897705,\n    \"time_this_iter_s\": 2539.0722539424896,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"d667232e\",\n    \"experiment_id\": \"805b25cbb2ab472790044bed3770f09c\",\n    \"date\": \"2022-07-14_00-49-40\",\n    \"timestamp\": 1657730980,\n    \"time_total_s\": 2539.0722539424896,\n    \"pid\": 11333,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 2.0934952814232196e-07,\n      \"weight_decay\": 0.0022972719454273215,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 2539.0722539424896,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"10___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.0935e-07,weight_decay=0.0022973\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657730980.2475882,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.4688817858695984,\n      \"min\": 0.4688817858695984,\n      \"avg\": 0.4688817858695984,\n      \"last\": 0.4688817858695984,\n      \"last-5-avg\": 0.4688817858695984,\n      \"last-10-avg\": 0.4688817858695984\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.48468321561813354,\n      \"min\": 0.48468321561813354,\n      \"avg\": 0.48468321561813354,\n      \"last\": 0.48468321561813354,\n      \"last-5-avg\": 0.48468321561813354,\n      \"last-10-avg\": 0.48468321561813354\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.005416384432464838,\n      \"min\": 0.005416384432464838,\n      \"avg\": 0.005416384432464838,\n      \"last\": 0.005416384432464838,\n      \"last-5-avg\": 0.005416384432464838,\n      \"last-10-avg\": 0.005416384432464838\n    },\n    \"validation_mean\": {\n      \"max\": 0.32048046588897705,\n      \"min\": 0.32048046588897705,\n      \"avg\": 0.32048046588897705,\n      \"last\": 0.32048046588897705,\n      \"last-5-avg\": 0.32048046588897705,\n      \"last-10-avg\": 0.32048046588897705\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2539.0722539424896,\n      \"min\": 2539.0722539424896,\n      \"avg\": 2539.0722539424896,\n      \"last\": 2539.0722539424896,\n      \"last-5-avg\": 2539.0722539424896,\n      \"last-10-avg\": 2539.0722539424896\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 2539.0722539424896,\n      \"min\": 2539.0722539424896,\n      \"avg\": 2539.0722539424896,\n      \"last\": 2539.0722539424896,\n      \"last-5-avg\": 2539.0722539424896,\n      \"last-10-avg\": 2539.0722539424896\n    },\n    \"time_since_restore\": {\n      \"max\": 2539.0722539424896,\n      \"min\": 2539.0722539424896,\n      \"avg\": 2539.0722539424896,\n      \"last\": 2539.0722539424896,\n      \"last-5-avg\": 2539.0722539424896,\n      \"last-10-avg\": 2539.0722539424896\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fde0228c0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fde0228c0000000612e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294470000000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294470000000000000000612e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fdf050cc0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fdf050cc0000000612e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f762f7da0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f762f7da0000000612e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd482c080000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd482c080000000612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a3d624fe780000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a3d624fe780000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a3d624fe780000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a3d624fe780000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a3d624fe780000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a3d624fe780000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657728437.514692,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_d667232e_10___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.0935e-07,weight_decay=0.0022973_2022-07-14_00-07-04\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"7711ae00\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 3.8640369034523515e-06,\n    \"weight_decay\": 0.0010057824708467515,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 3.8640369034523515e-06,\n    \"weight_decay\": 0.0010057824708467515,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"25___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.864e-06,weight_decay=0.0010058\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.4461907148361206,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.5190520286560059,\n    \"validation_2_f1\": 0.38436001539230347,\n    \"validation_mean\": 0.4022645652294159,\n    \"time_this_iter_s\": 2439.262053966522,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 8,\n    \"trial_id\": \"7711ae00\",\n    \"experiment_id\": \"b97bf8f1c245439da126062e90f08b00\",\n    \"date\": \"2022-07-22_00-36-58\",\n    \"timestamp\": 1658421418,\n    \"time_total_s\": 19479.93019938469,\n    \"pid\": 11311,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 3.8640369034523515e-06,\n      \"weight_decay\": 0.0010057824708467515,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 19479.93019938469,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 8,\n    \"experiment_tag\": \"25___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.864e-06,weight_decay=0.0010058\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1658421418.209679,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.5039063096046448,\n      \"min\": 0.4200187623500824,\n      \"avg\": 0.45728787034749985,\n      \"last\": 0.4461907148361206,\n      \"last-5-avg\": 0.4455924093723297,\n      \"last-10-avg\": 0.45728787034749985\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.5487820506095886,\n      \"min\": 0.4970225691795349,\n      \"avg\": 0.5201226770877837,\n      \"last\": 0.5190520286560059,\n      \"last-5-avg\": 0.523989450931549,\n      \"last-10-avg\": 0.5201226770877838\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.6114367246627808,\n      \"min\": 0.13812154531478882,\n      \"avg\": 0.3751101940870285,\n      \"last\": 0.38436001539230347,\n      \"last-5-avg\": 0.41680664122104644,\n      \"last-10-avg\": 0.3751101940870285\n    },\n    \"validation_mean\": {\n      \"max\": 0.4699716866016388,\n      \"min\": 0.34733378887176514,\n      \"avg\": 0.40411024168133736,\n      \"last\": 0.4022645652294159,\n      \"last-5-avg\": 0.4136638343334198,\n      \"last-10-avg\": 0.40411024168133736\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2441.9778101444244,\n      \"min\": 2429.658526659012,\n      \"avg\": 2434.991274923086,\n      \"last\": 2439.262053966522,\n      \"last-5-avg\": 2435.6400834560395,\n      \"last-10-avg\": 2434.991274923086\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.125,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.125\n    },\n    \"training_iteration\": {\n      \"max\": 8,\n      \"min\": 1,\n      \"avg\": 4.5,\n      \"last\": 8,\n      \"last-5-avg\": 6.0,\n      \"last-10-avg\": 4.5\n    },\n    \"time_total_s\": {\n      \"max\": 19479.93019938469,\n      \"min\": 2431.6653277873993,\n      \"avg\": 10955.34509652853,\n      \"last\": 19479.93019938469,\n      \"last-5-avg\": 14608.774407815934,\n      \"last-10-avg\": 10955.34509652853\n    },\n    \"time_since_restore\": {\n      \"max\": 19479.93019938469,\n      \"min\": 2431.6653277873993,\n      \"avg\": 10955.34509652853,\n      \"last\": 19479.93019938469,\n      \"last-5-avg\": 14608.774407815934,\n      \"last-10-avg\": 10955.34509652853\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 8,\n      \"min\": 1,\n      \"avg\": 4.5,\n      \"last\": 8,\n      \"last-5-avg\": 6.0,\n      \"last-10-avg\": 4.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fdc77ca60000000473fddf98da0000000473fdae19660000000473fdcb59c40000000473fdc8e6380000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fdb8aa820000000473fe0200020000000473fdfc00c40000000473fdc77ca60000000473fddf98da0000000473fdae19660000000473fdcb59c40000000473fdc8e6380000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe0f926a0000000473fe00137a0000000473fe18f9f60000000473fe0b08b00000000473fe09c1300000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe15a6220000000473fdfcf37c0000000473fe00e28e0000000473fe0f926a0000000473fe00137a0000000473fe18f9f60000000473fe0b08b00000000473fe09c1300000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fdf52d720000000473fc80bd6a0000000473fe390e3c0000000473fda4ce820000000473fd8995ac0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe2590780000000473fc1adf780000000473fca4933e0000000473fdf52d720000000473fc80bd6a0000000473fe390e3c0000000473fda4ce820000000473fd8995ac0000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fdb8d3ae0000000473fd6d3a3a0000000473fde140420000000473fda2bc0e0000000473fd9beb3e0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fdd3c6bc0000000473fd63ab780000000473fd7110f00000000473fdb8d3ae0000000473fd6d3a3a0000000473fde140420000000473fda2bc0e0000000473fd9beb3e0000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a313f4a38800004740a2fb512a6800004740a301aaf04000004740a304efb2f800004740a30e862bf00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a2ff54a5d800004740a303a8165800004740a30878e9d000004740a313f4a38800004740a2fb512a6800004740a301aaf04000004740a304efb2f800004740a30e862bf00000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b044b054b064b074b08652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059532000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b08652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c307da926200004740c7c6aedcfc00004740cc8719990c00004740d0a42ac2e500004740d305fb88630000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a2ff54a5d800004740b3017e5e1800004740bc85bad30000004740c307da926200004740c7c6aedcfc00004740cc8719990c00004740d0a42ac2e500004740d305fb88630000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c307da926200004740c7c6aedcfc00004740cc8719990c00004740d0a42ac2e500004740d305fb88630000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a2ff54a5d800004740b3017e5e1800004740bc85bad30000004740c307da926200004740c7c6aedcfc00004740cc8719990c00004740d0a42ac2e500004740d305fb88630000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059532000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b044b054b064b074b08652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059532000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b08652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1658330552.2578046,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_7711ae00_25___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.864e-06,weight_decay=0.0010058_2022-07-20_02-34-46\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_7711ae00_25___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.864e-06,weight_decay=0.0010058_2022-07-20_02-34-46/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11325, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11325, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 575, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 321, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 401, in ff_chunk\\n    ffn_output = self.activation(ffn_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/activations.py\\\", line 34, in forward\\n    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\\nRuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 15.78 GiB total capacity; 14.10 GiB already allocated; 71.50 MiB free; 14.28 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"ea572428\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 5.061064776852951e-06,\n    \"weight_decay\": 0.00023558260747815266,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 5.061064776852951e-06,\n    \"weight_decay\": 0.00023558260747815266,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"21___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=5.0611e-06,weight_decay=0.00023558\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.43774452805519104,\n    \"validation_0_f1\": 0.8111850023269653,\n    \"validation_1_f1\": 0.560745894908905,\n    \"validation_2_f1\": 0.11693894863128662,\n    \"validation_mean\": 0.5869482159614563,\n    \"time_this_iter_s\": 2451.9882802963257,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"ea572428\",\n    \"experiment_id\": \"01cbc16f5a96411c82271289fa5a3081\",\n    \"date\": \"2022-07-19_06-06-01\",\n    \"timestamp\": 1658181961,\n    \"time_total_s\": 81595.36519908905,\n    \"pid\": 11327,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 5.061064776852951e-06,\n      \"weight_decay\": 0.00023558260747815266,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 81595.36519908905,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"experiment_tag\": \"21___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=5.0611e-06,weight_decay=0.00023558\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1658181961.2959313,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.5000848174095154,\n      \"min\": 0.3379453420639038,\n      \"avg\": 0.4115649789571761,\n      \"last\": 0.43774452805519104,\n      \"last-5-avg\": 0.40016159415245056,\n      \"last-10-avg\": 0.39829490184783933\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.888773500919342,\n      \"min\": 0.0,\n      \"avg\": 0.741068215171496,\n      \"last\": 0.8111850023269653,\n      \"last-5-avg\": 0.8562116980552673,\n      \"last-10-avg\": 0.8663516700267792\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.8137102127075195,\n      \"min\": 0.49828463792800903,\n      \"avg\": 0.6425465206305185,\n      \"last\": 0.560745894908905,\n      \"last-5-avg\": 0.6622442841529846,\n      \"last-10-avg\": 0.6679784953594208\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.7566196918487549,\n      \"min\": 0.11693894863128662,\n      \"avg\": 0.34953689277172084,\n      \"last\": 0.11693894863128662,\n      \"last-5-avg\": 0.343771880865097,\n      \"last-10-avg\": 0.35346126556396484\n    },\n    \"validation_mean\": {\n      \"max\": 0.8255680799484253,\n      \"min\": 0.35108256340026855,\n      \"avg\": 0.6355086336533229,\n      \"last\": 0.5869482159614563,\n      \"last-5-avg\": 0.6756789803504943,\n      \"last-10-avg\": 0.6812791645526886\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3287.7224593162537,\n      \"min\": 2413.249736070633,\n      \"avg\": 2719.845506636302,\n      \"last\": 2451.9882802963257,\n      \"last-5-avg\": 2888.5727849960326,\n      \"last-10-avg\": 3006.0375910282137\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.03333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 81595.36519908905,\n      \"min\": 2430.5128240585327,\n      \"avg\": 40190.04883584976,\n      \"last\": 81595.36519908905,\n      \"last-5-avg\": 76191.80253214836,\n      \"last-10-avg\": 68440.51665058135\n    },\n    \"time_since_restore\": {\n      \"max\": 81595.36519908905,\n      \"min\": 2430.5128240585327,\n      \"avg\": 40190.04883584976,\n      \"last\": 81595.36519908905,\n      \"last-5-avg\": 76191.80253214836,\n      \"last-10-avg\": 68440.51665058135\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd7a8dcc0000000473fd96b14a0000000473fda227cc0000000473fd8d2cd20000000473fdc0401a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd93f1a00000000473fd8ec1b80000000473fd970b2e0000000473fda12e180000000473fd92c9c40000000473fd7a8dcc0000000473fd96b14a0000000473fda227cc0000000473fd8d2cd20000000473fdc0401a0000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fec280a40000000473fec16bf20000000473feaee3220000000473febdc38a0000000473fe9f53a40000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473febe4be00000000473febd13420000000473fec70d520000000473fec1d7520000000473febf8dca0000000473fec280a40000000473fec16bf20000000473feaee3220000000473febdc38a0000000473fe9f53a40000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe7b057e0000000473fe5cbdf60000000473fe4791c20000000473fe60e91e0000000473fe1f1a160000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe558f360000000473fe643fce0000000473fe550ece0000000473fe529a860000000473fe5b3c040000000473fe7b057e0000000473fe5cbdf60000000473fe4791c20000000473fe60e91e0000000473fe1f1a160000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe0bfb5c0000000473fd4cd9540000000473fd45e8460000000473fdbda5840000000473fbdefb600000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd9ebba80000000473fd994d0c0000000473fd75ed180000000473fd012cec0000000473fd94321a0000000473fe0bfb5c0000000473fd4cd9540000000473fd45e8460000000473fdbda5840000000473fbdefb600000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe7cf95c0000000473fe5eee1e0000000473fe5065d80000000473fe68eb2e0000000473fe2c847a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe61a2080000000473fe66877e0000000473fe5f707a0000000473fe5355ec0000000473fe6379540000000473fe7cf95c0000000473fe5eee1e0000000473fe5065d80000000473fe68eb2e0000000473fe2c847a0000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a94223de7000004740a81c115b2000004740a696fa3e0800004740a5b890dce800004740a327f9ffe00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a6036b86a800004740a874c9a8d800004740a84bf9eb2000004740a98f65222000004740a9af71e63000004740a94223de7000004740a81c115b2000004740a696fa3e0800004740a5b890dce800004740a327f9ffe00000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740f12f19242b80004740f1eff9af0480004740f2a4b180f4c0004740f3527607dc00004740f3ebb5d7db0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740ea8a1660ab80004740ec1162fb3900004740ed962299eb00004740ef2f18ec0d00004740f06508053800004740f12f19242b80004740f1eff9af0480004740f2a4b180f4c0004740f3527607dc00004740f3ebb5d7db0000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740f12f19242b80004740f1eff9af0480004740f2a4b180f4c0004740f3527607dc00004740f3ebb5d7db0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740ea8a1660ab80004740ec1162fb3900004740ed962299eb00004740ef2f18ec0d00004740f06508053800004740f12f19242b80004740f1eff9af0480004740f2a4b180f4c0004740f3527607dc00004740f3ebb5d7db0000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1658027679.5698478,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_ea572428_21___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=5.0611e-06,weight_decay=0.00023558_2022-07-17_10-34-00\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_ea572428_21___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=5.0611e-06,weight_decay=0.00023558_2022-07-17_10-34-00/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11328, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11328, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 575, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 321, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 401, in ff_chunk\\n    ffn_output = self.activation(ffn_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/activations.py\\\", line 34, in forward\\n    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\\nRuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 15.78 GiB total capacity; 14.10 GiB already allocated; 71.50 MiB free; 14.28 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"20576632\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 2.2677254422654865e-07,\n    \"weight_decay\": 0.006754057226249745,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 2.2677254422654865e-07,\n    \"weight_decay\": 0.006754057226249745,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"1___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.2677e-07,weight_decay=0.0067541\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.4546703100204468,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.0,\n    \"validation_2_f1\": 0.5019769668579102,\n    \"validation_mean\": 0.3350929617881775,\n    \"time_this_iter_s\": 2415.0128824710846,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"20576632\",\n    \"experiment_id\": \"2cc0f0a73b494d439f6b9d8c50ee99bb\",\n    \"date\": \"2022-07-11_07-04-53\",\n    \"timestamp\": 1657494293,\n    \"time_total_s\": 75386.09464716911,\n    \"pid\": 11321,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 2.2677254422654865e-07,\n      \"weight_decay\": 0.006754057226249745,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 75386.09464716911,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"experiment_tag\": \"1___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.2677e-07,weight_decay=0.0067541\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657494293.4915316,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.46927350759506226,\n      \"min\": 0.42689356207847595,\n      \"avg\": 0.4549837052822112,\n      \"last\": 0.4546703100204468,\n      \"last-5-avg\": 0.4370107173919678,\n      \"last-10-avg\": 0.43663200438022615\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.510087788105011,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.5019769668579102,\n      \"min\": 0.0,\n      \"avg\": 0.5019769668579102,\n      \"last\": 0.5019769668579102,\n      \"last-5-avg\": 0.5019769668579102,\n      \"last-10-avg\": 0.5019769668579102\n    },\n    \"validation_mean\": {\n      \"max\": 0.3423609435558319,\n      \"min\": 0.3350929617881775,\n      \"avg\": 0.3350929617881775,\n      \"last\": 0.3350929617881775,\n      \"last-5-avg\": 0.3350929617881775,\n      \"last-10-avg\": 0.3350929617881775\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3167.646394252777,\n      \"min\": 2399.181202173233,\n      \"avg\": 2512.8698215723034,\n      \"last\": 2415.0128824710846,\n      \"last-5-avg\": 2417.787618780136,\n      \"last-10-avg\": 2421.785351371765\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.03333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 75386.09464716911,\n      \"min\": 2426.9280412197113,\n      \"avg\": 40060.12549970943,\n      \"last\": 75386.09464716911,\n      \"last-5-avg\": 70553.65832715035,\n      \"last-10-avg\": 64499.46413378716\n    },\n    \"time_since_restore\": {\n      \"max\": 75386.09464716911,\n      \"min\": 2426.9280412197113,\n      \"avg\": 40060.12549970943,\n      \"last\": 75386.09464716911,\n      \"last-5-avg\": 70553.65832715035,\n      \"last-10-avg\": 64499.46413378716\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fdb523960000000473fdb800a80000000473fdc8a6d40000000473fdb61e860000000473fdd195180000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fdbc9c580000000473fdbecf100000000473fdc3d8020000000473fdc0afd60000000473fdb9aaaa0000000473fdb523960000000473fdb800a80000000473fdc8a6d40000000473fdb61e860000000473fdd195180000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a2ed73490000004740a2e1b921b000004740a2e37e690000004740a2e12ee1a000004740a2de0698880000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a2f83e8d7000004740a2ece3a7a800004740a2f4a2305000004740a2ef8b7fb000004740a2f884ccd000004740a2ed73490000004740a2e1b921b000004740a2e37e690000004740a2e12ee1a000004740a2de0698880000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740f00b7e1b8600004740f0a28be49380004740f139a7d7db80004740f1d0b14ee880004740f267a183acc000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740ea2b8ba03480004740eb5a59daaf00004740ec89a3fdb400004740edb89cb5af00004740eee825027c00004740f00b7e1b8600004740f0a28be49380004740f139a7d7db80004740f1d0b14ee880004740f267a183acc000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740f00b7e1b8600004740f0a28be49380004740f139a7d7db80004740f1d0b14ee880004740f267a183acc000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740ea2b8ba03480004740eb5a59daaf00004740ec89a3fdb400004740edb89cb5af00004740eee825027c00004740f00b7e1b8600004740f0a28be49380004740f139a7d7db80004740f1d0b14ee880004740f267a183acc000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657282301.8731766,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_20576632_1___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.2677e-07,weight_decay=0.0067541_2022-07-08_20-11-41\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_20576632_1___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.2677e-07,weight_decay=0.0067541_2022-07-08_20-11-41/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1765, in get\\n    raise value\\nray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\\n\\tclass_name: ImplicitFunc\\n\\tactor_id: c8b2d3817de6bed6f5db93ef01000000\\n\\tpid: 63487\\n\\tnamespace: b7dc3d4e-627b-4541-a953-e8e501c3c70e\\n\\tip: 192.168.249.74\\nThe actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR_EXIT\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 2,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"ebc57180\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 5.99196511048505e-07,\n    \"weight_decay\": 0.004412881557477912,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 5.99196511048505e-07,\n    \"weight_decay\": 0.004412881557477912,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"14___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=5.992e-07,weight_decay=0.0044129\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.45849886536598206,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.4320257902145386,\n    \"validation_2_f1\": 0.5284755229949951,\n    \"validation_mean\": 0.41741257905960083,\n    \"time_this_iter_s\": 2421.2501735687256,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 16,\n    \"trial_id\": \"ebc57180\",\n    \"experiment_id\": \"b306756d3906481491e03139c611034f\",\n    \"date\": \"2022-07-15_05-32-45\",\n    \"timestamp\": 1657834365,\n    \"time_total_s\": 41464.21819090843,\n    \"pid\": 11319,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 5.99196511048505e-07,\n      \"weight_decay\": 0.004412881557477912,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 41464.21819090843,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 16,\n    \"experiment_tag\": \"14___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=5.992e-07,weight_decay=0.0044129\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657834365.704279,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.47306209802627563,\n      \"min\": 0.4554086923599243,\n      \"avg\": 0.46634782478213305,\n      \"last\": 0.45849886536598206,\n      \"last-5-avg\": 0.46239259243011477,\n      \"last-10-avg\": 0.46252753734588625\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.5044368505477905,\n      \"min\": 0.0,\n      \"avg\": 0.2083735717460513,\n      \"last\": 0.4320257902145386,\n      \"last-5-avg\": 0.34681646823883056,\n      \"last-10-avg\": 0.3333977147936821\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.5381160378456116,\n      \"min\": 0.5019769668579102,\n      \"avg\": 0.5139027684926986,\n      \"last\": 0.5284755229949951,\n      \"last-5-avg\": 0.5198251724243164,\n      \"last-10-avg\": 0.5210582494735718\n    },\n    \"validation_mean\": {\n      \"max\": 0.43845152854919434,\n      \"min\": 0.3350929617881775,\n      \"avg\": 0.37308737076818943,\n      \"last\": 0.41741257905960083,\n      \"last-5-avg\": 0.3962818384170532,\n      \"last-10-avg\": 0.3958840161561966\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2898.445235490799,\n      \"min\": 2418.608295440674,\n      \"avg\": 2591.513636931776,\n      \"last\": 2421.2501735687256,\n      \"last-5-avg\": 2529.457525587082,\n      \"last-10-avg\": 2609.7257070064543\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.0625,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 16,\n      \"min\": 1,\n      \"avg\": 8.5,\n      \"last\": 16,\n      \"last-5-avg\": 14.0,\n      \"last-10-avg\": 11.5\n    },\n    \"time_total_s\": {\n      \"max\": 41464.21819090843,\n      \"min\": 2441.016155719757,\n      \"avg\": 22027.234403282404,\n      \"last\": 41464.21819090843,\n      \"last-5-avg\": 36557.355448150636,\n      \"last-10-avg\": 30027.513799571992\n    },\n    \"time_since_restore\": {\n      \"max\": 41464.21819090843,\n      \"min\": 2441.016155719757,\n      \"avg\": 22027.234403282404,\n      \"last\": 41464.21819090843,\n      \"last-5-avg\": 36557.355448150636,\n      \"last-10-avg\": 30027.513799571992\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 16,\n      \"min\": 1,\n      \"avg\": 8.5,\n      \"last\": 16,\n      \"last-5-avg\": 14.0,\n      \"last-10-avg\": 11.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fdd9ad520000000473fdda76d40000000473fdd933a80000000473fddc9ab00000000473fdd580ba0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fde25af60000000473fdddeb580000000473fdd4ec9a0000000473fdd94b680000000473fdd256a80000000473fdd9ad520000000473fdda76d40000000473fdd933a80000000473fddc9ab00000000473fdd580ba0000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd65d2bc0000000473fd560d700000000473fd6fb26e0000000473fd09bbb60000000473fdba64f80000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fb527f480000000473fcb44a6e0000000473fdcbc51e0000000473fd6735940000000473fe02458c0000000473fd65d2bc0000000473fd560d700000000473fd6fb26e0000000473fd09bbb60000000473fdba64f80000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe0baf9a0000000473fe090f3a0000000473fe095b0e0000000473fe0612660000000473fe0e94580000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe0184540000000473fe06bfcc0000000473fe10af120000000473fe0c99b40000000473fe1383f20000000473fe0baf9a0000000473fe090f3a0000000473fe095b0e0000000473fe0612660000000473fe0e94580000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd9828940000000473fd91d0180000000473fd9647400000000473fd8148680000000473fdab6e340000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd618dfa0000000473fd7b40240000000473fdb19e960000000473fd997d860000000473fdc0f9700000000473fd9828940000000473fd91d0180000000473fd9647400000000473fd8148680000000473fdab6e340000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a4ed0d870800004740a4d0a27ac800004740a3412bb8e800004740a2e537728000004740a2ea8016c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a61c4011c800004740a54ca2ce2000004740a38541949000004740a525c0076000004740a5000bdee000004740a4ed0d870800004740a4d0a27ac800004740a3412bb8e800004740a2e537728000004740a2ea8016c00000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0c4b0d4b0e4b0f4b10652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b074b084b094b0a4b0b4b0c4b0d4b0e4b0f4b10652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740dec1dd3f3900004740e0adf8c74900004740e1e20b82d780004740e3105ef9ff80004740e43f06fb6b8000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740d1c545853a00004740d46ed9defe00004740d6df82119000004740d9843a127c00004740dc243b8e5800004740dec1dd3f3900004740e0adf8c74900004740e1e20b82d780004740e3105ef9ff80004740e43f06fb6b8000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740dec1dd3f3900004740e0adf8c74900004740e1e20b82d780004740e3105ef9ff80004740e43f06fb6b8000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740d1c545853a00004740d46ed9defe00004740d6df82119000004740d9843a127c00004740dc243b8e5800004740dec1dd3f3900004740e0adf8c74900004740e1e20b82d780004740e3105ef9ff80004740e43f06fb6b8000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0c4b0d4b0e4b0f4b10652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b074b084b094b0a4b0b4b0c4b0d4b0e4b0f4b10652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657792897.8130586,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_ebc57180_14___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=5.992e-07,weight_decay=0.0044129_2022-07-14_18-01-37\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"619e954e\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 5.217893466600545e-07,\n    \"weight_decay\": 0.00777584464470708,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 5.217893466600545e-07,\n    \"weight_decay\": 0.00777584464470708,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"4___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=5.2179e-07,weight_decay=0.0077758\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.4506742060184479,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.5311965346336365,\n    \"validation_2_f1\": 0.4833764135837555,\n    \"validation_mean\": 0.4281233251094818,\n    \"time_this_iter_s\": 2506.6739745140076,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"619e954e\",\n    \"experiment_id\": \"09876252994a4100b4fed3bbd5658fd2\",\n    \"date\": \"2022-07-12_04-54-33\",\n    \"timestamp\": 1657572873,\n    \"time_total_s\": 73707.26650834084,\n    \"pid\": 11320,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 5.217893466600545e-07,\n      \"weight_decay\": 0.00777584464470708,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 73707.26650834084,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"experiment_tag\": \"4___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=5.2179e-07,weight_decay=0.0077758\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657572873.9445224,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.47195303440093994,\n      \"min\": 0.4119834899902344,\n      \"avg\": 0.4449638038873672,\n      \"last\": 0.4506742060184479,\n      \"last-5-avg\": 0.4324562311172485,\n      \"last-10-avg\": 0.4260110408067703\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.06328843533992767,\n      \"min\": 0.0,\n      \"avg\": 0.0029460293745311597,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0028861035825684667,\n      \"last-10-avg\": 0.00883808812359348\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.7460684180259705,\n      \"min\": 0.0,\n      \"avg\": 0.3935219476077085,\n      \"last\": 0.5311965346336365,\n      \"last-5-avg\": 0.5609212875366211,\n      \"last-10-avg\": 0.5949211180210113\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.877356231212616,\n      \"min\": 0.3761094808578491,\n      \"avg\": 0.6275786628325778,\n      \"last\": 0.4833764135837555,\n      \"last-5-avg\": 0.631966370344162,\n      \"last-10-avg\": 0.6944386035203933\n    },\n    \"validation_mean\": {\n      \"max\": 0.5963583588600159,\n      \"min\": 0.3350929617881775,\n      \"avg\": 0.4559916327397028,\n      \"last\": 0.4281233251094818,\n      \"last-5-avg\": 0.48730777502059935,\n      \"last-10-avg\": 0.5257822573184967\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2688.5190868377686,\n      \"min\": 2409.0497357845306,\n      \"avg\": 2456.908883611361,\n      \"last\": 2506.6739745140076,\n      \"last-5-avg\": 2520.705794429779,\n      \"last-10-avg\": 2531.845523190498\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.03333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 73707.26650834084,\n      \"min\": 2419.104125022888,\n      \"avg\": 37679.42258053621,\n      \"last\": 73707.26650834084,\n      \"last-5-avg\": 68692.07915563583,\n      \"last-10-avg\": 62288.520645666125\n    },\n    \"time_since_restore\": {\n      \"max\": 73707.26650834084,\n      \"min\": 2419.104125022888,\n      \"avg\": 37679.42258053621,\n      \"last\": 73707.26650834084,\n      \"last-5-avg\": 68692.07915563583,\n      \"last-10-avg\": 62288.520645666125\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fdaaba3a0000000473fda854ee0000000473fdd459660000000473fdb146f00000000473fdcd7d8a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fdab5af00000000473fda6ff140000000473fdaf84260000000473fdb6c8e40000000473fdab864c0000000473fdaaba3a0000000473fda854ee0000000473fdd459660000000473fdb146f00000000473fdcd7d8a0000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f55c49780000000473f89ee0180000000470000000000000000473f3ce55c80000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000473f85d5ebc0000000470000000000000000473fb033abc0000000473f55c49780000000473f89ee0180000000470000000000000000473f3ce55c80000000470000000000000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe269cf60000000473fe3499400000000473fe096ce40000000473fe2759480000000473fe0ff8fe0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe3bdca40000000473fe47a3300000000473fe6516fa0000000473fe1e644a0000000473fe430e8a0000000473fe269cf60000000473fe3499400000000473fe096ce40000000473fe2759480000000473fe0ff8fe0000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe84f4f00000000473fea12e300000000473fd8122d80000000473fe73a3d20000000473fdeefa3a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe9bf8b80000000473fea818280000000473fe67063e0000000473fe67c2840000000473fe7ed7740000000473fe84f4f00000000473fea12e300000000473fd8122d80000000473fe73a3d20000000473fdeefa3a0000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe0da6a60000000473fe20a6160000000473fd98f1220000000473fe0989be0000000473fdb665f60000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe25dbc40000000473fe3155e20000000473fe2962420000000473fe00a5740000000473fe2345f00000000473fe0da6a60000000473fe20a6160000000473fd98f1220000000473fe0989be0000000473fdb665f60000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a3e5dcf48000004740a3eec01c7800004740a3838edd9800004740a38989d3b000004740a3955913300000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a315928e7000004740a34c4b9f5000004740a34d88918000004740a4a569b9b800004740a50109c5c000004740a3e5dcf48000004740a3eec01c7800004740a3838edd9800004740a38989d3b000004740a3955913300000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740ef1455692d80004740f029a0b57a80004740f0c5bd2c6740004740f162097b04c0004740f1feb4439e4000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e8d1f31ee100004740ea06b7d8d600004740eb3b9061ee00004740ec85e6fd8980004740edd5f799e580004740ef1455692d80004740f029a0b57a80004740f0c5bd2c6740004740f162097b04c0004740f1feb4439e4000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740ef1455692d80004740f029a0b57a80004740f0c5bd2c6740004740f162097b04c0004740f1feb4439e4000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e8d1f31ee100004740ea06b7d8d600004740eb3b9061ee00004740ec85e6fd8980004740edd5f799e580004740ef1455692d80004740f029a0b57a80004740f0c5bd2c6740004740f162097b04c0004740f1feb4439e4000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657499166.659991,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_619e954e_4___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=5.2179e-07,weight_decay=0.0077758_2022-07-11_07-45-42\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"c6624f10\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 9.393146909349399e-06,\n    \"weight_decay\": 0.0035167667505115597,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 9.393146909349399e-06,\n    \"weight_decay\": 0.0035167667505115597,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"26___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=9.3931e-06,weight_decay=0.0035168\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.40911203622817993,\n    \"validation_0_f1\": 0.7778149247169495,\n    \"validation_1_f1\": 0.645990788936615,\n    \"validation_2_f1\": 0.4486907422542572,\n    \"validation_mean\": 0.6486114263534546,\n    \"time_this_iter_s\": 2362.1988985538483,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"c6624f10\",\n    \"experiment_id\": \"b97bf8f1c245439da126062e90f08b00\",\n    \"date\": \"2022-07-21_19-12-18\",\n    \"timestamp\": 1658401938,\n    \"time_total_s\": 71339.02326488495,\n    \"pid\": 11311,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 9.393146909349399e-06,\n      \"weight_decay\": 0.0035167667505115597,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 71339.02326488495,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"experiment_tag\": \"26___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=9.3931e-06,weight_decay=0.0035168\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1658401938.0196657,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.4468058943748474,\n      \"min\": 0.3363242745399475,\n      \"avg\": 0.3846097697814305,\n      \"last\": 0.40911203622817993,\n      \"last-5-avg\": 0.38895567059516906,\n      \"last-10-avg\": 0.39214259684085845\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.8608636260032654,\n      \"min\": 0.0,\n      \"avg\": 0.6572007954120633,\n      \"last\": 0.7778149247169495,\n      \"last-5-avg\": 0.7875337719917297,\n      \"last-10-avg\": 0.7765789866447449\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.85417640209198,\n      \"min\": 0.5262236595153809,\n      \"avg\": 0.7173400362332661,\n      \"last\": 0.645990788936615,\n      \"last-5-avg\": 0.7295623540878295,\n      \"last-10-avg\": 0.7021450340747833\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.8755322098731995,\n      \"min\": 0.38703736662864685,\n      \"avg\": 0.6096384187539418,\n      \"last\": 0.4486907422542572,\n      \"last-5-avg\": 0.5112747013568878,\n      \"last-10-avg\": 0.5436035573482514\n    },\n    \"validation_mean\": {\n      \"max\": 0.8328360319137573,\n      \"min\": 0.42009028792381287,\n      \"avg\": 0.6902889281511306,\n      \"last\": 0.6486114263534546,\n      \"last-5-avg\": 0.7027465343475342,\n      \"last-10-avg\": 0.6948205888271332\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2517.6719105243683,\n      \"min\": 2352.050645828247,\n      \"avg\": 2377.96744216283,\n      \"last\": 2362.1988985538483,\n      \"last-5-avg\": 2357.811461544037,\n      \"last-10-avg\": 2356.345769453049\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.03333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 71339.02326488495,\n      \"min\": 2517.6719105243683,\n      \"avg\": 37088.50197017987,\n      \"last\": 71339.02326488495,\n      \"last-5-avg\": 66619.69444932937,\n      \"last-10-avg\": 60728.080456805226\n    },\n    \"time_since_restore\": {\n      \"max\": 71339.02326488495,\n      \"min\": 2517.6719105243683,\n      \"avg\": 37088.50197017987,\n      \"last\": 71339.02326488495,\n      \"last-5-avg\": 66619.69444932937,\n      \"last-10-avg\": 60728.080456805226\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd902ab20000000473fd88ea880000000473fd8c41980000000473fd7f2ee40000000473fda2ee440000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd8b59500000000473fd7ab92e0000000473fda78ab60000000473fda2ab620000000473fd97cdba0000000473fd902ab20000000473fd88ea880000000473fd8c41980000000473fd7f2ee40000000473fda2ee440000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe8b13020000000473feaf4c020000000473fe7da13c0000000473fe99d8200000000473fe8e3dc20000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fead5dda0000000473fe842b340000000473fe7ccf680000000473fe7799180000000473fe820dec0000000473fe8b13020000000473feaf4c020000000473fe7da13c0000000473fe99d8200000000473fe8e3dc20000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe89d2380000000473fe72cae20000000473fe7bd3360000000473fe887e5e0000000473fe4abf4e0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe6313c20000000473fe8992f00000000473fe33b2800000000473fe4cc40c0000000473fe5230500000000473fe89d2380000000473fe72cae20000000473fe7bd3360000000473fe887e5e0000000473fe4abf4e0000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fdb81d580000000473fdefc96c0000000473fe35f2c00000000473fe2d3c100000000473fdcb75960000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe15529c0000000473fe6ec7ae0000000473fde35f4a0000000473fe1c0aa00000000473fe308e820000000473fdb81d580000000473fdefc96c0000000473fe35f2c00000000473fe2d3c100000000473fdcb75960000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe653c940000000473fe6fda160000000473fe6bd13a0000000473fe7a09480000000473fe4c16cc0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe6da8880000000473fe7f48fe0000000473fe46a4f20000000473fe4fed820000000473fe5aef4c0000000473fe653c940000000473fe6fda160000000473fe6bd13a0000000473fe7a09480000000473fe4c16cc0000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a2657a6d4000004740a26784546800004740a269fc273800004740a26ebc988800004740a27465d6080000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a26019ee4000004740a26162818800004740a2649746e800004740a266777ef000004740a27041c9e000004740a2657a6d4000004740a26784546800004740a269fc273800004740a26ebc988800004740a27465d6080000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740ee3a168ff300004740ef608ed53980004740f043974bd680004740f0d70d309ac0004740f16ab05f4b0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e879f3b80b00004740e9a009e02380004740eac653549200004740ebecbacc8100004740ed13bee91f00004740ee3a168ff300004740ef608ed53980004740f043974bd680004740f0d70d309ac0004740f16ab05f4b0000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740ee3a168ff300004740ef608ed53980004740f043974bd680004740f0d70d309ac0004740f16ab05f4b0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e879f3b80b00004740e9a009e02380004740eac653549200004740ebecbacc8100004740ed13bee91f00004740ee3a168ff300004740ef608ed53980004740f043974bd680004740f0d70d309ac0004740f16ab05f4b0000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1658330576.4471688,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_c6624f10_26___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=9.3931e-06,weight_decay=0.0035168_2022-07-20_23-22-32\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"804a98a2\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 2.1279383519243996e-07,\n    \"weight_decay\": 0.0015303410204614764,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 2.1279383519243996e-07,\n    \"weight_decay\": 0.0015303410204614764,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"15___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.1279e-07,weight_decay=0.0015303\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.4693058133125305,\n    \"validation_0_f1\": 0.5110781192779541,\n    \"validation_1_f1\": 0.009411764331161976,\n    \"validation_2_f1\": 0.0,\n    \"validation_mean\": 0.34389105439186096,\n    \"time_this_iter_s\": 2785.524362564087,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 8,\n    \"trial_id\": \"804a98a2\",\n    \"experiment_id\": \"f18001f105174064bc1dbdecd93a9105\",\n    \"date\": \"2022-07-15_17-20-43\",\n    \"timestamp\": 1657876843,\n    \"time_total_s\": 20691.270179986954,\n    \"pid\": 11314,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 2.1279383519243996e-07,\n      \"weight_decay\": 0.0015303410204614764,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 20691.270179986954,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 8,\n    \"experiment_tag\": \"15___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.1279e-07,weight_decay=0.0015303\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657876843.464735,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.4709828197956085,\n      \"min\": 0.4693058133125305,\n      \"avg\": 0.47049930691719055,\n      \"last\": 0.4693058133125305,\n      \"last-5-avg\": 0.4702234208583832,\n      \"last-10-avg\": 0.47049930691719055\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.5110781192779541,\n      \"min\": 0.510087788105011,\n      \"avg\": 0.5102297440171242,\n      \"last\": 0.5110781192779541,\n      \"last-5-avg\": 0.5103149175643921,\n      \"last-10-avg\": 0.5102297440171242\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.009411764331161976,\n      \"min\": 0.0,\n      \"avg\": 0.0013542518354370259,\n      \"last\": 0.009411764331161976,\n      \"last-5-avg\": 0.0021668029366992414,\n      \"last-10-avg\": 0.0013542518354370259\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_mean\": {\n      \"max\": 0.34389105439186096,\n      \"min\": 0.3423609435558319,\n      \"avg\": 0.342580895870924,\n      \"last\": 0.34389105439186096,\n      \"last-5-avg\": 0.34271286725997924,\n      \"last-10-avg\": 0.342580895870924\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2822.3477177619934,\n      \"min\": 2420.1945593357086,\n      \"avg\": 2586.408772498369,\n      \"last\": 2785.524362564087,\n      \"last-5-avg\": 2684.7402155399323,\n      \"last-10-avg\": 2586.408772498369\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.125,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.125\n    },\n    \"training_iteration\": {\n      \"max\": 8,\n      \"min\": 1,\n      \"avg\": 4.5,\n      \"last\": 8,\n      \"last-5-avg\": 6.0,\n      \"last-10-avg\": 4.5\n    },\n    \"time_total_s\": {\n      \"max\": 20691.270179986954,\n      \"min\": 2422.176505088806,\n      \"avg\": 11271.257181107998,\n      \"last\": 20691.270179986954,\n      \"last-5-avg\": 15127.588155412674,\n      \"last-10-avg\": 11271.257181107998\n    },\n    \"time_since_restore\": {\n      \"max\": 20691.270179986954,\n      \"min\": 2422.176505088806,\n      \"avg\": 11271.257181107998,\n      \"last\": 20691.270179986954,\n      \"last-5-avg\": 15127.588155412674,\n      \"last-10-avg\": 11271.257181107998\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 8,\n      \"min\": 1,\n      \"avg\": 4.5,\n      \"last\": 8,\n      \"last-5-avg\": 6.0,\n      \"last-10-avg\": 4.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fde223260000000473fde211e40000000473fde176f60000000473fde14d8a0000000473fde091b40000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fde249520000000473fde2464a0000000473fde239b60000000473fde223260000000473fde211e40000000473fde176f60000000473fde14d8a0000000473fde091b40000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe052a3a0000000473fe052a3a0000000473fe0531d80000000473fe0535a80000000473fe05ac080000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe052a3a0000000473fe052a3a0000000473fe052a3a0000000473fe052a3a0000000473fe052a3a0000000473fe0531d80000000473fe0535a80000000473fe05ac080000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000473f3f130ec0000000473f4f112c00000000473f834679a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000473f3f130ec0000000473f4f112c00000000473f834679a0000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd5e93de0000000473fd5e93de0000000473fd5ea7ec0000000473fd5ebbfa0000000473fd6024fa0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd5e93de0000000473fd5e93de0000000473fd5e93de0000000473fd5e93de0000000473fd5e93de0000000473fd5ea7ec0000000473fd5ebbfa0000000473fd6024fa0000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a2eaa3baf800004740a4277f705000004740a5fd85471000004740a60cb2081000004740a5c30c79400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a2ec5a5ee000004740a2e8639d4800004740a2f265653800004740a2eaa3baf800004740a4277f705000004740a5fd85471000004740a60cb2081000004740a5c30c79400000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b044b054b064b074b08652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059532000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b08652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c2ec71c71600004740c7f651a32a00004740cd75b2f4ee00004740d17c6fbb7900004740d434d14aa10000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a2ec5a5ee000004740b2ea5efe1400004740bc6391b0b000004740c2ec71c71600004740c7f651a32a00004740cd75b2f4ee00004740d17c6fbb7900004740d434d14aa10000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c2ec71c71600004740c7f651a32a00004740cd75b2f4ee00004740d17c6fbb7900004740d434d14aa10000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a2ec5a5ee000004740b2ea5efe1400004740bc6391b0b000004740c2ec71c71600004740c7f651a32a00004740cd75b2f4ee00004740d17c6fbb7900004740d434d14aa10000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059532000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b044b054b064b074b08652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059532000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b08652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657836793.396572,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_804a98a2_15___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.1279e-07,weight_decay=0.0015303_2022-07-15_05-32-45\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_804a98a2_15___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.1279e-07,weight_decay=0.0015303_2022-07-15_05-32-45/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11319, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11319, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 575, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 321, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 401, in ff_chunk\\n    ffn_output = self.activation(ffn_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/activations.py\\\", line 34, in forward\\n    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\\nRuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 15.78 GiB total capacity; 14.10 GiB already allocated; 71.50 MiB free; 14.28 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"53e8307a\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 2.3974671018783985e-06,\n    \"weight_decay\": 0.004925981378922703,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 2.3974671018783985e-06,\n    \"weight_decay\": 0.004925981378922703,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"20___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.3975e-06,weight_decay=0.004926\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.4209493100643158,\n    \"validation_0_f1\": 0.6182647347450256,\n    \"validation_1_f1\": 0.0,\n    \"validation_2_f1\": 0.8096644282341003,\n    \"validation_mean\": 0.573100745677948,\n    \"time_this_iter_s\": 2395.538090467453,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"53e8307a\",\n    \"experiment_id\": \"487c9af8803e4e0ab3486f7b8b4514cd\",\n    \"date\": \"2022-07-17_10-34-00\",\n    \"timestamp\": 1658025240,\n    \"time_total_s\": 72388.50458025932,\n    \"pid\": 11328,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 2.3974671018783985e-06,\n      \"weight_decay\": 0.004925981378922703,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 72388.50458025932,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"experiment_tag\": \"20___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.3975e-06,weight_decay=0.004926\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1658025240.2109442,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.46835511922836304,\n      \"min\": 0.40341001749038696,\n      \"avg\": 0.41752330263455695,\n      \"last\": 0.4209493100643158,\n      \"last-5-avg\": 0.41150715947151184,\n      \"last-10-avg\": 0.412522566318512\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.6696200370788574,\n      \"min\": 0.5106989741325378,\n      \"avg\": 0.6307971914609273,\n      \"last\": 0.6182647347450256,\n      \"last-5-avg\": 0.6326676845550537,\n      \"last-10-avg\": 0.630183857679367\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.9255331754684448,\n      \"min\": 0.0009088843362405896,\n      \"avg\": 0.8266414156532846,\n      \"last\": 0.8096644282341003,\n      \"last-5-avg\": 0.867096221446991,\n      \"last-10-avg\": 0.863325971364975\n    },\n    \"validation_mean\": {\n      \"max\": 0.6390482783317566,\n      \"min\": 0.34251394867897034,\n      \"avg\": 0.5913396050532657,\n      \"last\": 0.573100745677948,\n      \"last-5-avg\": 0.6022798538208007,\n      \"last-10-avg\": 0.6000841498374939\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2437.5110852718353,\n      \"min\": 2385.9026205539703,\n      \"avg\": 2412.9501526753106,\n      \"last\": 2395.538090467453,\n      \"last-5-avg\": 2389.607171583176,\n      \"last-10-avg\": 2397.366280436516\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.03333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 72388.50458025932,\n      \"min\": 2437.5110852718353,\n      \"avg\": 37511.22531824907,\n      \"last\": 72388.50458025932,\n      \"last-5-avg\": 67607.74344434738,\n      \"last-10-avg\": 61624.955148243906\n    },\n    \"time_since_restore\": {\n      \"max\": 72388.50458025932,\n      \"min\": 2437.5110852718353,\n      \"avg\": 37511.22531824907,\n      \"last\": 72388.50458025932,\n      \"last-5-avg\": 67607.74344434738,\n      \"last-10-avg\": 61624.955148243906\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fda27f2e0000000473fdaaa1340000000473fd9ee7ec0000000473fd9fd5060000000473fdaf0d560000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fda7f9460000000473fdb1b4340000000473fdad67d00000000473fd9d17840000000473fda123b00000000473fda27f2e0000000473fdaaa1340000000473fd9ee7ec0000000473fd9fd5060000000473fdaf0d560000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe48b2620000000473fe3ab7320000000473fe49ff840000000473fe49aace0000000473fe3c8d320000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe3ec6340000000473fe397abc0000000473fe3e3d500000000473fe4fca1e0000000473fe40a1200000000473fe48b2620000000473fe3ab7320000000473fe49ff840000000473fe49aace0000000473fe3c8d320000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fec6f4560000000473feae539a0000000473fecb29900000000473feccc6580000000473fe9e8c560000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473feb9112a0000000473fe9a27ae0000000473fea88f100000000473fed674e00000000473fec639a80000000473fec6f4560000000473feae539a0000000473fecb29900000000473feccc6580000000473fe9e8c560000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe3a44320000000473fe2b39900000000473fe3db6a20000000473fe3d34460000000473fe256d760000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe3173f60000000473fe2237320000000473fe298a5e0000000473fe447d6c0000000473fe38e53a0000000473fe3a44320000000473fe2b39900000000473fe3db6a20000000473fe3d34460000000473fe256d760000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a2ae3ba86800004740a2a6060a9000004740a2a8ef042000004740a2a3ce244800004740a2b71380980000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a2ddd2b69000004740a2dfef3a4800004740a2ca44407800004740a2b25e28d000004740a2b8dca50000004740a2ae3ba86800004740a2a6060a9000004740a2a8ef042000004740a2a3ce244800004740a2b71380980000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740eeadf2ba4c80004740efd8531af580004740f08171059bc0004740f1168f76be00004740f1ac4812c2c000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e8d1b81b3d00004740e9ffb70ee180004740eb2c5b52e900004740ec5781357600004740ed830effc600004740eeadf2ba4c80004740efd8531af580004740f08171059bc0004740f1168f76be00004740f1ac4812c2c000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740eeadf2ba4c80004740efd8531af580004740f08171059bc0004740f1168f76be00004740f1ac4812c2c000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e8d1b81b3d00004740e9ffb70ee180004740eb2c5b52e900004740ec5781357600004740ed830effc600004740eeadf2ba4c80004740efd8531af580004740f08171059bc0004740f1168f76be00004740f1ac4812c2c000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657952847.493939,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_53e8307a_20___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.3975e-06,weight_decay=0.004926_2022-07-16_14-27-12\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"3ee0ecb0\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.1511459478982988e-06,\n    \"weight_decay\": 0.008314269807685015,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.1511459478982988e-06,\n    \"weight_decay\": 0.008314269807685015,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"13___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.1511e-06,weight_decay=0.0083143\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.4697227478027344,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.487765371799469,\n    \"validation_2_f1\": 0.0,\n    \"validation_mean\": 0.3225460946559906,\n    \"time_this_iter_s\": 2427.1858723163605,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"3ee0ecb0\",\n    \"experiment_id\": \"b306756d3906481491e03139c611034f\",\n    \"date\": \"2022-07-15_06-13-13\",\n    \"timestamp\": 1657836793,\n    \"time_total_s\": 2427.1858723163605,\n    \"pid\": 11319,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 1.1511459478982988e-06,\n      \"weight_decay\": 0.008314269807685015,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 2427.1858723163605,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"13___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.1511e-06,weight_decay=0.0083143\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657836793.1462183,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.4697227478027344,\n      \"min\": 0.4697227478027344,\n      \"avg\": 0.4697227478027344,\n      \"last\": 0.4697227478027344,\n      \"last-5-avg\": 0.4697227478027344,\n      \"last-10-avg\": 0.4697227478027344\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.487765371799469,\n      \"min\": 0.487765371799469,\n      \"avg\": 0.487765371799469,\n      \"last\": 0.487765371799469,\n      \"last-5-avg\": 0.487765371799469,\n      \"last-10-avg\": 0.487765371799469\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_mean\": {\n      \"max\": 0.3225460946559906,\n      \"min\": 0.3225460946559906,\n      \"avg\": 0.3225460946559906,\n      \"last\": 0.3225460946559906,\n      \"last-5-avg\": 0.3225460946559906,\n      \"last-10-avg\": 0.3225460946559906\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2427.1858723163605,\n      \"min\": 2427.1858723163605,\n      \"avg\": 2427.1858723163605,\n      \"last\": 2427.1858723163605,\n      \"last-5-avg\": 2427.1858723163605,\n      \"last-10-avg\": 2427.1858723163605\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 2427.1858723163605,\n      \"min\": 2427.1858723163605,\n      \"avg\": 2427.1858723163605,\n      \"last\": 2427.1858723163605,\n      \"last-5-avg\": 2427.1858723163605,\n      \"last-10-avg\": 2427.1858723163605\n    },\n    \"time_since_restore\": {\n      \"max\": 2427.1858723163605,\n      \"min\": 2427.1858723163605,\n      \"avg\": 2427.1858723163605,\n      \"last\": 2427.1858723163605,\n      \"last-5-avg\": 2427.1858723163605,\n      \"last-10-avg\": 2427.1858723163605\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fde0ff000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fde0ff000000000612e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294470000000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294470000000000000000612e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fdf378c40000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fdf378c40000000612e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294470000000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294470000000000000000612e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd4a49860000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd4a49860000000612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a2f65f2aa80000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a2f65f2aa80000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a2f65f2aa80000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a2f65f2aa80000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a2f65f2aa80000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a2f65f2aa80000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657792885.0763304,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_3ee0ecb0_13___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.1511e-06,weight_decay=0.0083143_2022-07-14_18-01-24\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_3ee0ecb0_13___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.1511e-06,weight_decay=0.0083143_2022-07-14_18-01-24/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11326, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11326, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 575, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 321, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 401, in ff_chunk\\n    ffn_output = self.activation(ffn_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/activations.py\\\", line 34, in forward\\n    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\\nRuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 15.78 GiB total capacity; 14.02 GiB already allocated; 41.50 MiB free; 14.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"afc6c20c\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 2.172866349809914e-06,\n    \"weight_decay\": 0.005305954879986261,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 2.172866349809914e-06,\n    \"weight_decay\": 0.005305954879986261,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"12___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.1729e-06,weight_decay=0.005306\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.463144451379776,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.5777120590209961,\n    \"validation_2_f1\": 0.3402446508407593,\n    \"validation_mean\": 0.3741106390953064,\n    \"time_this_iter_s\": 2422.7190001010895,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 16,\n    \"trial_id\": \"afc6c20c\",\n    \"experiment_id\": \"65181e1ae0ac4424a9e0f846022b541f\",\n    \"date\": \"2022-07-14_17-20-47\",\n    \"timestamp\": 1657790447,\n    \"time_total_s\": 38876.49648761749,\n    \"pid\": 11326,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 2.172866349809914e-06,\n      \"weight_decay\": 0.005305954879986261,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 38876.49648761749,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 16,\n    \"experiment_tag\": \"12___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.1729e-06,weight_decay=0.005306\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657790447.3175397,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.4821043014526367,\n      \"min\": 0.43376779556274414,\n      \"avg\": 0.46043878048658365,\n      \"last\": 0.463144451379776,\n      \"last-5-avg\": 0.47373597621917723,\n      \"last-10-avg\": 0.4634819686412811\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.7439010739326477,\n      \"min\": 0.008932769298553467,\n      \"avg\": 0.5263009909540415,\n      \"last\": 0.5777120590209961,\n      \"last-5-avg\": 0.5223982989788055,\n      \"last-10-avg\": 0.5632601708173752\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.5075882077217102,\n      \"min\": 0.2209494262933731,\n      \"avg\": 0.3720546765252948,\n      \"last\": 0.3402446508407593,\n      \"last-5-avg\": 0.26990151703357695,\n      \"last-10-avg\": 0.3283973142504692\n    },\n    \"validation_mean\": {\n      \"max\": 0.49797260761260986,\n      \"min\": 0.2960752844810486,\n      \"avg\": 0.3720688913017512,\n      \"last\": 0.3741106390953064,\n      \"last-5-avg\": 0.32459643483161926,\n      \"last-10-avg\": 0.3604161858558655\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2467.1176660060883,\n      \"min\": 2413.826421737671,\n      \"avg\": 2429.7810304760933,\n      \"last\": 2422.7190001010895,\n      \"last-5-avg\": 2418.907300662994,\n      \"last-10-avg\": 2424.2854003190996\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.0625,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 16,\n      \"min\": 1,\n      \"avg\": 8.5,\n      \"last\": 16,\n      \"last-5-avg\": 14.0,\n      \"last-10-avg\": 11.5\n    },\n    \"time_total_s\": {\n      \"max\": 38876.49648761749,\n      \"min\": 2447.518670797348,\n      \"avg\": 20683.772373855114,\n      \"last\": 38876.49648761749,\n      \"last-5-avg\": 34039.66958327293,\n      \"last-10-avg\": 27984.50725121498\n    },\n    \"time_since_restore\": {\n      \"max\": 38876.49648761749,\n      \"min\": 2447.518670797348,\n      \"avg\": 20683.772373855114,\n      \"last\": 38876.49648761749,\n      \"last-5-avg\": 34039.66958327293,\n      \"last-10-avg\": 27984.50725121498\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 16,\n      \"min\": 1,\n      \"avg\": 8.5,\n      \"last\": 16,\n      \"last-5-avg\": 14.0,\n      \"last-10-avg\": 11.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fde251b40000000473fde65af20000000473fde8eb480000000473fdedacc00000000473fdda428a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fdcc657e0000000473fdd80b420000000473fdcecf580000000473fdda0c640000000473fdc33a780000000473fde251b40000000473fde65af20000000473fde8eb480000000473fdedacc00000000473fdda428a0000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fde7da080000000473fe1302d60000000473fdf4e2820000000473fe102bf80000000473fe27c9e00000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe4064560000000473fe07cd780000000473fe4d28e20000000473fe15fdd80000000473fe5f34e40000000473fde7da080000000473fe1302d60000000473fdf4e2820000000473fe102bf80000000473fe27c9e00000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd3513800000000473fcfa32760000000473fcea1dda0000000473fcc481220000000473fd5c69180000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fda07c520000000473fd7ce5320000000473fd789d7c0000000473fd58cfec0000000473fdce159e0000000473fd3513800000000473fcfa32760000000473fcea1dda0000000473fcc481220000000473fd5c69180000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd3f3db60000000473fd4a99be0000000473fd2f2e5c0000000473fd45d25e0000000473fd7f16dc0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fda4d98e0000000473fd6a18020000000473fda823e20000000473fd6691840000000473fdcf13680000000473fd3f3db60000000473fd4a99be0000000473fd2f2e5c0000000473fd45d25e0000000473fd7f16dc0000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a2ec28897000004740a2e816d08800004740a2dfbc151000004740a2dba720c000004740a2ed7020c80000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a3089d0c6000004740a30ea6f24800004740a2ee15031800004740a2e9d09dc000004740a2f978efd800004740a2ec28897000004740a2e816d08800004740a2dfbc151000004740a2dba720c000004740a2ed7020c80000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0c4b0d4b0e4b0f4b10652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b074b084b094b0a4b0b4b0c4b0d4b0e4b0f4b10652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740dc8502819000004740dee2055ba100004740e09efe6f2180004740e1ccb8e12d80004740e2fb8fe33a0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740d0ab7cc00300004740d30d519e4c00004740d56b143eaf00004740d7c84e526700004740da277d706200004740dc8502819000004740dee2055ba100004740e09efe6f2180004740e1ccb8e12d80004740e2fb8fe33a0000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740dc8502819000004740dee2055ba100004740e09efe6f2180004740e1ccb8e12d80004740e2fb8fe33a0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740d0ab7cc00300004740d30d519e4c00004740d56b143eaf00004740d7c84e526700004740da277d706200004740dc8502819000004740dee2055ba100004740e09efe6f2180004740e1ccb8e12d80004740e2fb8fe33a0000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0c4b0d4b0e4b0f4b10652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b074b084b094b0a4b0b4b0c4b0d4b0e4b0f4b10652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657751566.7058783,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_afc6c20c_12___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.1729e-06,weight_decay=0.005306_2022-07-14_06-32-46\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"cf683e4a\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 3.79985740910506e-06,\n    \"weight_decay\": 0.000584397481085676,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 3.79985740910506e-06,\n    \"weight_decay\": 0.000584397481085676,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"24___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.7999e-06,weight_decay=0.0005844\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.3246431052684784,\n    \"validation_0_f1\": 0.8796892762184143,\n    \"validation_1_f1\": 0.8444187641143799,\n    \"validation_2_f1\": 0.8584392070770264,\n    \"validation_mean\": 0.8617550134658813,\n    \"time_this_iter_s\": 2568.1087720394135,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"cf683e4a\",\n    \"experiment_id\": \"b76e735fbe4f4779bcd025e31a560849\",\n    \"date\": \"2022-07-20_02-34-46\",\n    \"timestamp\": 1658255686,\n    \"time_total_s\": 73709.66116952896,\n    \"pid\": 11325,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 3.79985740910506e-06,\n      \"weight_decay\": 0.000584397481085676,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 73709.66116952896,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"experiment_tag\": \"24___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.7999e-06,weight_decay=0.0005844\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1658255686.3919523,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.44453102350234985,\n      \"min\": 0.30100834369659424,\n      \"avg\": 0.3430797020594278,\n      \"last\": 0.3246431052684784,\n      \"last-5-avg\": 0.31440595984458924,\n      \"last-10-avg\": 0.31305848956108095\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.9165175557136536,\n      \"min\": 0.5952813029289246,\n      \"avg\": 0.8196298976739248,\n      \"last\": 0.8796892762184143,\n      \"last-5-avg\": 0.884322440624237,\n      \"last-10-avg\": 0.8861393451690673\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.9131478071212769,\n      \"min\": 0.47873252630233765,\n      \"avg\": 0.8118266483147937,\n      \"last\": 0.8444187641143799,\n      \"last-5-avg\": 0.8744256854057312,\n      \"last-10-avg\": 0.8833735466003418\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.9482100009918213,\n      \"min\": 0.0,\n      \"avg\": 0.6684341589609781,\n      \"last\": 0.8584392070770264,\n      \"last-5-avg\": 0.8954567909240723,\n      \"last-10-avg\": 0.896043848991394\n    },\n    \"validation_mean\": {\n      \"max\": 0.92074054479599,\n      \"min\": 0.4689771234989166,\n      \"avg\": 0.7915028204520543,\n      \"last\": 0.8617550134658813,\n      \"last-5-avg\": 0.884553599357605,\n      \"last-10-avg\": 0.888371205329895\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2656.514865875244,\n      \"min\": 2411.60985660553,\n      \"avg\": 2456.9887056509638,\n      \"last\": 2568.1087720394135,\n      \"last-5-avg\": 2504.4849314689636,\n      \"last-10-avg\": 2525.0013921737673\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.03333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 73709.66116952896,\n      \"min\": 2427.0446248054504,\n      \"avg\": 37717.834116633734,\n      \"last\": 73709.66116952896,\n      \"last-5-avg\": 68632.3286178112,\n      \"last-10-avg\": 62345.4950507164\n    },\n    \"time_since_restore\": {\n      \"max\": 73709.66116952896,\n      \"min\": 2427.0446248054504,\n      \"avg\": 37717.834116633734,\n      \"last\": 73709.66116952896,\n      \"last-5-avg\": 68632.3286178112,\n      \"last-10-avg\": 62345.4950507164\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd3451a60000000473fd43972c0000000473fd4aed620000000473fd3a7cbc0000000473fd4c6f3e0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd3443640000000473fd46a3320000000473fd3d1d8a0000000473fd3646de0000000473fd4daae00000000473fd3451a60000000473fd43972c0000000473fd4aed620000000473fd3a7cbc0000000473fd4c6f3e0000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fecc82d60000000473fec0019c0000000473feb9e16c0000000473fecf110e0000000473fec266a20000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fed541ca0000000473feb566f80000000473fec845060000000473fecf9f5a0000000473febe9de00000000473fecc82d60000000473fec0019c0000000473feb9e16c0000000473fecf110e0000000473fec266a20000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fece17e80000000473fec21bc60000000473feb3dacc0000000473feca217c0000000473feb057a80000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fed30f400000000473fecd572e0000000473fec57e320000000473fecf43cc0000000473feb72f560000000473fece17e80000000473fec21bc60000000473feb3dacc0000000473feca217c0000000473feb057a80000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fee57bc80000000473fec5ba740000000473fec1f1800000000473fecfb17c0000000473feb785580000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fede35c80000000473febb9cfe0000000473fed42ae60000000473fedb6db60000000473feadf4a60000000473fee57bc80000000473fec5ba740000000473fec1f1800000000473fecfb17c0000000473feb785580000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fed4fd980000000473fec262700000000473feba32a60000000473fecdaa6a0000000473feb937f40000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fed76b4e0000000473febed1ea0000000473fecb28a40000000473fed33a580000000473feb760a80000000473fed4fd980000000473fec262700000000473feba32a60000000473fecdaa6a0000000473feb937f40000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a30052957000004740a3680ef9b000004740a3685aee4000004740a3f3e53e5800004740a41037b0f80000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a2ee26a93800004740a41327805800004740a459eefd9000004740a4c1079c8000004740a352e8f07000004740a30052957000004740a3680ef9b000004740a3685aee4000004740a3f3e53e5800004740a41037b0f80000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740ef106cbad900004740f02376d53a00004740f0beb9acac00004740f15e58d69ec0004740f1feda94268000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e8d85720d480004740ea198998da00004740eb5f2888b300004740ecab39027b00004740ede067918200004740ef106cbad900004740f02376d53a00004740f0beb9acac00004740f15e58d69ec0004740f1feda94268000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740ef106cbad900004740f02376d53a00004740f0beb9acac00004740f15e58d69ec0004740f1feda94268000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e8d85720d480004740ea198998da00004740eb5f2888b300004740ecab39027b00004740ede067918200004740ef106cbad900004740f02376d53a00004740f0beb9acac00004740f15e58d69ec0004740f1feda94268000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1658181973.240061,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_cf683e4a_24___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.7999e-06,weight_decay=0.0005844_2022-07-19_06-06-01\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"c9bfa0aa\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.6786087991515405e-06,\n    \"weight_decay\": 0.006194357048041414,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.6786087991515405e-06,\n    \"weight_decay\": 0.006194357048041414,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"11___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.6786e-06,weight_decay=0.0061944\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.46959152817726135,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.487765371799469,\n    \"validation_2_f1\": 0.0,\n    \"validation_mean\": 0.3225460946559906,\n    \"time_this_iter_s\": 2437.2760095596313,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"c9bfa0aa\",\n    \"experiment_id\": \"65181e1ae0ac4424a9e0f846022b541f\",\n    \"date\": \"2022-07-14_18-01-24\",\n    \"timestamp\": 1657792884,\n    \"time_total_s\": 2437.2760095596313,\n    \"pid\": 11326,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 1.6786087991515405e-06,\n      \"weight_decay\": 0.006194357048041414,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 2437.2760095596313,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"11___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.6786e-06,weight_decay=0.0061944\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657792884.8216388,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.46959152817726135,\n      \"min\": 0.46959152817726135,\n      \"avg\": 0.46959152817726135,\n      \"last\": 0.46959152817726135,\n      \"last-5-avg\": 0.46959152817726135,\n      \"last-10-avg\": 0.46959152817726135\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.487765371799469,\n      \"min\": 0.487765371799469,\n      \"avg\": 0.487765371799469,\n      \"last\": 0.487765371799469,\n      \"last-5-avg\": 0.487765371799469,\n      \"last-10-avg\": 0.487765371799469\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_mean\": {\n      \"max\": 0.3225460946559906,\n      \"min\": 0.3225460946559906,\n      \"avg\": 0.3225460946559906,\n      \"last\": 0.3225460946559906,\n      \"last-5-avg\": 0.3225460946559906,\n      \"last-10-avg\": 0.3225460946559906\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2437.2760095596313,\n      \"min\": 2437.2760095596313,\n      \"avg\": 2437.2760095596313,\n      \"last\": 2437.2760095596313,\n      \"last-5-avg\": 2437.2760095596313,\n      \"last-10-avg\": 2437.2760095596313\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 2437.2760095596313,\n      \"min\": 2437.2760095596313,\n      \"avg\": 2437.2760095596313,\n      \"last\": 2437.2760095596313,\n      \"last-5-avg\": 2437.2760095596313,\n      \"last-10-avg\": 2437.2760095596313\n    },\n    \"time_since_restore\": {\n      \"max\": 2437.2760095596313,\n      \"min\": 2437.2760095596313,\n      \"avg\": 2437.2760095596313,\n      \"last\": 2437.2760095596313,\n      \"last-5-avg\": 2437.2760095596313,\n      \"last-10-avg\": 2437.2760095596313\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fde0dc9a0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fde0dc9a0000000612e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294470000000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294470000000000000000612e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fdf378c40000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fdf378c40000000612e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294470000000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294470000000000000000612e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd4a49860000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd4a49860000000612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a30a8d51200000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a30a8d51200000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a30a8d51200000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a30a8d51200000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a30a8d51200000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a30a8d51200000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657751552.7302434,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_c9bfa0aa_11___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.6786e-06,weight_decay=0.0061944_2022-07-14_06-32-32\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_c9bfa0aa_11___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.6786e-06,weight_decay=0.0061944_2022-07-14_06-32-32/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11333, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11333, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 575, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 321, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 401, in ff_chunk\\n    ffn_output = self.activation(ffn_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/activations.py\\\", line 34, in forward\\n    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\\nRuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 15.78 GiB total capacity; 14.10 GiB already allocated; 47.50 MiB free; 14.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"fbc20f8c\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 5.40191711128002e-06,\n    \"weight_decay\": 0.0005995708342598074,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 5.40191711128002e-06,\n    \"weight_decay\": 0.0005995708342598074,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"27___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=5.4019e-06,weight_decay=0.00059957\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"trial_id\": \"fbc20f8c\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1658421418.4707909,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_fbc20f8c_27___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=5.4019e-06,weight_decay=0.00059957_2022-07-22_00-36-58\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_fbc20f8c_27___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=5.4019e-06,weight_decay=0.00059957_2022-07-22_00-36-58/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=53387, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=53387, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"<ipython-input-8-797bc33ac026>\\\", line 10, in train_tune\\nNameError: name 'logger' is not defined\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 6,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"39e8bb2c\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 2.3532860439119194e-07,\n    \"weight_decay\": 0.008112415690918017,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 2.3532860439119194e-07,\n    \"weight_decay\": 0.008112415690918017,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"17___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.3533e-07,weight_decay=0.0081124\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.47111964225769043,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.4874153733253479,\n    \"validation_2_f1\": 0.0,\n    \"validation_mean\": 0.32224008440971375,\n    \"time_this_iter_s\": 2432.686667203903,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"39e8bb2c\",\n    \"experiment_id\": \"0fad0c84818c4b44aa005cfb50f1c979\",\n    \"date\": \"2022-07-16_14-27-12\",\n    \"timestamp\": 1657952832,\n    \"time_total_s\": 2432.686667203903,\n    \"pid\": 11318,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 2.3532860439119194e-07,\n      \"weight_decay\": 0.008112415690918017,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 2432.686667203903,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"17___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.3533e-07,weight_decay=0.0081124\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657952832.332761,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.47111964225769043,\n      \"min\": 0.47111964225769043,\n      \"avg\": 0.47111964225769043,\n      \"last\": 0.47111964225769043,\n      \"last-5-avg\": 0.47111964225769043,\n      \"last-10-avg\": 0.47111964225769043\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.4874153733253479,\n      \"min\": 0.4874153733253479,\n      \"avg\": 0.4874153733253479,\n      \"last\": 0.4874153733253479,\n      \"last-5-avg\": 0.4874153733253479,\n      \"last-10-avg\": 0.4874153733253479\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_mean\": {\n      \"max\": 0.32224008440971375,\n      \"min\": 0.32224008440971375,\n      \"avg\": 0.32224008440971375,\n      \"last\": 0.32224008440971375,\n      \"last-5-avg\": 0.32224008440971375,\n      \"last-10-avg\": 0.32224008440971375\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2432.686667203903,\n      \"min\": 2432.686667203903,\n      \"avg\": 2432.686667203903,\n      \"last\": 2432.686667203903,\n      \"last-5-avg\": 2432.686667203903,\n      \"last-10-avg\": 2432.686667203903\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 2432.686667203903,\n      \"min\": 2432.686667203903,\n      \"avg\": 2432.686667203903,\n      \"last\": 2432.686667203903,\n      \"last-5-avg\": 2432.686667203903,\n      \"last-10-avg\": 2432.686667203903\n    },\n    \"time_since_restore\": {\n      \"max\": 2432.686667203903,\n      \"min\": 2432.686667203903,\n      \"avg\": 2432.686667203903,\n      \"last\": 2432.686667203903,\n      \"last-5-avg\": 2432.686667203903,\n      \"last-10-avg\": 2432.686667203903\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fde26d300000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fde26d300000000612e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294470000000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294470000000000000000612e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fdf31d040000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fdf31d040000000612e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294470000000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294470000000000000000612e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd49f94e0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd49f94e0000000612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a3015f92d80000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a3015f92d80000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a3015f92d80000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a3015f92d80000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a3015f92d80000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a3015f92d80000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657876843.7155683,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_39e8bb2c_17___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.3533e-07,weight_decay=0.0081124_2022-07-15_11-35-52\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_39e8bb2c_17___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=2.3533e-07,weight_decay=0.0081124_2022-07-15_11-35-52/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11314, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11314, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 575, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 321, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 401, in ff_chunk\\n    ffn_output = self.activation(ffn_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/activations.py\\\", line 34, in forward\\n    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\\nRuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 15.78 GiB total capacity; 14.10 GiB already allocated; 71.50 MiB free; 14.28 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"9831da02\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 3.7661418879778663e-06,\n    \"weight_decay\": 0.0008234235316433061,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 3.7661418879778663e-06,\n    \"weight_decay\": 0.0008234235316433061,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"22___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.7661e-06,weight_decay=0.00082342\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.3535211682319641,\n    \"validation_0_f1\": 0.8530282378196716,\n    \"validation_1_f1\": 0.7363727688789368,\n    \"validation_2_f1\": 0.7527371048927307,\n    \"validation_mean\": 0.7860148549079895,\n    \"time_this_iter_s\": 2415.0978927612305,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"9831da02\",\n    \"experiment_id\": \"01cbc16f5a96411c82271289fa5a3081\",\n    \"date\": \"2022-07-18_07-26-05\",\n    \"timestamp\": 1658100365,\n    \"time_total_s\": 72669.34437918663,\n    \"pid\": 11327,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 3.7661418879778663e-06,\n      \"weight_decay\": 0.0008234235316433061,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 72669.34437918663,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"experiment_tag\": \"22___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.7661e-06,weight_decay=0.00082342\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1658100365.7213862,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.4052022397518158,\n      \"min\": 0.3066159784793854,\n      \"avg\": 0.35751346548398316,\n      \"last\": 0.3535211682319641,\n      \"last-5-avg\": 0.335998398065567,\n      \"last-10-avg\": 0.35159213542938234\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.9260092377662659,\n      \"min\": 0.7070308923721313,\n      \"avg\": 0.8719096561272938,\n      \"last\": 0.8530282378196716,\n      \"last-5-avg\": 0.8952832341194152,\n      \"last-10-avg\": 0.8901633620262146\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.8729382157325745,\n      \"min\": 0.4622912108898163,\n      \"avg\": 0.7250482549269992,\n      \"last\": 0.7363727688789368,\n      \"last-5-avg\": 0.78900648355484,\n      \"last-10-avg\": 0.7509457468986511\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.9068725109100342,\n      \"min\": 0.27959945797920227,\n      \"avg\": 0.708388727903366,\n      \"last\": 0.7527371048927307,\n      \"last-5-avg\": 0.7862171173095703,\n      \"last-10-avg\": 0.6979639858007431\n    },\n    \"validation_mean\": {\n      \"max\": 0.9014612436294556,\n      \"min\": 0.6603167057037354,\n      \"avg\": 0.7799658238887786,\n      \"last\": 0.7860148549079895,\n      \"last-5-avg\": 0.827526581287384,\n      \"last-10-avg\": 0.7892816126346588\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2457.2581532001495,\n      \"min\": 2415.0978927612305,\n      \"avg\": 2422.31147930622,\n      \"last\": 2415.0978927612305,\n      \"last-5-avg\": 2423.6007404327393,\n      \"last-10-avg\": 2429.007388973236\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.03333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 72669.34437918663,\n      \"min\": 2419.207798242569,\n      \"avg\": 37513.4368434906,\n      \"last\": 72669.34437918663,\n      \"last-5-avg\": 67832.50848722458,\n      \"last-10-avg\": 61748.345551157\n    },\n    \"time_since_restore\": {\n      \"max\": 72669.34437918663,\n      \"min\": 2419.207798242569,\n      \"avg\": 37513.4368434906,\n      \"last\": 72669.34437918663,\n      \"last-5-avg\": 67832.50848722458,\n      \"last-10-avg\": 61748.345551157\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd39f98a0000000473fd52f60c0000000473fd603bba0000000473fd61230e0000000473fd6a01740000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd590d1c0000000473fd70b5640000000473fd7f5b2e0000000473fd8a8ec60000000473fd84516a0000000473fd39f98a0000000473fd52f60c0000000473fd603bba0000000473fd61230e0000000473fd6a01740000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fed8efc40000000473fed2b6220000000473fec4487e0000000473fecf3e500000000473feb4c01e0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fecb85280000000473fec4cfec0000000473feb9038a0000000473fec175a40000000473fecee7d80000000473fed8efc40000000473fed2b6220000000473fec4487e0000000473fecf3e500000000473feb4c01e0000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473febef1c20000000473fe9bbe640000000473fe89ba300000000473fe866b1a0000000473fe7905da0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe92f5080000000473fe74cf500000000473fe5e99840000000473fe585b0e0000000473fe6243680000000473febef1c20000000473fe9bbe640000000473fe89ba300000000473fe866b1a0000000473fe7905da0000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fed051980000000473fe9752180000000473fe8332460000000473fe707a880000000473fe8166c20000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe8da4c20000000473fe5a76be0000000473fe3d7a1c0000000473fe0327b80000000473fde03d8e0000000473fed051980000000473fe9752180000000473fe8332460000000473fe707a880000000473fe8166c20000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fecd8c540000000473feae4a3a0000000473fe9df4ae0000000473fe9a3c0c0000000473fe92708a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fea551e20000000473fe89d2720000000473fe78c8660000000473fe6ba91e0000000473fe6f11880000000473fecd8c540000000473feae4a3a0000000473fe9df4ae0000000473fe9a3c0c0000000473fe92708a0000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a307be614800004740a2faf9faf000004740a2e4acd2e000004740a2e66a972800004740a2de321f000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a2ea0d60f000004740a2e650ef0000004740a2f5a74ed000004740a332842ca800004740a31f9a243800004740a307be614800004740a2faf9faf000004740a2e4acd2e000004740a2e66a972800004740a2de321f000000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740eec166cce800004740eff1166c9700004740f08fb09ce280004740f126e3f19bc0004740f1bdd58293c000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e8ce097de880004740e9fc6e8cd880004740eb2bc901c580004740ec5ef1449000004740ed90eae6d380004740eec166cce800004740eff1166c9700004740f08fb09ce280004740f126e3f19bc0004740f1bdd58293c000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740eec166cce800004740eff1166c9700004740f08fb09ce280004740f126e3f19bc0004740f1bdd58293c000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e8ce097de880004740e9fc6e8cd880004740eb2bc901c580004740ec5ef1449000004740ed90eae6d380004740eec166cce800004740eff1166c9700004740f08fb09ce280004740f126e3f19bc0004740f1bdd58293c000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1658027692.9510744,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_9831da02_22___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.7661e-06,weight_decay=0.00082342_2022-07-17_11-14-39\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"6706d53c\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 8.72596159329642e-07,\n    \"weight_decay\": 0.00942843972725673,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 8.72596159329642e-07,\n    \"weight_decay\": 0.00942843972725673,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"18___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=8.726e-07,weight_decay=0.0094284\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.4401673674583435,\n    \"validation_0_f1\": 0.5840349793434143,\n    \"validation_1_f1\": 0.0,\n    \"validation_2_f1\": 0.6519303321838379,\n    \"validation_mean\": 0.507000207901001,\n    \"time_this_iter_s\": 2410.5409841537476,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"6706d53c\",\n    \"experiment_id\": \"0fad0c84818c4b44aa005cfb50f1c979\",\n    \"date\": \"2022-07-16_13-46-39\",\n    \"timestamp\": 1657950399,\n    \"time_total_s\": 73538.04019021988,\n    \"pid\": 11318,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 8.72596159329642e-07,\n      \"weight_decay\": 0.00942843972725673,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 73538.04019021988,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"experiment_tag\": \"18___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=8.726e-07,weight_decay=0.0094284\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657950399.3809109,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.46818286180496216,\n      \"min\": 0.4250577390193939,\n      \"avg\": 0.44389689167340596,\n      \"last\": 0.4401673674583435,\n      \"last-5-avg\": 0.43571004271507263,\n      \"last-10-avg\": 0.440720397233963\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.6742892265319824,\n      \"min\": 0.5104950666427612,\n      \"avg\": 0.5979590892791748,\n      \"last\": 0.5840349793434143,\n      \"last-5-avg\": 0.6018704295158386,\n      \"last-10-avg\": 0.589581698179245\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.005200945772230625,\n      \"min\": 0.0,\n      \"avg\": 0.00033099919479961194,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.8236473202705383,\n      \"min\": 0.0,\n      \"avg\": 0.6311275667375109,\n      \"last\": 0.6519303321838379,\n      \"last-5-avg\": 0.7301251769065857,\n      \"last-10-avg\": 0.6729905664920807\n    },\n    \"validation_mean\": {\n      \"max\": 0.6168617606163025,\n      \"min\": 0.34312599897384644,\n      \"avg\": 0.5177364607652029,\n      \"last\": 0.507000207901001,\n      \"last-5-avg\": 0.5398362755775452,\n      \"last-10-avg\": 0.5169382601976394\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2805.677257537842,\n      \"min\": 2410.5409841537476,\n      \"avg\": 2451.2680063406615,\n      \"last\": 2410.5409841537476,\n      \"last-5-avg\": 2424.52445192337,\n      \"last-10-avg\": 2429.374093389511\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.03333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 73538.04019021988,\n      \"min\": 2454.305910587311,\n      \"avg\": 38214.26587623755,\n      \"last\": 73538.04019021988,\n      \"last-5-avg\": 68697.05578045845,\n      \"last-10-avg\": 62623.982934093474\n    },\n    \"time_since_restore\": {\n      \"max\": 73538.04019021988,\n      \"min\": 2454.305910587311,\n      \"avg\": 38214.26587623755,\n      \"last\": 73538.04019021988,\n      \"last-5-avg\": 68697.05578045845,\n      \"last-10-avg\": 62623.982934093474\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fdb7b13c0000000473fdbc89980000000473fdc0f1500000000473fdbeee7e0000000473fdc2bb3c0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fdc2cdda0000000473fdcfc4480000000473fdc847b80000000473fdcbd2f60000000473fdc377660000000473fdb7b13c0000000473fdbc89980000000473fdc0f1500000000473fdbeee7e0000000473fdc2bb3c0000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe3c9b5e0000000473fe3667f40000000473fe30e3aa0000000473fe35dc300000000473fe2b06a20000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe2c01460000000473fe21d5040000000473fe27de880000000473fe22ad920000000473fe2d7c540000000473fe3c9b5e0000000473fe3667f40000000473fe30e3aa0000000473fe35dc300000000473fe2b06a20000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe9a343c0000000473fe83520c0000000473fe6ab1ca0000000473fe771cf40000000473fe4dc9d00000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe4fe5880000000473fe1c52d60000000473fe3ffd760000000473fe21031e0000000473fe5b5e6a0000000473fe9a343c0000000473fe83520c0000000473fe6ab1ca0000000473fe771cf40000000473fe4dc9d00000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe2440a20000000473fe1970fc0000000473fe0efb980000000473fe15b85c0000000473fe0395880000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe04c25e0000000473fde399ec0000000473fdfc33500000000473fde6d0320000000473fe08ad220000000473fe2440a20000000473fe1970fc0000000473fe0efb980000000473fe15b85c0000000473fe0395880000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a3021daf6800004740a2ed063d9800004740a2fa93262000004740a2f67289d000004740a2d514fbe00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a3058f2ce000004740a31b0adaa000004740a2f9de986800004740a2f8c4836800004740a302ff9f9000004740a3021daf6800004740a2ed063d9800004740a2fa93262000004740a2f67289d000004740a2d514fbe00000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740ef2d0f3aa680004740f02defcf4000004740f0c5c4687100004740f15d77fcbf80004740f1f420a49e8000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e93be2865000004740ea6d9333fa00004740eb9d311d8080004740ecccbd65b700004740edfced5fb000004740ef2d0f3aa680004740f02defcf4000004740f0c5c4687100004740f15d77fcbf80004740f1f420a49e8000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740ef2d0f3aa680004740f02defcf4000004740f0c5c4687100004740f15d77fcbf80004740f1f420a49e8000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e93be2865000004740ea6d9333fa00004740eb9d311d8080004740ecccbd65b700004740edfced5fb000004740ef2d0f3aa680004740f02defcf4000004740f0c5c4687100004740f15d77fcbf80004740f1f420a49e8000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657876857.7282114,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_6706d53c_18___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=8.726e-07,weight_decay=0.0094284_2022-07-15_17-20-43\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"75f39120\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 3.058367056957645e-07,\n    \"weight_decay\": 0.007223633395075165,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 3.058367056957645e-07,\n    \"weight_decay\": 0.007223633395075165,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"9___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.0584e-07,weight_decay=0.0072236\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.4716818630695343,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.0,\n    \"validation_2_f1\": 0.5019769668579102,\n    \"validation_mean\": 0.3350929617881775,\n    \"time_this_iter_s\": 2472.8352172374725,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 8,\n    \"trial_id\": \"75f39120\",\n    \"experiment_id\": \"805b25cbb2ab472790044bed3770f09c\",\n    \"date\": \"2022-07-14_06-32-32\",\n    \"timestamp\": 1657751552,\n    \"time_total_s\": 20571.985881328583,\n    \"pid\": 11333,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 3.058367056957645e-07,\n      \"weight_decay\": 0.007223633395075165,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 20571.985881328583,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 8,\n    \"experiment_tag\": \"9___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.0584e-07,weight_decay=0.0072236\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657751552.4713497,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.4719979166984558,\n      \"min\": 0.4716818630695343,\n      \"avg\": 0.4718209393322468,\n      \"last\": 0.4716818630695343,\n      \"last-5-avg\": 0.47174887657165526,\n      \"last-10-avg\": 0.4718209393322468\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.5019769668579102,\n      \"min\": 0.5019769668579102,\n      \"avg\": 0.5019769668579102,\n      \"last\": 0.5019769668579102,\n      \"last-5-avg\": 0.5019769668579102,\n      \"last-10-avg\": 0.5019769668579102\n    },\n    \"validation_mean\": {\n      \"max\": 0.3350929617881775,\n      \"min\": 0.3350929617881775,\n      \"avg\": 0.3350929617881775,\n      \"last\": 0.3350929617881775,\n      \"last-5-avg\": 0.3350929617881775,\n      \"last-10-avg\": 0.3350929617881775\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2683.8950061798096,\n      \"min\": 2472.8352172374725,\n      \"avg\": 2571.498235166073,\n      \"last\": 2472.8352172374725,\n      \"last-5-avg\": 2512.7270605564117,\n      \"last-10-avg\": 2571.498235166073\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.125,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.125\n    },\n    \"training_iteration\": {\n      \"max\": 8,\n      \"min\": 1,\n      \"avg\": 4.5,\n      \"last\": 8,\n      \"last-5-avg\": 6.0,\n      \"last-10-avg\": 4.5\n    },\n    \"time_total_s\": {\n      \"max\": 20571.985881328583,\n      \"min\": 2670.550014734268,\n      \"avg\": 11756.032738536596,\n      \"last\": 20571.985881328583,\n      \"last-5-avg\": 15602.98325881958,\n      \"last-10-avg\": 11756.032738536596\n    },\n    \"time_since_restore\": {\n      \"max\": 20571.985881328583,\n      \"min\": 2670.550014734268,\n      \"avg\": 11756.032738536596,\n      \"last\": 20571.985881328583,\n      \"last-5-avg\": 15602.98325881958,\n      \"last-10-avg\": 11756.032738536596\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 8,\n      \"min\": 1,\n      \"avg\": 4.5,\n      \"last\": 8,\n      \"last-5-avg\": 6.0,\n      \"last-10-avg\": 4.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fde327020000000473fde31fd80000000473fde30cb60000000473fde3068e0000000473fde300920000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fde3536c0000000473fde346300000000473fde333ee0000000473fde327020000000473fde31fd80000000473fde30cb60000000473fde3068e0000000473fde300920000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a41cb1ed0000004740a3f988ea5800004740a3644d227000004740a35b11ab0800004740a351aba1980000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a4dd199b8800004740a4f7ca3e4000004740a4bbcfa54000004740a41cb1ed0000004740a3f988ea5800004740a3644d227000004740a35b11ab0800004740a351aba1980000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b044b054b064b074b08652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059532000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b08652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c4ab595b0200004740c9a9bb959800004740ce82cede3400004740d1acc9a47b00004740d416ff18ae0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a4dd199b8800004740b4ea71ece400004740bf4859bf8400004740c4ab595b0200004740c9a9bb959800004740ce82cede3400004740d1acc9a47b00004740d416ff18ae0000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c4ab595b0200004740c9a9bb959800004740ce82cede3400004740d1acc9a47b00004740d416ff18ae0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a4dd199b8800004740b4ea71ece400004740bf4859bf8400004740c4ab595b0200004740c9a9bb959800004740ce82cede3400004740d1acc9a47b00004740d416ff18ae0000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059532000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b044b054b064b074b08652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059532000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b08652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657728424.719892,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_75f39120_9___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.0584e-07,weight_decay=0.0072236_2022-07-13_03-18-50\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_75f39120_9___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.0584e-07,weight_decay=0.0072236_2022-07-13_03-18-50/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11324, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11324, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 575, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 321, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 401, in ff_chunk\\n    ffn_output = self.activation(ffn_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/activations.py\\\", line 34, in forward\\n    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\\nRuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 15.78 GiB total capacity; 14.10 GiB already allocated; 47.50 MiB free; 14.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"a9c207c4\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.6017570662606394e-06,\n    \"weight_decay\": 0.006286740635855888,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.6017570662606394e-06,\n    \"weight_decay\": 0.006286740635855888,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"19___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.6018e-06,weight_decay=0.0062867\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.471067875623703,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.4891734719276428,\n    \"validation_2_f1\": 0.04145308583974838,\n    \"validation_mean\": 0.3285900056362152,\n    \"time_this_iter_s\": 2438.933156967163,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"a9c207c4\",\n    \"experiment_id\": \"487c9af8803e4e0ab3486f7b8b4514cd\",\n    \"date\": \"2022-07-17_11-14-39\",\n    \"timestamp\": 1658027679,\n    \"time_total_s\": 2438.933156967163,\n    \"pid\": 11328,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 1.6017570662606394e-06,\n      \"weight_decay\": 0.006286740635855888,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 2438.933156967163,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"19___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.6018e-06,weight_decay=0.0062867\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1658027679.3588452,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.471067875623703,\n      \"min\": 0.471067875623703,\n      \"avg\": 0.471067875623703,\n      \"last\": 0.471067875623703,\n      \"last-5-avg\": 0.471067875623703,\n      \"last-10-avg\": 0.471067875623703\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.4891734719276428,\n      \"min\": 0.4891734719276428,\n      \"avg\": 0.4891734719276428,\n      \"last\": 0.4891734719276428,\n      \"last-5-avg\": 0.4891734719276428,\n      \"last-10-avg\": 0.4891734719276428\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.04145308583974838,\n      \"min\": 0.04145308583974838,\n      \"avg\": 0.04145308583974838,\n      \"last\": 0.04145308583974838,\n      \"last-5-avg\": 0.04145308583974838,\n      \"last-10-avg\": 0.04145308583974838\n    },\n    \"validation_mean\": {\n      \"max\": 0.3285900056362152,\n      \"min\": 0.3285900056362152,\n      \"avg\": 0.3285900056362152,\n      \"last\": 0.3285900056362152,\n      \"last-5-avg\": 0.3285900056362152,\n      \"last-10-avg\": 0.3285900056362152\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2438.933156967163,\n      \"min\": 2438.933156967163,\n      \"avg\": 2438.933156967163,\n      \"last\": 2438.933156967163,\n      \"last-5-avg\": 2438.933156967163,\n      \"last-10-avg\": 2438.933156967163\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 2438.933156967163,\n      \"min\": 2438.933156967163,\n      \"avg\": 2438.933156967163,\n      \"last\": 2438.933156967163,\n      \"last-5-avg\": 2438.933156967163,\n      \"last-10-avg\": 2438.933156967163\n    },\n    \"time_since_restore\": {\n      \"max\": 2438.933156967163,\n      \"min\": 2438.933156967163,\n      \"avg\": 2438.933156967163,\n      \"last\": 2438.933156967163,\n      \"last-5-avg\": 2438.933156967163,\n      \"last-10-avg\": 2438.933156967163\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fde25f9e0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fde25f9e0000000612e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294470000000000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294470000000000000000612e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fdf4e9e40000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fdf4e9e40000000612e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fa53956c0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fa53956c0000000612e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fd5079e60000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fd5079e60000000612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a30dddc6c00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a30dddc6c00000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a30dddc6c00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a30dddc6c00000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740a30dddc6c00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740a30dddc6c00000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657952832.5677545,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_a9c207c4_19___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.6018e-06,weight_decay=0.0062867_2022-07-16_13-46-39\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_a9c207c4_19___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.6018e-06,weight_decay=0.0062867_2022-07-16_13-46-39/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11318, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11318, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 575, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 321, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 401, in ff_chunk\\n    ffn_output = self.activation(ffn_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/activations.py\\\", line 34, in forward\\n    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\\nRuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 15.78 GiB total capacity; 14.10 GiB already allocated; 63.50 MiB free; 14.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"d4a18718\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 8.311709514598116e-06,\n    \"weight_decay\": 0.00010418087644685915,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 8.311709514598116e-06,\n    \"weight_decay\": 0.00010418087644685915,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"23___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=8.3117e-06,weight_decay=0.00010418\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.42374953627586365,\n    \"validation_0_f1\": 0.872333824634552,\n    \"validation_1_f1\": 0.628648579120636,\n    \"validation_2_f1\": 0.08640628308057785,\n    \"validation_mean\": 0.6240532398223877,\n    \"time_this_iter_s\": 2417.133424282074,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"d4a18718\",\n    \"experiment_id\": \"b76e735fbe4f4779bcd025e31a560849\",\n    \"date\": \"2022-07-20_23-22-31\",\n    \"timestamp\": 1658330551,\n    \"time_total_s\": 74865.23815369606,\n    \"pid\": 11325,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 8.311709514598116e-06,\n      \"weight_decay\": 0.00010418087644685915,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 74865.23815369606,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"experiment_tag\": \"23___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=8.3117e-06,weight_decay=0.00010418\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1658330551.9704263,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.5214269161224365,\n      \"min\": 0.3420841097831726,\n      \"avg\": 0.40812104741732275,\n      \"last\": 0.42374953627586365,\n      \"last-5-avg\": 0.3987200915813446,\n      \"last-10-avg\": 0.3942702203989029\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.9069886207580566,\n      \"min\": 0.0,\n      \"avg\": 0.8084642767906186,\n      \"last\": 0.872333824634552,\n      \"last-5-avg\": 0.871315336227417,\n      \"last-10-avg\": 0.8754840195178986\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.7990380525588989,\n      \"min\": 0.5134483575820923,\n      \"avg\": 0.6566210468610125,\n      \"last\": 0.628648579120636,\n      \"last-5-avg\": 0.6735817790031433,\n      \"last-10-avg\": 0.6833040654659271\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.7124173641204834,\n      \"min\": 0.07387863099575043,\n      \"avg\": 0.3332453439633051,\n      \"last\": 0.08640628308057785,\n      \"last-5-avg\": 0.34686564952135085,\n      \"last-10-avg\": 0.37684551551938056\n    },\n    \"validation_mean\": {\n      \"max\": 0.8168464303016663,\n      \"min\": 0.39606761932373047,\n      \"avg\": 0.6553668439388273,\n      \"last\": 0.6240532398223877,\n      \"last-5-avg\": 0.6828704714775086,\n      \"last-10-avg\": 0.6930915772914886\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2821.9960947036743,\n      \"min\": 2416.1528809070587,\n      \"avg\": 2495.507938456534,\n      \"last\": 2417.133424282074,\n      \"last-5-avg\": 2569.8832923412324,\n      \"last-10-avg\": 2630.700022482872\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.03333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 74865.23815369606,\n      \"min\": 2442.2788467407227,\n      \"avg\": 38035.53142244021,\n      \"last\": 74865.23815369606,\n      \"last-5-avg\": 69917.43144097328,\n      \"last-10-avg\": 63187.21361272335\n    },\n    \"time_since_restore\": {\n      \"max\": 74865.23815369606,\n      \"min\": 2442.2788467407227,\n      \"avg\": 38035.53142244021,\n      \"last\": 74865.23815369606,\n      \"last-5-avg\": 69917.43144097328,\n      \"last-10-avg\": 63187.21361272335\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd7e5a6c0000000473fd929f360000000473fda2893e0000000473fd9404200000000473fdb1eb660000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd90a55e0000000473fd85bc6e0000000473fd9b930e0000000473fd955f6c0000000473fd848d0e0000000473fd7e5a6c0000000473fd929f360000000473fda2893e0000000473fd9404200000000473fdb1eb660000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fec62dbe0000000473fec0eb780000000473febab4ee0000000473feb6208a0000000473febea28a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fec57aca0000000473feaf3d520000000473fec6c63a0000000473fec74c300000000473fec91eac0000000473fec62dbe0000000473fec0eb780000000473febab4ee0000000473feb6208a0000000473febea28a0000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe6fc0840000000473fe5db84c0000000473fe4d0f780000000473fe5ff80c0000000473fe41de3a0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe5fa5540000000473fe725fbe0000000473fe4f47a80000000473fe601caa0000000473fe6cbc5c0000000473fe6fc0840000000473fe5db84c0000000473fe4d0f780000000473fe5ff80c0000000473fe41de3a0000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe0c52600000000473fd9508780000000473fcf364660000000473fdf019700000000473fb61eb8e0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd9ebe0c0000000473fe064c000000000473fd28f7ce0000000473fd4dc4b80000000473fe006fcc0000000473fe0c52600000000473fd9508780000000473fcf364660000000473fdf019700000000473fb61eb8e0000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe7a3b6c0000000473fe65328c0000000473fe4e8e8a0000000473fe66a5940000000473fe3f83e80000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe66cdb00000000473fe7298060000000473fe5772d40000000473fe618dfa0000000473fe76147c0000000473fe7a3b6c0000000473fe65328c0000000473fe4e8e8a0000000473fe66a5940000000473fe3f83e80000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a60bfe002000004740a461e001e000004740a3dcf8cc3800004740a335ba1c1000004740a2e24450300000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a31502089800004740a48a546c2800004740a5d7205c5000004740a5c72319c800004740a5e590f82800004740a60bfe002000004740a461e001e000004740a3dcf8cc3800004740a335ba1c1000004740a2e24450300000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740efa8ba2b4f00004740f0776c15b680004740f11653dc1840004740f1b001acf8c0004740f24713cf7a4000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e8e717bda680004740ea2fbd046900004740eb8d2f0a2e00004740ece9a13bca80004740ee47fa4b4d00004740efa8ba2b4f00004740f0776c15b680004740f11653dc1840004740f1b001acf8c0004740f24713cf7a4000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740efa8ba2b4f00004740f0776c15b680004740f11653dc1840004740f1b001acf8c0004740f24713cf7a4000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e8e717bda680004740ea2fbd046900004740eb8d2f0a2e00004740ece9a13bca80004740ee47fa4b4d00004740efa8ba2b4f00004740f0776c15b680004740f11653dc1840004740f1b001acf8c0004740f24713cf7a4000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1658181961.5245333,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_d4a18718_23___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=8.3117e-06,weight_decay=0.00010418_2022-07-18_07-26-05\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_d4a18718_23___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=8.3117e-06,weight_decay=0.00010418_2022-07-18_07-26-05/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11327, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11327, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 575, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 321, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 401, in ff_chunk\\n    ffn_output = self.activation(ffn_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/activations.py\\\", line 34, in forward\\n    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\\nRuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 15.78 GiB total capacity; 14.10 GiB already allocated; 19.50 MiB free; 14.33 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"272b4e64\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.266013623154677e-07,\n    \"weight_decay\": 0.007496970889759907,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 1.266013623154677e-07,\n    \"weight_decay\": 0.007496970889759907,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"16___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.266e-07,weight_decay=0.007497\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.47214391827583313,\n    \"validation_0_f1\": 0.0,\n    \"validation_1_f1\": 0.0,\n    \"validation_2_f1\": 0.5019769668579102,\n    \"validation_mean\": 0.3350929617881775,\n    \"time_this_iter_s\": 2419.6383199691772,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 8,\n    \"trial_id\": \"272b4e64\",\n    \"experiment_id\": \"f18001f105174064bc1dbdecd93a9105\",\n    \"date\": \"2022-07-15_11-35-51\",\n    \"timestamp\": 1657856151,\n    \"time_total_s\": 19341.479066848755,\n    \"pid\": 11314,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 1.266013623154677e-07,\n      \"weight_decay\": 0.007496970889759907,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 19341.479066848755,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 8,\n    \"experiment_tag\": \"16___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.266e-07,weight_decay=0.007497\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657856151.959069,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.47223904728889465,\n      \"min\": 0.47214391827583313,\n      \"avg\": 0.47218998894095415,\n      \"last\": 0.47214391827583313,\n      \"last-5-avg\": 0.47217113971710206,\n      \"last-10-avg\": 0.4721899889409542\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.5019769668579102,\n      \"min\": 0.5019769668579102,\n      \"avg\": 0.5019769668579102,\n      \"last\": 0.5019769668579102,\n      \"last-5-avg\": 0.5019769668579102,\n      \"last-10-avg\": 0.5019769668579102\n    },\n    \"validation_mean\": {\n      \"max\": 0.3350929617881775,\n      \"min\": 0.3350929617881775,\n      \"avg\": 0.3350929617881775,\n      \"last\": 0.3350929617881775,\n      \"last-5-avg\": 0.3350929617881775,\n      \"last-10-avg\": 0.3350929617881775\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2424.361991882324,\n      \"min\": 2414.6065225601196,\n      \"avg\": 2417.6848833560944,\n      \"last\": 2419.6383199691772,\n      \"last-5-avg\": 2417.4526031017303,\n      \"last-10-avg\": 2417.6848833560944\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.125,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.125\n    },\n    \"training_iteration\": {\n      \"max\": 8,\n      \"min\": 1,\n      \"avg\": 4.5,\n      \"last\": 8,\n      \"last-5-avg\": 6.0,\n      \"last-10-avg\": 4.5\n    },\n    \"time_total_s\": {\n      \"max\": 19341.479066848755,\n      \"min\": 2424.361991882324,\n      \"avg\": 10879.998695164919,\n      \"last\": 19341.479066848755,\n      \"last-5-avg\": 14504.488600730896,\n      \"last-10-avg\": 10879.998695164919\n    },\n    \"time_since_restore\": {\n      \"max\": 19341.479066848755,\n      \"min\": 2424.361991882324,\n      \"avg\": 10879.998695164919,\n      \"last\": 19341.479066848755,\n      \"last-5-avg\": 14504.488600730896,\n      \"last-10-avg\": 10879.998695164919\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 8,\n      \"min\": 1,\n      \"avg\": 4.5,\n      \"last\": 8,\n      \"last-5-avg\": 6.0,\n      \"last-10-avg\": 4.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fde38b780000000473fde385760000000473fde37cbe0000000473fde37cca0000000473fde379b20000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fde392a20000000473fde38ee60000000473fde3887e0000000473fde38b780000000473fde385760000000473fde37cbe0000000473fde37cca0000000473fde379b20000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000473fe0103200000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000473fd57229c0000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a2dfb2d0b800004740a2dd4d522000004740a2e740218000004740a2e2ff93c000004740a2e746d1e00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a2f0b9570000004740a2dd368a2000004740a2de7ebd2800004740a2dfb2d0b800004740a2dd4d522000004740a2e740218000004740a2e2ff93c000004740a2e746d1e00000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b044b054b064b074b08652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059532000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b08652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c2e3085bc000004740c79a5bb04800004740cc542bb8a800004740d08675cecc00004740d2e35ea9080000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a2f0b9570000004740b2e6f7f09000004740bc56374f2400004740c2e3085bc000004740c79a5bb04800004740cc542bb8a800004740d08675cecc00004740d2e35ea9080000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c2e3085bc000004740c79a5bb04800004740cc542bb8a800004740d08675cecc00004740d2e35ea9080000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a2f0b9570000004740b2e6f7f09000004740bc56374f2400004740c2e3085bc000004740c79a5bb04800004740cc542bb8a800004740d08675cecc00004740d2e35ea9080000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059532000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b044b054b064b074b08652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059532000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b08652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657836806.393986,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_272b4e64_16___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=1.266e-07,weight_decay=0.007497_2022-07-15_06-13-13\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"0df3afd2\",\n  \"config\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 3.527204602413617e-07,\n    \"weight_decay\": 0.0032998352223865147,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 14,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"lr\": 3.527204602413617e-07,\n    \"weight_decay\": 0.0032998352223865147,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"5___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.5272e-07,weight_decay=0.0032998\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": -1,\n  \"_last_result\": {\n    \"validation_loss\": 0.43743985891342163,\n    \"validation_0_f1\": 0.02944141998887062,\n    \"validation_1_f1\": 0.5687097907066345,\n    \"validation_2_f1\": 0.7023653984069824,\n    \"validation_mean\": 0.5016448497772217,\n    \"time_this_iter_s\": 2758.5412995815277,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 30,\n    \"trial_id\": \"0df3afd2\",\n    \"experiment_id\": \"30e84f779eea4ab5b5d14b098d41d685\",\n    \"date\": \"2022-07-13_02-31-54\",\n    \"timestamp\": 1657650714,\n    \"time_total_s\": 75297.83004760742,\n    \"pid\": 11331,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 14,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"lr\": 3.527204602413617e-07,\n      \"weight_decay\": 0.0032998352223865147,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 75297.83004760742,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 30,\n    \"experiment_tag\": \"5___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.5272e-07,weight_decay=0.0032998\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1657650714.745527,\n  \"metric_analysis\": {\n    \"validation_loss\": {\n      \"max\": 0.47192421555519104,\n      \"min\": 0.40915754437446594,\n      \"avg\": 0.43886068065961203,\n      \"last\": 0.43743985891342163,\n      \"last-5-avg\": 0.4207147479057312,\n      \"last-10-avg\": 0.4206258416175842\n    },\n    \"validation_0_f1\": {\n      \"max\": 0.3781645596027374,\n      \"min\": 0.0,\n      \"avg\": 0.018855048047650296,\n      \"last\": 0.02944141998887062,\n      \"last-5-avg\": 0.10048438832163811,\n      \"last-10-avg\": 0.0563451859401539\n    },\n    \"validation_1_f1\": {\n      \"max\": 0.6282253265380859,\n      \"min\": 0.0,\n      \"avg\": 0.46982814990527305,\n      \"last\": 0.5687097907066345,\n      \"last-5-avg\": 0.5988521933555603,\n      \"last-10-avg\": 0.5928559899330139\n    },\n    \"validation_2_f1\": {\n      \"max\": 0.8752484917640686,\n      \"min\": 0.5019769668579102,\n      \"avg\": 0.7039835333824156,\n      \"last\": 0.7023653984069824,\n      \"last-5-avg\": 0.7957129001617431,\n      \"last-10-avg\": 0.801203453540802\n    },\n    \"validation_mean\": {\n      \"max\": 0.6154846549034119,\n      \"min\": 0.3350929617881775,\n      \"avg\": 0.4904954959948857,\n      \"last\": 0.5016448497772217,\n      \"last-5-avg\": 0.5619462847709655,\n      \"last-10-avg\": 0.5552597284317017\n    },\n    \"time_this_iter_s\": {\n      \"max\": 2758.5412995815277,\n      \"min\": 2431.900208234787,\n      \"avg\": 2509.92766825358,\n      \"last\": 2758.5412995815277,\n      \"last-5-avg\": 2590.6506423950195,\n      \"last-10-avg\": 2524.270641994476\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.03333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.1\n    },\n    \"training_iteration\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    },\n    \"time_total_s\": {\n      \"max\": 75297.83004760742,\n      \"min\": 2503.7849996089935,\n      \"avg\": 38731.74592356682,\n      \"last\": 75297.83004760742,\n      \"last-5-avg\": 69928.14154849053,\n      \"last-10-avg\": 63686.113322377205\n    },\n    \"time_since_restore\": {\n      \"max\": 75297.83004760742,\n      \"min\": 2503.7849996089935,\n      \"avg\": 38731.74592356682,\n      \"last\": 75297.83004760742,\n      \"last-5-avg\": 69928.14154849053,\n      \"last-10-avg\": 63686.113322377205\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 30,\n      \"min\": 1,\n      \"avg\": 15.5,\n      \"last\": 30,\n      \"last-5-avg\": 28.0,\n      \"last-10-avg\": 25.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"validation_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fda2fa320000000473fda72d460000000473fdb656c80000000473fda9a0c00000000473fdbff03c0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fdb147fc0000000473fda78d1c0000000473fdb04ee40000000473fdb55aaa0000000473fdaaa7860000000473fda2fa320000000473fda72d460000000473fdb656c80000000473fda9a0c00000000473fdbff03c0000000652e\"\n      }\n    },\n    \"validation_0_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fa22b1f60000000473f97e27840000000473fd833d920000000473fa26f5c40000000473f9e25e440000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f692f1b80000000473f61f90920000000473f88aa0180000000473f9d894fc0000000473f8e7696c0000000473fa22b1f60000000473f97e27840000000473fd833d920000000473fa26f5c40000000473f9e25e440000000652e\"\n      }\n    },\n    \"validation_1_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe388ee20000000473fe322a680000000473fe41a6c00000000473fe2d81ce0000000473fe232dee0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe2784c80000000473fe3086980000000473fe2d8b320000000473fe2baa5a0000000473fe2d1b820000000473fe388ee20000000473fe322a680000000473fe41a6c00000000473fe2d81ce0000000473fe232dee0000000652e\"\n      }\n    },\n    \"validation_2_f1\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fec020920000000473fea6ac900000000473fe93da700000000473fe92c2660000000473fe679c700000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe874b840000000473fea9e2ac0000000473fea723680000000473fea138380000000473fe97992c0000000473fec020920000000473fea6ac900000000473fe93da700000000473fe92c2660000000473fe679c700000000652e\"\n      }\n    },\n    \"validation_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe2d9d400000000473fe1ecec80000000473fe3b20ce0000000473fe1630b00000000473fe00d7980000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe0eab600000000473fe1f1f000000000473fe1ce36c0000000473fe1af8120000000473fe16b30c0000000473fe2d9d400000000473fe1ecec80000000473fe3b20ce0000000473fe1630b00000000473fe00d7980000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a307a83cf000004740a2ffcce81800004740a44d24fe7000004740a550d25c5000004740a58d1525380000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a36a07ade800004740a32394534000004740a3333f097800004740a3255b8ce000004740a31cb1736000004740a307a83cf000004740a2ffcce81800004740a44d24fe7000004740a550d25c5000004740a58d1525380000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740efa18cf93f00004740f068c4e3e040004740f10b2e0bd3c0004740f1b5b49eb640004740f2621d47e00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e9a7846fa080004740ead9bdb4d480004740ec0cf1a56c00004740ed3f475e3a00004740ee7112757000004740efa18cf93f00004740f068c4e3e040004740f10b2e0bd3c0004740f1b5b49eb640004740f2621d47e00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740efa18cf93f00004740f068c4e3e040004740f10b2e0bd3c0004740f1b5b49eb640004740f2621d47e00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740e9a7846fa080004740ead9bdb4d480004740ec0cf1a56c00004740ed3f475e3a00004740ee7112757000004740efa18cf93f00004740f068c4e3e040004740f10b2e0bd3c0004740f1b5b49eb640004740f2621d47e00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1a4b1b4b1c4b1d4b1e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b154b164b174b184b194b1a4b1b4b1c4b1d4b1e652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1657572874.3089383,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_0df3afd2_5___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.5272e-07,weight_decay=0.0032998_2022-07-11_08-26-06\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_lr_asha/train_tune_0df3afd2_5___trial_index__=0,batch_size=14,beta1=0.9,beta2=0.999,lr=3.5272e-07,weight_decay=0.0032998_2022-07-11_08-26-06/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11320, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=11320, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 575, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 321, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 401, in ff_chunk\\n    ffn_output = self.activation(ffn_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/activations.py\\\", line 34, in forward\\n    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\\nRuntimeError: CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 15.78 GiB total capacity; 14.10 GiB already allocated; 47.50 MiB free; 14.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_insufficient_resources_manager": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "8005958c000000000000008c277261792e74756e652e696e73756666696369656e745f7265736f75726365735f6d616e61676572948c1c496e73756666696369656e745265736f75726365734d616e616765729493942981947d94288c185f6e6f5f72756e6e696e675f747269616c735f73696e636594474135f9a5dfa263ff8c0f5f6c6173745f747269616c5f6e756d944b1c75622e"
    },
    "_max_pending_trials": 1,
    "_metric": null,
    "_total_time": 1209890.3874909878,
    "_iteration": 1228942,
    "_has_errored": true,
    "_fail_fast": false,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_updated_queue": false,
    "_result_wait_time": 1,
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "/home/xwm/DeepSVFilter/code/tune_lr_asha",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059527000000000000008c107261792e74756e652e73746f70706572948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": true,
    "checkpoint_file": "/home/xwm/DeepSVFilter/code/tune_lr_asha/experiment_state-2022-07-25_11-16-23.json",
    "_session_str": "2022-07-25_11-16-23",
    "_start_time": 1658718983.3883538,
    "_last_checkpoint_time": -Infinity,
    "_checkpoint_period": "auto",
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1658718983.3883538,
    "timestamp": 1658719016.8434749
  }
}