{
  "checkpoints": [
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"55f566c8\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 350,\n    \"lr\": 4.662880795764871e-08,\n    \"weight_decay\": 1.6489046820149402e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 350,\n    \"lr\": 4.662880795764871e-08,\n    \"weight_decay\": 1.6489046820149402e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"1___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=350,lr=4.6629e-08,weight_decay=1.6489e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834323134393438387102580300000063707571034b014e747104512e80025d7100580e00000039343732393834323134393438387101612e01000000000000004e91ab3e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 3553.1837334632874,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 3,\n    \"trial_id\": \"55f566c8\",\n    \"experiment_id\": \"189c3f7777cc415491888d2bb71c532f\",\n    \"date\": \"2022-06-12_12-34-01\",\n    \"timestamp\": 1655008441,\n    \"time_total_s\": 7099.3270354270935,\n    \"pid\": 59971,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 350,\n      \"lr\": 4.662880795764871e-08,\n      \"weight_decay\": 1.6489046820149402e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 7099.3270354270935,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 3,\n    \"experiment_tag\": \"1___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=350,lr=4.6629e-08,weight_decay=1.6489e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655008441.104251,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 3553.1837334632874,\n      \"min\": 27.823471784591675,\n      \"avg\": 2366.4423451423645,\n      \"last\": 3553.1837334632874,\n      \"last-5-avg\": 2366.4423451423645,\n      \"last-10-avg\": 2366.4423451423645\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.3333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.3333333333333333,\n      \"last-10-avg\": 0.3333333333333333\n    },\n    \"training_iteration\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"time_total_s\": {\n      \"max\": 7099.3270354270935,\n      \"min\": 27.823471784591675,\n      \"avg\": 3557.764603058497,\n      \"last\": 7099.3270354270935,\n      \"last-5-avg\": 3557.764603058497,\n      \"last-10-avg\": 3557.764603058497\n    },\n    \"time_since_restore\": {\n      \"max\": 7099.3270354270935,\n      \"min\": 27.823471784591675,\n      \"avg\": 3557.764603058497,\n      \"last\": 7099.3270354270935,\n      \"last-5-avg\": 3557.764603058497,\n      \"last-10-avg\": 3557.764603058497\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403bd2cf0c0000004740ab7ca3c0c800004740abc25e12500000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403bd2cf0c0000004740ab7ca3c0c800004740abc25e12500000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403bd2cf0c0000004740abb4495ee000004740bbbb53b8980000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403bd2cf0c0000004740abb4495ee000004740bbbb53b8980000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403bd2cf0c0000004740abb4495ee000004740bbbb53b8980000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403bd2cf0c0000004740abb4495ee000004740bbbb53b8980000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655001334.7910328,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_55f566c8_1___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=350,lr=4.6629e-08,weight_decay_2022-06-12_10-35-34\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"563938e4\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 79,\n    \"lr\": 1.0044313618961752e-08,\n    \"weight_decay\": 7.902669512100982e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 79,\n    \"lr\": 1.0044313618961752e-08,\n    \"weight_decay\": 7.902669512100982e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"3___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=79,lr=1.0044e-08,weight_decay=7.9027e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834363636383238387102580300000063707571034b014e747104512e80025d7100580e00000039343732393834363636383238387101612e0100000000000000c324a53e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 4141.1884388923645,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 2,\n    \"trial_id\": \"563938e4\",\n    \"experiment_id\": \"c1cbb40abf8349f4a82ef2595c5c6de2\",\n    \"date\": \"2022-06-12_11-45-10\",\n    \"timestamp\": 1655005510,\n    \"time_total_s\": 4168.275222063065,\n    \"pid\": 59968,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 79,\n      \"lr\": 1.0044313618961752e-08,\n      \"weight_decay\": 7.902669512100982e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 4168.275222063065,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"3___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=79,lr=1.0044e-08,weight_decay=7.9027e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655005510.79351,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 4141.1884388923645,\n      \"min\": 27.086783170700073,\n      \"avg\": 2084.1376110315323,\n      \"last\": 4141.1884388923645,\n      \"last-5-avg\": 2084.1376110315323,\n      \"last-10-avg\": 2084.1376110315323\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_total_s\": {\n      \"max\": 4168.275222063065,\n      \"min\": 27.086783170700073,\n      \"avg\": 2097.6810026168823,\n      \"last\": 4168.275222063065,\n      \"last-5-avg\": 2097.6810026168823,\n      \"last-10-avg\": 2097.6810026168823\n    },\n    \"time_since_restore\": {\n      \"max\": 4168.275222063065,\n      \"min\": 27.086783170700073,\n      \"avg\": 2097.6810026168823,\n      \"last\": 4168.275222063065,\n      \"last-5-avg\": 2097.6810026168823,\n      \"last-10-avg\": 2097.6810026168823\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403b16376c0000004740b02d303d880000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403b16376c0000004740b02d303d880000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403b16376c0000004740b0484674f40000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403b16376c0000004740b0484674f40000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403b16376c0000004740b0484674f40000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403b16376c0000004740b0484674f40000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655001335.0567892,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_563938e4_3___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=79,lr=1.0044e-08,weight_decay=_2022-06-12_10-35-34\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"5624c7a6\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 37,\n    \"lr\": 5.273926439012544e-05,\n    \"weight_decay\": 6.69553864040595e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 37,\n    \"lr\": 5.273926439012544e-05,\n    \"weight_decay\": 6.69553864040595e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"2___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=37,lr=5.2739e-05,weight_decay=6.6955e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834373632313734347102580300000063707571034b014e747104512e80025d7100580e00000039343732393834373632313734347101612e0100000000000000ef49af3e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 4980.828709363937,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 3,\n    \"trial_id\": \"5624c7a6\",\n    \"experiment_id\": \"1e3d6c6d7aa443c9ad7b85cb99b30a1f\",\n    \"date\": \"2022-06-12_13-21-48\",\n    \"timestamp\": 1655011308,\n    \"time_total_s\": 9965.713065385818,\n    \"pid\": 59959,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 37,\n      \"lr\": 5.273926439012544e-05,\n      \"weight_decay\": 6.69553864040595e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 9965.713065385818,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 3,\n    \"experiment_tag\": \"2___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=37,lr=5.2739e-05,weight_decay=6.6955e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655011308.053561,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 4980.828709363937,\n      \"min\": 29.58536386489868,\n      \"avg\": 3321.904355128606,\n      \"last\": 4980.828709363937,\n      \"last-5-avg\": 3321.9043551286063,\n      \"last-10-avg\": 3321.9043551286063\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.3333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.3333333333333333,\n      \"last-10-avg\": 0.3333333333333333\n    },\n    \"training_iteration\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"time_total_s\": {\n      \"max\": 9965.713065385818,\n      \"min\": 29.58536386489868,\n      \"avg\": 4993.394261757532,\n      \"last\": 9965.713065385818,\n      \"last-5-avg\": 4993.394261757533,\n      \"last-10-avg\": 4993.394261757533\n    },\n    \"time_since_restore\": {\n      \"max\": 9965.713065385818,\n      \"min\": 29.58536386489868,\n      \"avg\": 4993.394261757532,\n      \"last\": 9965.713065385818,\n      \"last-5-avg\": 4993.394261757533,\n      \"last-10-avg\": 4993.394261757533\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403d95da680000004740b35b4c8ac000004740b374d4264c0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403d95da680000004740b35b4c8ac000004740b374d4264c0000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403d95da680000004740b378e2652800004740c376db45ba0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403d95da680000004740b378e2652800004740c376db45ba0000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403d95da680000004740b378e2652800004740c376db45ba0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403d95da680000004740b378e2652800004740c376db45ba0000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655001334.9307156,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_5624c7a6_2___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=37,lr=5.2739e-05,weight_decay=_2022-06-12_10-35-34\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"564fcc94\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 39,\n    \"lr\": 6.124242249635632e-06,\n    \"weight_decay\": 6.0682337589575936e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 39,\n    \"lr\": 6.124242249635632e-06,\n    \"weight_decay\": 6.0682337589575936e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"4___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=39,lr=6.1242e-06,weight_decay=6.0682e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834373635363439367102580300000063707571034b014e747104512e80025d7100580e00000039343732393834373635363439367101612e0100000000000000ef49af3e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 4962.647962093353,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 3,\n    \"trial_id\": \"564fcc94\",\n    \"experiment_id\": \"88182d24a2254e50b3fe520729f6e305\",\n    \"date\": \"2022-06-12_14-30-51\",\n    \"timestamp\": 1655015451,\n    \"time_total_s\": 9928.595785856247,\n    \"pid\": 59979,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 39,\n      \"lr\": 6.124242249635632e-06,\n      \"weight_decay\": 6.0682337589575936e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 9928.595785856247,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 3,\n    \"experiment_tag\": \"4___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=39,lr=6.1242e-06,weight_decay=6.0682e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655015452.0029023,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 4962.647962093353,\n      \"min\": 32.05570125579834,\n      \"avg\": 3309.5319286187487,\n      \"last\": 4962.647962093353,\n      \"last-5-avg\": 3309.531928618749,\n      \"last-10-avg\": 3309.531928618749\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.3333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.3333333333333333,\n      \"last-10-avg\": 0.3333333333333333\n    },\n    \"training_iteration\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"time_total_s\": {\n      \"max\": 9928.595785856247,\n      \"min\": 32.05570125579834,\n      \"avg\": 4975.533103624979,\n      \"last\": 9928.595785856247,\n      \"last-5-avg\": 4975.53310362498,\n      \"last-10-avg\": 4975.53310362498\n    },\n    \"time_since_restore\": {\n      \"max\": 9928.595785856247,\n      \"min\": 32.05570125579834,\n      \"avg\": 4975.533103624979,\n      \"last\": 9928.595785856247,\n      \"last-5-avg\": 4975.53310362498,\n      \"last-10-avg\": 4975.53310362498\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740400721380000004740b345e4622400004740b362a5e0d80000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740400721380000004740b345e4622400004740b362a5e0d80000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740400721380000004740b365f2a49400004740c3644c42b60000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740400721380000004740b365f2a49400004740c3644c42b60000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740400721380000004740b365f2a49400004740c3644c42b60000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740400721380000004740b365f2a49400004740c3644c42b60000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655005514.040359,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_564fcc94_4___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=39,lr=6.1242e-06,weight_decay=_2022-06-12_10-35-35\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"112c8224\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 170,\n    \"lr\": 3.236127830260763e-06,\n    \"weight_decay\": 8.414338194138929e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 170,\n    \"lr\": 3.236127830260763e-06,\n    \"weight_decay\": 8.414338194138929e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"5___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=170,lr=3.2361e-06,weight_decay=8.4143e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834373339313639367102580300000063707571034b014e747104512e80025d7100580e00000039343732393834373339313639367101612e0100000000000000ef49af3e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 3754.1890075206757,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 3,\n    \"trial_id\": \"112c8224\",\n    \"experiment_id\": \"911aa613816646b78f3d475324e9f311\",\n    \"date\": \"2022-06-12_14-39-39\",\n    \"timestamp\": 1655015979,\n    \"time_total_s\": 7509.123656272888,\n    \"pid\": 59957,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 170,\n      \"lr\": 3.236127830260763e-06,\n      \"weight_decay\": 8.414338194138929e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 7509.123656272888,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 3,\n    \"experiment_tag\": \"5___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=170,lr=3.2361e-06,weight_decay=8.4143e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655015979.6011205,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 3754.1890075206757,\n      \"min\": 29.74102473258972,\n      \"avg\": 2503.0412187576294,\n      \"last\": 3754.1890075206757,\n      \"last-5-avg\": 2503.0412187576294,\n      \"last-10-avg\": 2503.0412187576294\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.3333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.3333333333333333,\n      \"last-10-avg\": 0.3333333333333333\n    },\n    \"training_iteration\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"time_total_s\": {\n      \"max\": 7509.123656272888,\n      \"min\": 29.74102473258972,\n      \"avg\": 3764.5997765858965,\n      \"last\": 7509.123656272888,\n      \"last-5-avg\": 3764.599776585897,\n      \"last-10-avg\": 3764.599776585897\n    },\n    \"time_since_restore\": {\n      \"max\": 7509.123656272888,\n      \"min\": 29.74102473258972,\n      \"avg\": 3764.5997765858965,\n      \"last\": 7509.123656272888,\n      \"last-5-avg\": 3764.599776585897,\n      \"last-10-avg\": 3764.599776585897\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403dbdb3cc0000004740ad1a6322b000004740ad5460c5980000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403dbdb3cc0000004740ad1a6322b000004740ad5460c5980000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403dbdb3cc0000004740ad55de8a4800004740bd551fa7f00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403dbdb3cc0000004740ad55de8a4800004740bd551fa7f00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403dbdb3cc0000004740ad55de8a4800004740bd551fa7f00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403dbdb3cc0000004740ad55de8a4800004740bd551fa7f00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655008444.2108793,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_112c8224_5___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=170,lr=3.2361e-06,weight_decay_2022-06-12_11-45-14\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"e3bad8b6\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 155,\n    \"lr\": 3.617511711950156e-05,\n    \"weight_decay\": 1.0606585772190014e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 155,\n    \"lr\": 3.617511711950156e-05,\n    \"weight_decay\": 1.0606585772190014e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"6___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=155,lr=3.6175e-05,weight_decay=1.0607e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834373630343738347102580300000063707571034b014e747104512e80025d7100580e00000039343732393834373630343738347101612e01000000000000004e91ab3e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 3750.0612659454346,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 2,\n    \"trial_id\": \"e3bad8b6\",\n    \"experiment_id\": \"716d61001b3a41b5b643fc912771f5e3\",\n    \"date\": \"2022-06-12_14-25-02\",\n    \"timestamp\": 1655015102,\n    \"time_total_s\": 3775.7091035842896,\n    \"pid\": 59978,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 155,\n      \"lr\": 3.617511711950156e-05,\n      \"weight_decay\": 1.0606585772190014e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 3775.7091035842896,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"6___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=155,lr=3.6175e-05,weight_decay=1.0607e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655015102.2110333,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 3750.0612659454346,\n      \"min\": 25.64783763885498,\n      \"avg\": 1887.8545517921448,\n      \"last\": 3750.0612659454346,\n      \"last-5-avg\": 1887.8545517921448,\n      \"last-10-avg\": 1887.8545517921448\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_total_s\": {\n      \"max\": 3775.7091035842896,\n      \"min\": 25.64783763885498,\n      \"avg\": 1900.6784706115723,\n      \"last\": 3775.7091035842896,\n      \"last-5-avg\": 1900.6784706115723,\n      \"last-10-avg\": 1900.6784706115723\n    },\n    \"time_since_restore\": {\n      \"max\": 3775.7091035842896,\n      \"min\": 25.64783763885498,\n      \"avg\": 1900.6784706115723,\n      \"last\": 3775.7091035842896,\n      \"last-5-avg\": 1900.6784706115723,\n      \"last-10-avg\": 1900.6784706115723\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474039a5d8b00000004740ad4c1f5e400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474039a5d8b00000004740ad4c1f5e400000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474039a5d8b00000004740ad7f6b0fa00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474039a5d8b00000004740ad7f6b0fa00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474039a5d8b00000004740ad7f6b0fa00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474039a5d8b00000004740ad7f6b0fa00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655011311.1558425,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_e3bad8b6_6___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=155,lr=3.6175e-05,weight_decay_2022-06-12_12-34-04\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"908b455c\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 49,\n    \"lr\": 9.72172237656587e-08,\n    \"weight_decay\": 1.8409354927323486e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 49,\n    \"lr\": 9.72172237656587e-08,\n    \"weight_decay\": 1.8409354927323486e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"7___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=49,lr=9.7217e-08,weight_decay=1.8409e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834373632313734347102580300000063707571034b014e747104512e80025d7100580e00000039343732393834373632313734347101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 33.039878368377686,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"908b455c\",\n    \"experiment_id\": \"96c6da124bfd4875aa77056de0186a0f\",\n    \"date\": \"2022-06-12_14-25-53\",\n    \"timestamp\": 1655015153,\n    \"time_total_s\": 33.039878368377686,\n    \"pid\": 59958,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 49,\n      \"lr\": 9.72172237656587e-08,\n      \"weight_decay\": 1.8409354927323486e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 33.039878368377686,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"7___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=49,lr=9.7217e-08,weight_decay=1.8409e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655015153.224174,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 33.039878368377686,\n      \"min\": 33.039878368377686,\n      \"avg\": 33.039878368377686,\n      \"last\": 33.039878368377686,\n      \"last-5-avg\": 33.039878368377686,\n      \"last-10-avg\": 33.039878368377686\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 33.039878368377686,\n      \"min\": 33.039878368377686,\n      \"avg\": 33.039878368377686,\n      \"last\": 33.039878368377686,\n      \"last-5-avg\": 33.039878368377686,\n      \"last-10-avg\": 33.039878368377686\n    },\n    \"time_since_restore\": {\n      \"max\": 33.039878368377686,\n      \"min\": 33.039878368377686,\n      \"avg\": 33.039878368377686,\n      \"last\": 33.039878368377686,\n      \"last-5-avg\": 33.039878368377686,\n      \"last-10-avg\": 33.039878368377686\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474040851abc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474040851abc000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474040851abc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474040851abc000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474040851abc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474040851abc000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655015105.3376844,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_908b455c_7___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=49,lr=9.7217e-08,weight_decay=_2022-06-12_13-21-51\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"6606faa2\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 313,\n    \"lr\": 3.870947830528618e-08,\n    \"weight_decay\": 3.4320950481911706e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 313,\n    \"lr\": 3.870947830528618e-08,\n    \"weight_decay\": 3.4320950481911706e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"8___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=313,lr=3.8709e-08,weight_decay=3.4321e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834323236363335327102580300000063707571034b014e747104512e80025d7100580e00000039343732393834323236363335327101612e01000000000000000000803e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 23.32670760154724,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"6606faa2\",\n    \"experiment_id\": \"c207bf5499604f9eaf26096ccc386bc8\",\n    \"date\": \"2022-06-12_14-26-27\",\n    \"timestamp\": 1655015187,\n    \"time_total_s\": 23.32670760154724,\n    \"pid\": 59977,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 313,\n      \"lr\": 3.870947830528618e-08,\n      \"weight_decay\": 3.4320950481911706e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 23.32670760154724,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"8___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=313,lr=3.8709e-08,weight_decay=3.4321e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655015187.8606176,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 23.32670760154724,\n      \"min\": 23.32670760154724,\n      \"avg\": 23.32670760154724,\n      \"last\": 23.32670760154724,\n      \"last-5-avg\": 23.32670760154724,\n      \"last-10-avg\": 23.32670760154724\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 23.32670760154724,\n      \"min\": 23.32670760154724,\n      \"avg\": 23.32670760154724,\n      \"last\": 23.32670760154724,\n      \"last-5-avg\": 23.32670760154724,\n      \"last-10-avg\": 23.32670760154724\n    },\n    \"time_since_restore\": {\n      \"max\": 23.32670760154724,\n      \"min\": 23.32670760154724,\n      \"avg\": 23.32670760154724,\n      \"last\": 23.32670760154724,\n      \"last-5-avg\": 23.32670760154724,\n      \"last-10-avg\": 23.32670760154724\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403753a31c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403753a31c000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403753a31c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403753a31c000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403753a31c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403753a31c000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655015156.2531726,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_6606faa2_8___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=313,lr=3.8709e-08,weight_decay_2022-06-12_14-25-05\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"845ef676\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 35,\n    \"lr\": 2.7613082024724424e-06,\n    \"weight_decay\": 1.5204069432228107e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 35,\n    \"lr\": 2.7613082024724424e-06,\n    \"weight_decay\": 1.5204069432228107e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"9___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=35,lr=2.7613e-06,weight_decay=1.5204e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834363636323338347102580300000063707571034b014e747104512e80025d7100580e00000039343732393834363636323338347101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 34.19461011886597,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"845ef676\",\n    \"experiment_id\": \"3bdec805435948bdb2362c340010b8db\",\n    \"date\": \"2022-06-12_14-27-14\",\n    \"timestamp\": 1655015234,\n    \"time_total_s\": 34.19461011886597,\n    \"pid\": 59974,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 35,\n      \"lr\": 2.7613082024724424e-06,\n      \"weight_decay\": 1.5204069432228107e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 34.19461011886597,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"9___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=35,lr=2.7613e-06,weight_decay=1.5204e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655015234.0545235,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 34.19461011886597,\n      \"min\": 34.19461011886597,\n      \"avg\": 34.19461011886597,\n      \"last\": 34.19461011886597,\n      \"last-5-avg\": 34.19461011886597,\n      \"last-10-avg\": 34.19461011886597\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 34.19461011886597,\n      \"min\": 34.19461011886597,\n      \"avg\": 34.19461011886597,\n      \"last\": 34.19461011886597,\n      \"last-5-avg\": 34.19461011886597,\n      \"last-10-avg\": 34.19461011886597\n    },\n    \"time_since_restore\": {\n      \"max\": 34.19461011886597,\n      \"min\": 34.19461011886597,\n      \"avg\": 34.19461011886597,\n      \"last\": 34.19461011886597,\n      \"last-5-avg\": 34.19461011886597,\n      \"last-10-avg\": 34.19461011886597\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447404118e8fc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447404118e8fc000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447404118e8fc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447404118e8fc000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447404118e8fc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447404118e8fc000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655015190.9261708,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_845ef676_9___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=35,lr=2.7613e-06,weight_decay=_2022-06-12_14-25-56\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"990d32ae\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 535,\n    \"lr\": 2.828990584659825e-06,\n    \"weight_decay\": 1.5248049804146847e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 535,\n    \"lr\": 2.828990584659825e-06,\n    \"weight_decay\": 1.5248049804146847e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"10___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=535,lr=2.829e-06,weight_decay=1.5248e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834323138333239367102580300000063707571034b014e747104512e80025d7100580e00000039343732393834323138333239367101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 26.23819613456726,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"990d32ae\",\n    \"experiment_id\": \"50b203c50ae443ff9bcade581da95324\",\n    \"date\": \"2022-06-12_14-27-50\",\n    \"timestamp\": 1655015270,\n    \"time_total_s\": 26.23819613456726,\n    \"pid\": 59960,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 535,\n      \"lr\": 2.828990584659825e-06,\n      \"weight_decay\": 1.5248049804146847e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 26.23819613456726,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"10___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=535,lr=2.829e-06,weight_decay=1.5248e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655015270.7750535,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 26.23819613456726,\n      \"min\": 26.23819613456726,\n      \"avg\": 26.23819613456726,\n      \"last\": 26.23819613456726,\n      \"last-5-avg\": 26.23819613456726,\n      \"last-10-avg\": 26.23819613456726\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 26.23819613456726,\n      \"min\": 26.23819613456726,\n      \"avg\": 26.23819613456726,\n      \"last\": 26.23819613456726,\n      \"last-5-avg\": 26.23819613456726,\n      \"last-10-avg\": 26.23819613456726\n    },\n    \"time_since_restore\": {\n      \"max\": 26.23819613456726,\n      \"min\": 26.23819613456726,\n      \"avg\": 26.23819613456726,\n      \"last\": 26.23819613456726,\n      \"last-5-avg\": 26.23819613456726,\n      \"last-10-avg\": 26.23819613456726\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403a3cfa6c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403a3cfa6c000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403a3cfa6c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403a3cfa6c000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403a3cfa6c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403a3cfa6c000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655015237.2262468,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_990d32ae_10___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=535,lr=2.829e-06,weight_decay_2022-06-12_14-26-30\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"b4a464ba\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 27,\n    \"lr\": 2.1098014168856053e-06,\n    \"weight_decay\": 8.255122188588196e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 27,\n    \"lr\": 2.1098014168856053e-06,\n    \"weight_decay\": 8.255122188588196e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"11___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=27,lr=2.1098e-06,weight_decay=8.2551e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834323231333633327102580300000063707571034b014e747104512e80025d7100580e00000039343732393834323231333633327101612e01000000000000000000203f94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 36.154643297195435,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"b4a464ba\",\n    \"experiment_id\": \"4904a48e506b42848334ffcf237e42ba\",\n    \"date\": \"2022-06-12_14-28-39\",\n    \"timestamp\": 1655015319,\n    \"time_total_s\": 36.154643297195435,\n    \"pid\": 59967,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 27,\n      \"lr\": 2.1098014168856053e-06,\n      \"weight_decay\": 8.255122188588196e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 36.154643297195435,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"11___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=27,lr=2.1098e-06,weight_decay=8.2551e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655015319.3848019,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 36.154643297195435,\n      \"min\": 36.154643297195435,\n      \"avg\": 36.154643297195435,\n      \"last\": 36.154643297195435,\n      \"last-5-avg\": 36.154643297195435,\n      \"last-10-avg\": 36.154643297195435\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 36.154643297195435,\n      \"min\": 36.154643297195435,\n      \"avg\": 36.154643297195435,\n      \"last\": 36.154643297195435,\n      \"last-5-avg\": 36.154643297195435,\n      \"last-10-avg\": 36.154643297195435\n    },\n    \"time_since_restore\": {\n      \"max\": 36.154643297195435,\n      \"min\": 36.154643297195435,\n      \"avg\": 36.154643297195435,\n      \"last\": 36.154643297195435,\n      \"last-5-avg\": 36.154643297195435,\n      \"last-10-avg\": 36.154643297195435\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447404213cb5a000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447404213cb5a000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447404213cb5a000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447404213cb5a000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447404213cb5a000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447404213cb5a000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1655015273.8484817,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_b4a464ba_11___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=27,lr=2.1098e-06,weight_decay_2022-06-12_14-27-17\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"ca77f28e\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 26,\n    \"lr\": 2.30451415823525e-07,\n    \"weight_decay\": 3.2837442211387404e-06,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 26,\n    \"lr\": 2.30451415823525e-07,\n    \"weight_decay\": 3.2837442211387404e-06,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"12___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=26,lr=2.3045e-07,weight_decay=3.2837e-06\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834373632373737367102580300000063707571034b014e747104512e80025d7100580e00000039343732393834373632373737367101612e01000000000000000000203f94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 34.48546743392944,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"ca77f28e\",\n    \"experiment_id\": \"541c0891953a48679001077e254a4fa6\",\n    \"date\": \"2022-06-12_14-31-36\",\n    \"timestamp\": 1655015496,\n    \"time_total_s\": 34.48546743392944,\n    \"pid\": 59965,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 26,\n      \"lr\": 2.30451415823525e-07,\n      \"weight_decay\": 3.2837442211387404e-06,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 34.48546743392944,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"12___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=26,lr=2.3045e-07,weight_decay=3.2837e-06\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655015496.9983952,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 34.48546743392944,\n      \"min\": 34.48546743392944,\n      \"avg\": 34.48546743392944,\n      \"last\": 34.48546743392944,\n      \"last-5-avg\": 34.48546743392944,\n      \"last-10-avg\": 34.48546743392944\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 34.48546743392944,\n      \"min\": 34.48546743392944,\n      \"avg\": 34.48546743392944,\n      \"last\": 34.48546743392944,\n      \"last-5-avg\": 34.48546743392944,\n      \"last-10-avg\": 34.48546743392944\n    },\n    \"time_since_restore\": {\n      \"max\": 34.48546743392944,\n      \"min\": 34.48546743392944,\n      \"avg\": 34.48546743392944,\n      \"last\": 34.48546743392944,\n      \"last-5-avg\": 34.48546743392944,\n      \"last-10-avg\": 34.48546743392944\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740413e23cc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740413e23cc000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740413e23cc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740413e23cc000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740413e23cc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740413e23cc000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1655015455.0230174,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_ca77f28e_12___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=26,lr=2.3045e-07,weight_decay_2022-06-12_14-27-53\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"367414ae\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 112,\n    \"lr\": 9.45036277356089e-05,\n    \"weight_decay\": 3.354981593582683e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 112,\n    \"lr\": 9.45036277356089e-05,\n    \"weight_decay\": 3.354981593582683e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"13___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=112,lr=9.4504e-05,weight_decay=3.355e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834373635363238387102580300000063707571034b014e747104512e80025d7100580e00000039343732393834373635363238387101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 28.660590171813965,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"367414ae\",\n    \"experiment_id\": \"f30f476d58254372b5dcae4cdf162f0a\",\n    \"date\": \"2022-06-12_14-40-19\",\n    \"timestamp\": 1655016019,\n    \"time_total_s\": 28.660590171813965,\n    \"pid\": 59966,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 112,\n      \"lr\": 9.45036277356089e-05,\n      \"weight_decay\": 3.354981593582683e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 28.660590171813965,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"13___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=112,lr=9.4504e-05,weight_decay=3.355e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655016019.2255094,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 28.660590171813965,\n      \"min\": 28.660590171813965,\n      \"avg\": 28.660590171813965,\n      \"last\": 28.660590171813965,\n      \"last-5-avg\": 28.660590171813965,\n      \"last-10-avg\": 28.660590171813965\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 28.660590171813965,\n      \"min\": 28.660590171813965,\n      \"avg\": 28.660590171813965,\n      \"last\": 28.660590171813965,\n      \"last-5-avg\": 28.660590171813965,\n      \"last-10-avg\": 28.660590171813965\n    },\n    \"time_since_restore\": {\n      \"max\": 28.660590171813965,\n      \"min\": 28.660590171813965,\n      \"avg\": 28.660590171813965,\n      \"last\": 28.660590171813965,\n      \"last-5-avg\": 28.660590171813965,\n      \"last-10-avg\": 28.660590171813965\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403ca91c70000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403ca91c70000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403ca91c70000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403ca91c70000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403ca91c70000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403ca91c70000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655015982.7854798,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_367414ae_13___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=112,lr=9.4504e-05,weight_deca_2022-06-12_14-30-55\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"71062a84\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 80,\n    \"lr\": 8.160666892574553e-05,\n    \"weight_decay\": 2.353810687098248e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 80,\n    \"lr\": 8.160666892574553e-05,\n    \"weight_decay\": 2.353810687098248e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"14___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=80,lr=8.1607e-05,weight_decay=2.3538e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834373230393437327102580300000063707571034b014e747104512e80025d7100580e00000039343732393834373230393437327101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 30.00856900215149,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"71062a84\",\n    \"experiment_id\": \"8582f47ba9784d969571107589b81fb0\",\n    \"date\": \"2022-06-12_14-41-01\",\n    \"timestamp\": 1655016061,\n    \"time_total_s\": 30.00856900215149,\n    \"pid\": 59962,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 80,\n      \"lr\": 8.160666892574553e-05,\n      \"weight_decay\": 2.353810687098248e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 30.00856900215149,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"14___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=80,lr=8.1607e-05,weight_decay=2.3538e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655016061.1928473,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 30.00856900215149,\n      \"min\": 30.00856900215149,\n      \"avg\": 30.00856900215149,\n      \"last\": 30.00856900215149,\n      \"last-5-avg\": 30.00856900215149,\n      \"last-10-avg\": 30.00856900215149\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 30.00856900215149,\n      \"min\": 30.00856900215149,\n      \"avg\": 30.00856900215149,\n      \"last\": 30.00856900215149,\n      \"last-5-avg\": 30.00856900215149,\n      \"last-10-avg\": 30.00856900215149\n    },\n    \"time_since_restore\": {\n      \"max\": 30.00856900215149,\n      \"min\": 30.00856900215149,\n      \"avg\": 30.00856900215149,\n      \"last\": 30.00856900215149,\n      \"last-5-avg\": 30.00856900215149,\n      \"last-10-avg\": 30.00856900215149\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403e023194000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403e023194000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403e023194000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403e023194000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403e023194000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403e023194000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655016022.293841,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_71062a84_14___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=80,lr=8.1607e-05,weight_decay_2022-06-12_14-39-42\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"8893e362\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 112,\n    \"lr\": 2.1693591798799312e-08,\n    \"weight_decay\": 4.433599955544587e-06,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 112,\n    \"lr\": 2.1693591798799312e-08,\n    \"weight_decay\": 4.433599955544587e-06,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"15___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=112,lr=2.1694e-08,weight_decay=4.4336e-06\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834323135303939327102580300000063707571034b014e747104512e80025d7100580e00000039343732393834323135303939327101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 26.767937898635864,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"8893e362\",\n    \"experiment_id\": \"312eb58a4b5a463b98c949fdbb6c7fe9\",\n    \"date\": \"2022-06-12_14-41-38\",\n    \"timestamp\": 1655016098,\n    \"time_total_s\": 26.767937898635864,\n    \"pid\": 59963,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 112,\n      \"lr\": 2.1693591798799312e-08,\n      \"weight_decay\": 4.433599955544587e-06,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 26.767937898635864,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"15___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=112,lr=2.1694e-08,weight_decay=4.4336e-06\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655016098.5783043,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 26.767937898635864,\n      \"min\": 26.767937898635864,\n      \"avg\": 26.767937898635864,\n      \"last\": 26.767937898635864,\n      \"last-5-avg\": 26.767937898635864,\n      \"last-10-avg\": 26.767937898635864\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 26.767937898635864,\n      \"min\": 26.767937898635864,\n      \"avg\": 26.767937898635864,\n      \"last\": 26.767937898635864,\n      \"last-5-avg\": 26.767937898635864,\n      \"last-10-avg\": 26.767937898635864\n    },\n    \"time_since_restore\": {\n      \"max\": 26.767937898635864,\n      \"min\": 26.767937898635864,\n      \"avg\": 26.767937898635864,\n      \"last\": 26.767937898635864,\n      \"last-5-avg\": 26.767937898635864,\n      \"last-10-avg\": 26.767937898635864\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403ac49794000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403ac49794000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403ac49794000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403ac49794000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403ac49794000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403ac49794000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655016064.2964852,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_8893e362_15___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=112,lr=2.1694e-08,weight_deca_2022-06-12_14-40-22\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"a19d290e\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 71,\n    \"lr\": 7.545658768908755e-06,\n    \"weight_decay\": 5.4197367063368954e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 71,\n    \"lr\": 7.545658768908755e-06,\n    \"weight_decay\": 5.4197367063368954e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"16___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=71,lr=7.5457e-06,weight_decay=5.4197e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834373631323030307102580300000063707571034b014e747104512e80025d7100580e00000039343732393834373631323030307101612e01000000000000000000203f94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 30.92141366004944,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"a19d290e\",\n    \"experiment_id\": \"4279d05733274bf19a6915a3afd533fc\",\n    \"date\": \"2022-06-12_14-42-20\",\n    \"timestamp\": 1655016140,\n    \"time_total_s\": 30.92141366004944,\n    \"pid\": 59961,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 71,\n      \"lr\": 7.545658768908755e-06,\n      \"weight_decay\": 5.4197367063368954e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 30.92141366004944,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"16___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=71,lr=7.5457e-06,weight_decay=5.4197e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655016140.1396687,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 30.92141366004944,\n      \"min\": 30.92141366004944,\n      \"avg\": 30.92141366004944,\n      \"last\": 30.92141366004944,\n      \"last-5-avg\": 30.92141366004944,\n      \"last-10-avg\": 30.92141366004944\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 30.92141366004944,\n      \"min\": 30.92141366004944,\n      \"avg\": 30.92141366004944,\n      \"last\": 30.92141366004944,\n      \"last-5-avg\": 30.92141366004944,\n      \"last-10-avg\": 30.92141366004944\n    },\n    \"time_since_restore\": {\n      \"max\": 30.92141366004944,\n      \"min\": 30.92141366004944,\n      \"avg\": 30.92141366004944,\n      \"last\": 30.92141366004944,\n      \"last-5-avg\": 30.92141366004944,\n      \"last-10-avg\": 30.92141366004944\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403eebe1c4000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403eebe1c4000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403eebe1c4000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403eebe1c4000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403eebe1c4000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403eebe1c4000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1655016101.609204,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_a19d290e_16___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=71,lr=7.5457e-06,weight_decay_2022-06-12_14-41-04\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"b7dc375a\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 76,\n    \"lr\": 2.0721541066527486e-05,\n    \"weight_decay\": 3.963788873286078e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 76,\n    \"lr\": 2.0721541066527486e-05,\n    \"weight_decay\": 3.963788873286078e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"17___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=76,lr=2.0722e-05,weight_decay=3.9638e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"trial_id\": \"b7dc375a\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"start_time\": null,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_b7dc375a_17___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=76,lr=2.0722e-05,weight_decay_2022-06-12_14-41-41\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_insufficient_resources_manager": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059588000000000000008c277261792e74756e652e696e73756666696369656e745f7265736f75726365735f6d616e61676572948c1c496e73756666696369656e745265736f75726365734d616e616765729493942981947d94288c185f6e6f5f72756e6e696e675f747269616c735f73696e6365944affffffff8c0f5f6c6173745f747269616c5f6e756d944b0175622e"
    },
    "_max_pending_trials": 1,
    "_metric": null,
    "_total_time": 42750.541882276535,
    "_iteration": 17709,
    "_has_errored": false,
    "_fail_fast": false,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_updated_queue": false,
    "_result_wait_time": 1,
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "/home/xwm/DeepSVFilter/code/tune_asha",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "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"
    },
    "_resumed": false,
    "_start_time": 1655001334.492541,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2022-06-12_10-35-34",
    "checkpoint_file": "/home/xwm/DeepSVFilter/code/tune_asha/experiment_state-2022-06-12_10-35-34.json",
    "_checkpoint_period": "auto",
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1655001334.492541,
    "timestamp": 1655018807.328149
  }
}