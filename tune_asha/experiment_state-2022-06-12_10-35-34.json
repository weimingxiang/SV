{
  "checkpoints": [
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"55f566c8\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 350,\n    \"lr\": 4.662880795764871e-08,\n    \"weight_decay\": 1.6489046820149402e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 350,\n    \"lr\": 4.662880795764871e-08,\n    \"weight_decay\": 1.6489046820149402e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"1___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=350,lr=4.6629e-08,weight_decay=1.6489e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834323134393438387102580300000063707571034b014e747104512e80025d7100580e00000039343732393834323134393438387101612e01000000000000004e91ab3e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 3553.1837334632874,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 3,\n    \"trial_id\": \"55f566c8\",\n    \"experiment_id\": \"189c3f7777cc415491888d2bb71c532f\",\n    \"date\": \"2022-06-12_12-34-01\",\n    \"timestamp\": 1655008441,\n    \"time_total_s\": 7099.3270354270935,\n    \"pid\": 59971,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 350,\n      \"lr\": 4.662880795764871e-08,\n      \"weight_decay\": 1.6489046820149402e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 7099.3270354270935,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 3,\n    \"experiment_tag\": \"1___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=350,lr=4.6629e-08,weight_decay=1.6489e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655008441.104251,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 3553.1837334632874,\n      \"min\": 27.823471784591675,\n      \"avg\": 2366.4423451423645,\n      \"last\": 3553.1837334632874,\n      \"last-5-avg\": 2366.4423451423645,\n      \"last-10-avg\": 2366.4423451423645\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.3333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.3333333333333333,\n      \"last-10-avg\": 0.3333333333333333\n    },\n    \"training_iteration\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"time_total_s\": {\n      \"max\": 7099.3270354270935,\n      \"min\": 27.823471784591675,\n      \"avg\": 3557.764603058497,\n      \"last\": 7099.3270354270935,\n      \"last-5-avg\": 3557.764603058497,\n      \"last-10-avg\": 3557.764603058497\n    },\n    \"time_since_restore\": {\n      \"max\": 7099.3270354270935,\n      \"min\": 27.823471784591675,\n      \"avg\": 3557.764603058497,\n      \"last\": 7099.3270354270935,\n      \"last-5-avg\": 3557.764603058497,\n      \"last-10-avg\": 3557.764603058497\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403bd2cf0c0000004740ab7ca3c0c800004740abc25e12500000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403bd2cf0c0000004740ab7ca3c0c800004740abc25e12500000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403bd2cf0c0000004740abb4495ee000004740bbbb53b8980000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403bd2cf0c0000004740abb4495ee000004740bbbb53b8980000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403bd2cf0c0000004740abb4495ee000004740bbbb53b8980000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403bd2cf0c0000004740abb4495ee000004740bbbb53b8980000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655001334.7910328,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_55f566c8_1___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=350,lr=4.6629e-08,weight_decay_2022-06-12_10-35-34\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"563938e4\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 79,\n    \"lr\": 1.0044313618961752e-08,\n    \"weight_decay\": 7.902669512100982e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 79,\n    \"lr\": 1.0044313618961752e-08,\n    \"weight_decay\": 7.902669512100982e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"3___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=79,lr=1.0044e-08,weight_decay=7.9027e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834363636383238387102580300000063707571034b014e747104512e80025d7100580e00000039343732393834363636383238387101612e0100000000000000c324a53e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 4141.1884388923645,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 2,\n    \"trial_id\": \"563938e4\",\n    \"experiment_id\": \"c1cbb40abf8349f4a82ef2595c5c6de2\",\n    \"date\": \"2022-06-12_11-45-10\",\n    \"timestamp\": 1655005510,\n    \"time_total_s\": 4168.275222063065,\n    \"pid\": 59968,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 79,\n      \"lr\": 1.0044313618961752e-08,\n      \"weight_decay\": 7.902669512100982e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 4168.275222063065,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"3___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=79,lr=1.0044e-08,weight_decay=7.9027e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655005510.79351,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 4141.1884388923645,\n      \"min\": 27.086783170700073,\n      \"avg\": 2084.1376110315323,\n      \"last\": 4141.1884388923645,\n      \"last-5-avg\": 2084.1376110315323,\n      \"last-10-avg\": 2084.1376110315323\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_total_s\": {\n      \"max\": 4168.275222063065,\n      \"min\": 27.086783170700073,\n      \"avg\": 2097.6810026168823,\n      \"last\": 4168.275222063065,\n      \"last-5-avg\": 2097.6810026168823,\n      \"last-10-avg\": 2097.6810026168823\n    },\n    \"time_since_restore\": {\n      \"max\": 4168.275222063065,\n      \"min\": 27.086783170700073,\n      \"avg\": 2097.6810026168823,\n      \"last\": 4168.275222063065,\n      \"last-5-avg\": 2097.6810026168823,\n      \"last-10-avg\": 2097.6810026168823\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403b16376c0000004740b02d303d880000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403b16376c0000004740b02d303d880000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403b16376c0000004740b0484674f40000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403b16376c0000004740b0484674f40000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403b16376c0000004740b0484674f40000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403b16376c0000004740b0484674f40000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655001335.0567892,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_563938e4_3___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=79,lr=1.0044e-08,weight_decay=_2022-06-12_10-35-34\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"5624c7a6\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 37,\n    \"lr\": 5.273926439012544e-05,\n    \"weight_decay\": 6.69553864040595e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 37,\n    \"lr\": 5.273926439012544e-05,\n    \"weight_decay\": 6.69553864040595e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"2___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=37,lr=5.2739e-05,weight_decay=6.6955e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834373632313734347102580300000063707571034b014e747104512e80025d7100580e00000039343732393834373632313734347101612e0100000000000000ef49af3e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 4980.828709363937,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 3,\n    \"trial_id\": \"5624c7a6\",\n    \"experiment_id\": \"1e3d6c6d7aa443c9ad7b85cb99b30a1f\",\n    \"date\": \"2022-06-12_13-21-48\",\n    \"timestamp\": 1655011308,\n    \"time_total_s\": 9965.713065385818,\n    \"pid\": 59959,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 37,\n      \"lr\": 5.273926439012544e-05,\n      \"weight_decay\": 6.69553864040595e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 9965.713065385818,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 3,\n    \"experiment_tag\": \"2___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=37,lr=5.2739e-05,weight_decay=6.6955e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655011308.053561,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 4980.828709363937,\n      \"min\": 29.58536386489868,\n      \"avg\": 3321.904355128606,\n      \"last\": 4980.828709363937,\n      \"last-5-avg\": 3321.9043551286063,\n      \"last-10-avg\": 3321.9043551286063\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.3333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.3333333333333333,\n      \"last-10-avg\": 0.3333333333333333\n    },\n    \"training_iteration\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"time_total_s\": {\n      \"max\": 9965.713065385818,\n      \"min\": 29.58536386489868,\n      \"avg\": 4993.394261757532,\n      \"last\": 9965.713065385818,\n      \"last-5-avg\": 4993.394261757533,\n      \"last-10-avg\": 4993.394261757533\n    },\n    \"time_since_restore\": {\n      \"max\": 9965.713065385818,\n      \"min\": 29.58536386489868,\n      \"avg\": 4993.394261757532,\n      \"last\": 9965.713065385818,\n      \"last-5-avg\": 4993.394261757533,\n      \"last-10-avg\": 4993.394261757533\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403d95da680000004740b35b4c8ac000004740b374d4264c0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403d95da680000004740b35b4c8ac000004740b374d4264c0000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403d95da680000004740b378e2652800004740c376db45ba0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403d95da680000004740b378e2652800004740c376db45ba0000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403d95da680000004740b378e2652800004740c376db45ba0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403d95da680000004740b378e2652800004740c376db45ba0000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655001334.9307156,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_5624c7a6_2___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=37,lr=5.2739e-05,weight_decay=_2022-06-12_10-35-34\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"564fcc94\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 39,\n    \"lr\": 6.124242249635632e-06,\n    \"weight_decay\": 6.0682337589575936e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 39,\n    \"lr\": 6.124242249635632e-06,\n    \"weight_decay\": 6.0682337589575936e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"4___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=39,lr=6.1242e-06,weight_decay=6.0682e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834373635363439367102580300000063707571034b014e747104512e80025d7100580e00000039343732393834373635363439367101612e0100000000000000ef49af3e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 4962.647962093353,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 3,\n    \"trial_id\": \"564fcc94\",\n    \"experiment_id\": \"88182d24a2254e50b3fe520729f6e305\",\n    \"date\": \"2022-06-12_14-30-51\",\n    \"timestamp\": 1655015451,\n    \"time_total_s\": 9928.595785856247,\n    \"pid\": 59979,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 39,\n      \"lr\": 6.124242249635632e-06,\n      \"weight_decay\": 6.0682337589575936e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 9928.595785856247,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 3,\n    \"experiment_tag\": \"4___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=39,lr=6.1242e-06,weight_decay=6.0682e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655015452.0029023,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 4962.647962093353,\n      \"min\": 32.05570125579834,\n      \"avg\": 3309.5319286187487,\n      \"last\": 4962.647962093353,\n      \"last-5-avg\": 3309.531928618749,\n      \"last-10-avg\": 3309.531928618749\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.3333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.3333333333333333,\n      \"last-10-avg\": 0.3333333333333333\n    },\n    \"training_iteration\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"time_total_s\": {\n      \"max\": 9928.595785856247,\n      \"min\": 32.05570125579834,\n      \"avg\": 4975.533103624979,\n      \"last\": 9928.595785856247,\n      \"last-5-avg\": 4975.53310362498,\n      \"last-10-avg\": 4975.53310362498\n    },\n    \"time_since_restore\": {\n      \"max\": 9928.595785856247,\n      \"min\": 32.05570125579834,\n      \"avg\": 4975.533103624979,\n      \"last\": 9928.595785856247,\n      \"last-5-avg\": 4975.53310362498,\n      \"last-10-avg\": 4975.53310362498\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740400721380000004740b345e4622400004740b362a5e0d80000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740400721380000004740b345e4622400004740b362a5e0d80000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740400721380000004740b365f2a49400004740c3644c42b60000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740400721380000004740b365f2a49400004740c3644c42b60000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740400721380000004740b365f2a49400004740c3644c42b60000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740400721380000004740b365f2a49400004740c3644c42b60000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655005514.040359,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_564fcc94_4___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=39,lr=6.1242e-06,weight_decay=_2022-06-12_10-35-35\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"112c8224\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 170,\n    \"lr\": 3.236127830260763e-06,\n    \"weight_decay\": 8.414338194138929e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 170,\n    \"lr\": 3.236127830260763e-06,\n    \"weight_decay\": 8.414338194138929e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"5___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=170,lr=3.2361e-06,weight_decay=8.4143e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834373339313639367102580300000063707571034b014e747104512e80025d7100580e00000039343732393834373339313639367101612e0100000000000000ef49af3e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 3754.1890075206757,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 3,\n    \"trial_id\": \"112c8224\",\n    \"experiment_id\": \"911aa613816646b78f3d475324e9f311\",\n    \"date\": \"2022-06-12_14-39-39\",\n    \"timestamp\": 1655015979,\n    \"time_total_s\": 7509.123656272888,\n    \"pid\": 59957,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 170,\n      \"lr\": 3.236127830260763e-06,\n      \"weight_decay\": 8.414338194138929e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 7509.123656272888,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 3,\n    \"experiment_tag\": \"5___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=170,lr=3.2361e-06,weight_decay=8.4143e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655015979.6011205,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 3754.1890075206757,\n      \"min\": 29.74102473258972,\n      \"avg\": 2503.0412187576294,\n      \"last\": 3754.1890075206757,\n      \"last-5-avg\": 2503.0412187576294,\n      \"last-10-avg\": 2503.0412187576294\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.3333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.3333333333333333,\n      \"last-10-avg\": 0.3333333333333333\n    },\n    \"training_iteration\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"time_total_s\": {\n      \"max\": 7509.123656272888,\n      \"min\": 29.74102473258972,\n      \"avg\": 3764.5997765858965,\n      \"last\": 7509.123656272888,\n      \"last-5-avg\": 3764.599776585897,\n      \"last-10-avg\": 3764.599776585897\n    },\n    \"time_since_restore\": {\n      \"max\": 7509.123656272888,\n      \"min\": 29.74102473258972,\n      \"avg\": 3764.5997765858965,\n      \"last\": 7509.123656272888,\n      \"last-5-avg\": 3764.599776585897,\n      \"last-10-avg\": 3764.599776585897\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403dbdb3cc0000004740ad1a6322b000004740ad5460c5980000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403dbdb3cc0000004740ad1a6322b000004740ad5460c5980000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403dbdb3cc0000004740ad55de8a4800004740bd551fa7f00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403dbdb3cc0000004740ad55de8a4800004740bd551fa7f00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403dbdb3cc0000004740ad55de8a4800004740bd551fa7f00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403dbdb3cc0000004740ad55de8a4800004740bd551fa7f00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655008444.2108793,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_112c8224_5___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=170,lr=3.2361e-06,weight_decay_2022-06-12_11-45-14\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"e3bad8b6\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 155,\n    \"lr\": 3.617511711950156e-05,\n    \"weight_decay\": 1.0606585772190014e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 155,\n    \"lr\": 3.617511711950156e-05,\n    \"weight_decay\": 1.0606585772190014e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"6___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=155,lr=3.6175e-05,weight_decay=1.0607e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834373630343738347102580300000063707571034b014e747104512e80025d7100580e00000039343732393834373630343738347101612e01000000000000004e91ab3e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 3750.0612659454346,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 2,\n    \"trial_id\": \"e3bad8b6\",\n    \"experiment_id\": \"716d61001b3a41b5b643fc912771f5e3\",\n    \"date\": \"2022-06-12_14-25-02\",\n    \"timestamp\": 1655015102,\n    \"time_total_s\": 3775.7091035842896,\n    \"pid\": 59978,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 155,\n      \"lr\": 3.617511711950156e-05,\n      \"weight_decay\": 1.0606585772190014e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 3775.7091035842896,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"6___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=155,lr=3.6175e-05,weight_decay=1.0607e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655015102.2110333,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 3750.0612659454346,\n      \"min\": 25.64783763885498,\n      \"avg\": 1887.8545517921448,\n      \"last\": 3750.0612659454346,\n      \"last-5-avg\": 1887.8545517921448,\n      \"last-10-avg\": 1887.8545517921448\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_total_s\": {\n      \"max\": 3775.7091035842896,\n      \"min\": 25.64783763885498,\n      \"avg\": 1900.6784706115723,\n      \"last\": 3775.7091035842896,\n      \"last-5-avg\": 1900.6784706115723,\n      \"last-10-avg\": 1900.6784706115723\n    },\n    \"time_since_restore\": {\n      \"max\": 3775.7091035842896,\n      \"min\": 25.64783763885498,\n      \"avg\": 1900.6784706115723,\n      \"last\": 3775.7091035842896,\n      \"last-5-avg\": 1900.6784706115723,\n      \"last-10-avg\": 1900.6784706115723\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474039a5d8b00000004740ad4c1f5e400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474039a5d8b00000004740ad4c1f5e400000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474039a5d8b00000004740ad7f6b0fa00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474039a5d8b00000004740ad7f6b0fa00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474039a5d8b00000004740ad7f6b0fa00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474039a5d8b00000004740ad7f6b0fa00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655011311.1558425,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_e3bad8b6_6___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=155,lr=3.6175e-05,weight_decay_2022-06-12_12-34-04\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"908b455c\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 49,\n    \"lr\": 9.72172237656587e-08,\n    \"weight_decay\": 1.8409354927323486e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 49,\n    \"lr\": 9.72172237656587e-08,\n    \"weight_decay\": 1.8409354927323486e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"7___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=49,lr=9.7217e-08,weight_decay=1.8409e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834373632313734347102580300000063707571034b014e747104512e80025d7100580e00000039343732393834373632313734347101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 33.039878368377686,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"908b455c\",\n    \"experiment_id\": \"96c6da124bfd4875aa77056de0186a0f\",\n    \"date\": \"2022-06-12_14-25-53\",\n    \"timestamp\": 1655015153,\n    \"time_total_s\": 33.039878368377686,\n    \"pid\": 59958,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 49,\n      \"lr\": 9.72172237656587e-08,\n      \"weight_decay\": 1.8409354927323486e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 33.039878368377686,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"7___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=49,lr=9.7217e-08,weight_decay=1.8409e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655015153.224174,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 33.039878368377686,\n      \"min\": 33.039878368377686,\n      \"avg\": 33.039878368377686,\n      \"last\": 33.039878368377686,\n      \"last-5-avg\": 33.039878368377686,\n      \"last-10-avg\": 33.039878368377686\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 33.039878368377686,\n      \"min\": 33.039878368377686,\n      \"avg\": 33.039878368377686,\n      \"last\": 33.039878368377686,\n      \"last-5-avg\": 33.039878368377686,\n      \"last-10-avg\": 33.039878368377686\n    },\n    \"time_since_restore\": {\n      \"max\": 33.039878368377686,\n      \"min\": 33.039878368377686,\n      \"avg\": 33.039878368377686,\n      \"last\": 33.039878368377686,\n      \"last-5-avg\": 33.039878368377686,\n      \"last-10-avg\": 33.039878368377686\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474040851abc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474040851abc000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474040851abc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474040851abc000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474040851abc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474040851abc000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655015105.3376844,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_908b455c_7___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=49,lr=9.7217e-08,weight_decay=_2022-06-12_13-21-51\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"6606faa2\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 313,\n    \"lr\": 3.870947830528618e-08,\n    \"weight_decay\": 3.4320950481911706e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 313,\n    \"lr\": 3.870947830528618e-08,\n    \"weight_decay\": 3.4320950481911706e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"8___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=313,lr=3.8709e-08,weight_decay=3.4321e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834323236363335327102580300000063707571034b014e747104512e80025d7100580e00000039343732393834323236363335327101612e01000000000000000000803e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 23.32670760154724,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"6606faa2\",\n    \"experiment_id\": \"c207bf5499604f9eaf26096ccc386bc8\",\n    \"date\": \"2022-06-12_14-26-27\",\n    \"timestamp\": 1655015187,\n    \"time_total_s\": 23.32670760154724,\n    \"pid\": 59977,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 313,\n      \"lr\": 3.870947830528618e-08,\n      \"weight_decay\": 3.4320950481911706e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 23.32670760154724,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"8___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=313,lr=3.8709e-08,weight_decay=3.4321e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655015187.8606176,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 23.32670760154724,\n      \"min\": 23.32670760154724,\n      \"avg\": 23.32670760154724,\n      \"last\": 23.32670760154724,\n      \"last-5-avg\": 23.32670760154724,\n      \"last-10-avg\": 23.32670760154724\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 23.32670760154724,\n      \"min\": 23.32670760154724,\n      \"avg\": 23.32670760154724,\n      \"last\": 23.32670760154724,\n      \"last-5-avg\": 23.32670760154724,\n      \"last-10-avg\": 23.32670760154724\n    },\n    \"time_since_restore\": {\n      \"max\": 23.32670760154724,\n      \"min\": 23.32670760154724,\n      \"avg\": 23.32670760154724,\n      \"last\": 23.32670760154724,\n      \"last-5-avg\": 23.32670760154724,\n      \"last-10-avg\": 23.32670760154724\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403753a31c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403753a31c000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403753a31c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403753a31c000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403753a31c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403753a31c000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655015156.2531726,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_6606faa2_8___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=313,lr=3.8709e-08,weight_decay_2022-06-12_14-25-05\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"845ef676\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 35,\n    \"lr\": 2.7613082024724424e-06,\n    \"weight_decay\": 1.5204069432228107e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 35,\n    \"lr\": 2.7613082024724424e-06,\n    \"weight_decay\": 1.5204069432228107e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"9___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=35,lr=2.7613e-06,weight_decay=1.5204e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834363636323338347102580300000063707571034b014e747104512e80025d7100580e00000039343732393834363636323338347101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 34.19461011886597,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"845ef676\",\n    \"experiment_id\": \"3bdec805435948bdb2362c340010b8db\",\n    \"date\": \"2022-06-12_14-27-14\",\n    \"timestamp\": 1655015234,\n    \"time_total_s\": 34.19461011886597,\n    \"pid\": 59974,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 35,\n      \"lr\": 2.7613082024724424e-06,\n      \"weight_decay\": 1.5204069432228107e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 34.19461011886597,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"9___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=35,lr=2.7613e-06,weight_decay=1.5204e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655015234.0545235,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 34.19461011886597,\n      \"min\": 34.19461011886597,\n      \"avg\": 34.19461011886597,\n      \"last\": 34.19461011886597,\n      \"last-5-avg\": 34.19461011886597,\n      \"last-10-avg\": 34.19461011886597\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 34.19461011886597,\n      \"min\": 34.19461011886597,\n      \"avg\": 34.19461011886597,\n      \"last\": 34.19461011886597,\n      \"last-5-avg\": 34.19461011886597,\n      \"last-10-avg\": 34.19461011886597\n    },\n    \"time_since_restore\": {\n      \"max\": 34.19461011886597,\n      \"min\": 34.19461011886597,\n      \"avg\": 34.19461011886597,\n      \"last\": 34.19461011886597,\n      \"last-5-avg\": 34.19461011886597,\n      \"last-10-avg\": 34.19461011886597\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447404118e8fc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447404118e8fc000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447404118e8fc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447404118e8fc000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447404118e8fc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447404118e8fc000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655015190.9261708,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_845ef676_9___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=35,lr=2.7613e-06,weight_decay=_2022-06-12_14-25-56\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"990d32ae\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 535,\n    \"lr\": 2.828990584659825e-06,\n    \"weight_decay\": 1.5248049804146847e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 535,\n    \"lr\": 2.828990584659825e-06,\n    \"weight_decay\": 1.5248049804146847e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"10___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=535,lr=2.829e-06,weight_decay=1.5248e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834323138333239367102580300000063707571034b014e747104512e80025d7100580e00000039343732393834323138333239367101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 26.23819613456726,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"990d32ae\",\n    \"experiment_id\": \"50b203c50ae443ff9bcade581da95324\",\n    \"date\": \"2022-06-12_14-27-50\",\n    \"timestamp\": 1655015270,\n    \"time_total_s\": 26.23819613456726,\n    \"pid\": 59960,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 535,\n      \"lr\": 2.828990584659825e-06,\n      \"weight_decay\": 1.5248049804146847e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 26.23819613456726,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"10___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=535,lr=2.829e-06,weight_decay=1.5248e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655015270.7750535,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 26.23819613456726,\n      \"min\": 26.23819613456726,\n      \"avg\": 26.23819613456726,\n      \"last\": 26.23819613456726,\n      \"last-5-avg\": 26.23819613456726,\n      \"last-10-avg\": 26.23819613456726\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 26.23819613456726,\n      \"min\": 26.23819613456726,\n      \"avg\": 26.23819613456726,\n      \"last\": 26.23819613456726,\n      \"last-5-avg\": 26.23819613456726,\n      \"last-10-avg\": 26.23819613456726\n    },\n    \"time_since_restore\": {\n      \"max\": 26.23819613456726,\n      \"min\": 26.23819613456726,\n      \"avg\": 26.23819613456726,\n      \"last\": 26.23819613456726,\n      \"last-5-avg\": 26.23819613456726,\n      \"last-10-avg\": 26.23819613456726\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403a3cfa6c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403a3cfa6c000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403a3cfa6c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403a3cfa6c000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403a3cfa6c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403a3cfa6c000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655015237.2262468,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_990d32ae_10___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=535,lr=2.829e-06,weight_decay_2022-06-12_14-26-30\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"b4a464ba\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 27,\n    \"lr\": 2.1098014168856053e-06,\n    \"weight_decay\": 8.255122188588196e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 27,\n    \"lr\": 2.1098014168856053e-06,\n    \"weight_decay\": 8.255122188588196e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"11___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=27,lr=2.1098e-06,weight_decay=8.2551e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834373630353636347102580300000063707571034b014e747104512e80025d7100580e00000039343732393834373630353636347101612e0100000000000000ef49af3e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 5625.381126642227,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 3,\n    \"trial_id\": \"b4a464ba\",\n    \"experiment_id\": \"4904a48e506b42848334ffcf237e42ba\",\n    \"date\": \"2022-06-12_17-36-43\",\n    \"timestamp\": 1655026603,\n    \"time_total_s\": 11320.571524381638,\n    \"pid\": 59967,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 27,\n      \"lr\": 2.1098014168856053e-06,\n      \"weight_decay\": 8.255122188588196e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 11320.571524381638,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 3,\n    \"experiment_tag\": \"11___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=27,lr=2.1098e-06,weight_decay=8.2551e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655026603.7660298,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 5659.035754442215,\n      \"min\": 36.154643297195435,\n      \"avg\": 3773.5238414605456,\n      \"last\": 5625.381126642227,\n      \"last-5-avg\": 3773.523841460546,\n      \"last-10-avg\": 3773.523841460546\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.3333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.3333333333333333,\n      \"last-10-avg\": 0.3333333333333333\n    },\n    \"training_iteration\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"time_total_s\": {\n      \"max\": 11320.571524381638,\n      \"min\": 36.154643297195435,\n      \"avg\": 5683.972188472748,\n      \"last\": 11320.571524381638,\n      \"last-5-avg\": 5683.972188472748,\n      \"last-10-avg\": 5683.972188472748\n    },\n    \"time_since_restore\": {\n      \"max\": 11320.571524381638,\n      \"min\": 36.154643297195435,\n      \"avg\": 5683.972188472748,\n      \"last\": 11320.571524381638,\n      \"last-5-avg\": 5683.972188472748,\n      \"last-10-avg\": 5683.972188472748\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404213cb5a0000004740b61b09273400004740b5f96191840000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404213cb5a0000004740b61b09273400004740b5f96191840000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404213cb5a0000004740b63f30bde800004740c61c4927b60000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404213cb5a0000004740b63f30bde800004740c61c4927b60000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404213cb5a0000004740b63f30bde800004740c61c4927b60000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404213cb5a0000004740b63f30bde800004740c61c4927b60000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655015273.8484817,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_b4a464ba_11___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=27,lr=2.1098e-06,weight_decay_2022-06-12_14-27-17\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"ca77f28e\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 26,\n    \"lr\": 2.30451415823525e-07,\n    \"weight_decay\": 3.2837442211387404e-06,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 26,\n    \"lr\": 2.30451415823525e-07,\n    \"weight_decay\": 3.2837442211387404e-06,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"12___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=26,lr=2.3045e-07,weight_decay=3.2837e-06\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834323330353432347102580300000063707571034b014e747104512e80025d7100580e00000039343732393834323330353432347101612e0100000000000000ef49af3e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 5707.694234132767,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 3,\n    \"trial_id\": \"ca77f28e\",\n    \"experiment_id\": \"541c0891953a48679001077e254a4fa6\",\n    \"date\": \"2022-06-12_17-41-35\",\n    \"timestamp\": 1655026895,\n    \"time_total_s\": 11432.876506567001,\n    \"pid\": 59965,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 26,\n      \"lr\": 2.30451415823525e-07,\n      \"weight_decay\": 3.2837442211387404e-06,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 11432.876506567001,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 3,\n    \"experiment_tag\": \"12___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=26,lr=2.3045e-07,weight_decay=3.2837e-06\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655026895.3825748,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 5707.694234132767,\n      \"min\": 34.48546743392944,\n      \"avg\": 3810.9588355223336,\n      \"last\": 5707.694234132767,\n      \"last-5-avg\": 3810.9588355223336,\n      \"last-10-avg\": 3810.9588355223336\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.3333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.3333333333333333,\n      \"last-10-avg\": 0.3333333333333333\n    },\n    \"training_iteration\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"time_total_s\": {\n      \"max\": 11432.876506567001,\n      \"min\": 34.48546743392944,\n      \"avg\": 5730.848082145055,\n      \"last\": 11432.876506567001,\n      \"last-5-avg\": 5730.848082145055,\n      \"last-10-avg\": 5730.848082145055\n    },\n    \"time_since_restore\": {\n      \"max\": 11432.876506567001,\n      \"min\": 34.48546743392944,\n      \"avg\": 5730.848082145055,\n      \"last\": 11432.876506567001,\n      \"last-5-avg\": 5730.848082145055,\n      \"last-10-avg\": 5730.848082145055\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740413e23cc0000004740b63ab261d000004740b64bb1b9540000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740413e23cc0000004740b63ab261d000004740b64bb1b9540000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740413e23cc0000004740b65d2ea96800004740c65470315e0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740413e23cc0000004740b65d2ea96800004740c65470315e0000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740413e23cc0000004740b65d2ea96800004740c65470315e0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740413e23cc0000004740b65d2ea96800004740c65470315e0000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655015455.0230174,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_ca77f28e_12___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=26,lr=2.3045e-07,weight_decay_2022-06-12_14-27-53\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"367414ae\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 112,\n    \"lr\": 9.45036277356089e-05,\n    \"weight_decay\": 3.354981593582683e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 112,\n    \"lr\": 9.45036277356089e-05,\n    \"weight_decay\": 3.354981593582683e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"13___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=112,lr=9.4504e-05,weight_decay=3.355e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834373635363238387102580300000063707571034b014e747104512e80025d7100580e00000039343732393834373635363238387101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 28.660590171813965,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"367414ae\",\n    \"experiment_id\": \"f30f476d58254372b5dcae4cdf162f0a\",\n    \"date\": \"2022-06-12_14-40-19\",\n    \"timestamp\": 1655016019,\n    \"time_total_s\": 28.660590171813965,\n    \"pid\": 59966,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 112,\n      \"lr\": 9.45036277356089e-05,\n      \"weight_decay\": 3.354981593582683e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 28.660590171813965,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"13___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=112,lr=9.4504e-05,weight_decay=3.355e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655016019.2255094,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 28.660590171813965,\n      \"min\": 28.660590171813965,\n      \"avg\": 28.660590171813965,\n      \"last\": 28.660590171813965,\n      \"last-5-avg\": 28.660590171813965,\n      \"last-10-avg\": 28.660590171813965\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 28.660590171813965,\n      \"min\": 28.660590171813965,\n      \"avg\": 28.660590171813965,\n      \"last\": 28.660590171813965,\n      \"last-5-avg\": 28.660590171813965,\n      \"last-10-avg\": 28.660590171813965\n    },\n    \"time_since_restore\": {\n      \"max\": 28.660590171813965,\n      \"min\": 28.660590171813965,\n      \"avg\": 28.660590171813965,\n      \"last\": 28.660590171813965,\n      \"last-5-avg\": 28.660590171813965,\n      \"last-10-avg\": 28.660590171813965\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403ca91c70000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403ca91c70000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403ca91c70000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403ca91c70000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403ca91c70000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403ca91c70000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655015982.7854798,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_367414ae_13___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=112,lr=9.4504e-05,weight_deca_2022-06-12_14-30-55\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"71062a84\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 80,\n    \"lr\": 8.160666892574553e-05,\n    \"weight_decay\": 2.353810687098248e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 80,\n    \"lr\": 8.160666892574553e-05,\n    \"weight_decay\": 2.353810687098248e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"14___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=80,lr=8.1607e-05,weight_decay=2.3538e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834373230393437327102580300000063707571034b014e747104512e80025d7100580e00000039343732393834373230393437327101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 30.00856900215149,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"71062a84\",\n    \"experiment_id\": \"8582f47ba9784d969571107589b81fb0\",\n    \"date\": \"2022-06-12_14-41-01\",\n    \"timestamp\": 1655016061,\n    \"time_total_s\": 30.00856900215149,\n    \"pid\": 59962,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 80,\n      \"lr\": 8.160666892574553e-05,\n      \"weight_decay\": 2.353810687098248e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 30.00856900215149,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"14___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=80,lr=8.1607e-05,weight_decay=2.3538e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655016061.1928473,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 30.00856900215149,\n      \"min\": 30.00856900215149,\n      \"avg\": 30.00856900215149,\n      \"last\": 30.00856900215149,\n      \"last-5-avg\": 30.00856900215149,\n      \"last-10-avg\": 30.00856900215149\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 30.00856900215149,\n      \"min\": 30.00856900215149,\n      \"avg\": 30.00856900215149,\n      \"last\": 30.00856900215149,\n      \"last-5-avg\": 30.00856900215149,\n      \"last-10-avg\": 30.00856900215149\n    },\n    \"time_since_restore\": {\n      \"max\": 30.00856900215149,\n      \"min\": 30.00856900215149,\n      \"avg\": 30.00856900215149,\n      \"last\": 30.00856900215149,\n      \"last-5-avg\": 30.00856900215149,\n      \"last-10-avg\": 30.00856900215149\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403e023194000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403e023194000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403e023194000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403e023194000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403e023194000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403e023194000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655016022.293841,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_71062a84_14___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=80,lr=8.1607e-05,weight_decay_2022-06-12_14-39-42\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"8893e362\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 112,\n    \"lr\": 2.1693591798799312e-08,\n    \"weight_decay\": 4.433599955544587e-06,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 112,\n    \"lr\": 2.1693591798799312e-08,\n    \"weight_decay\": 4.433599955544587e-06,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"15___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=112,lr=2.1694e-08,weight_decay=4.4336e-06\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834323135303939327102580300000063707571034b014e747104512e80025d7100580e00000039343732393834323135303939327101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 26.767937898635864,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"8893e362\",\n    \"experiment_id\": \"312eb58a4b5a463b98c949fdbb6c7fe9\",\n    \"date\": \"2022-06-12_14-41-38\",\n    \"timestamp\": 1655016098,\n    \"time_total_s\": 26.767937898635864,\n    \"pid\": 59963,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 112,\n      \"lr\": 2.1693591798799312e-08,\n      \"weight_decay\": 4.433599955544587e-06,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 26.767937898635864,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"15___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=112,lr=2.1694e-08,weight_decay=4.4336e-06\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655016098.5783043,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 26.767937898635864,\n      \"min\": 26.767937898635864,\n      \"avg\": 26.767937898635864,\n      \"last\": 26.767937898635864,\n      \"last-5-avg\": 26.767937898635864,\n      \"last-10-avg\": 26.767937898635864\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 26.767937898635864,\n      \"min\": 26.767937898635864,\n      \"avg\": 26.767937898635864,\n      \"last\": 26.767937898635864,\n      \"last-5-avg\": 26.767937898635864,\n      \"last-10-avg\": 26.767937898635864\n    },\n    \"time_since_restore\": {\n      \"max\": 26.767937898635864,\n      \"min\": 26.767937898635864,\n      \"avg\": 26.767937898635864,\n      \"last\": 26.767937898635864,\n      \"last-5-avg\": 26.767937898635864,\n      \"last-10-avg\": 26.767937898635864\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403ac49794000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403ac49794000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403ac49794000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403ac49794000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403ac49794000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403ac49794000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655016064.2964852,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_8893e362_15___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=112,lr=2.1694e-08,weight_deca_2022-06-12_14-40-22\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"a19d290e\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 71,\n    \"lr\": 7.545658768908755e-06,\n    \"weight_decay\": 5.4197367063368954e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 71,\n    \"lr\": 7.545658768908755e-06,\n    \"weight_decay\": 5.4197367063368954e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"16___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=71,lr=7.5457e-06,weight_decay=5.4197e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834383135383237327102580300000063707571034b014e747104512e80025d7100580e00000039343732393834383135383237327101612e0100000000000000ef49af3e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 4123.608369112015,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 3,\n    \"trial_id\": \"a19d290e\",\n    \"experiment_id\": \"4279d05733274bf19a6915a3afd533fc\",\n    \"date\": \"2022-06-12_17-00-20\",\n    \"timestamp\": 1655024420,\n    \"time_total_s\": 8311.606129646301,\n    \"pid\": 59961,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 71,\n      \"lr\": 7.545658768908755e-06,\n      \"weight_decay\": 5.4197367063368954e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 8311.606129646301,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 3,\n    \"experiment_tag\": \"16___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=71,lr=7.5457e-06,weight_decay=5.4197e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655024420.9057984,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 4157.076346874237,\n      \"min\": 30.92141366004944,\n      \"avg\": 2770.535376548767,\n      \"last\": 4123.608369112015,\n      \"last-5-avg\": 2770.535376548767,\n      \"last-10-avg\": 2770.535376548767\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.3333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.3333333333333333,\n      \"last-10-avg\": 0.3333333333333333\n    },\n    \"training_iteration\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"time_total_s\": {\n      \"max\": 8311.606129646301,\n      \"min\": 30.92141366004944,\n      \"avg\": 4176.8417679468785,\n      \"last\": 8311.606129646301,\n      \"last-5-avg\": 4176.841767946879,\n      \"last-10-avg\": 4176.841767946879\n    },\n    \"time_since_restore\": {\n      \"max\": 8311.606129646301,\n      \"min\": 30.92141366004944,\n      \"avg\": 4176.8417679468785,\n      \"last\": 8311.606129646301,\n      \"last-5-avg\": 4176.841767946879,\n      \"last-10-avg\": 4176.841767946879\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403eebe1c40000004740b03d138b7800004740b01b9bbe140000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403eebe1c40000004740b03d138b7800004740b01b9bbe140000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403eebe1c40000004740b05bff6d3c00004740c03bcd95a80000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403eebe1c40000004740b05bff6d3c00004740c03bcd95a80000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403eebe1c40000004740b05bff6d3c00004740c03bcd95a80000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403eebe1c40000004740b05bff6d3c00004740c03bcd95a80000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655016101.609204,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_a19d290e_16___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=71,lr=7.5457e-06,weight_decay_2022-06-12_14-41-04\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"b7dc375a\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 76,\n    \"lr\": 2.0721541066527486e-05,\n    \"weight_decay\": 3.963788873286078e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 76,\n    \"lr\": 2.0721541066527486e-05,\n    \"weight_decay\": 3.963788873286078e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"17___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=76,lr=2.0722e-05,weight_decay=3.9638e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834383233373032347102580300000063707571034b014e747104512e80025d7100580e00000039343732393834383233373032347101612e0100000000000000ef49af3e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 4146.993567943573,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 3,\n    \"trial_id\": \"b7dc375a\",\n    \"experiment_id\": \"43fb3136ff284e5ab975974ba103a7bd\",\n    \"date\": \"2022-06-12_19-18-58\",\n    \"timestamp\": 1655032738,\n    \"time_total_s\": 8303.317385911942,\n    \"pid\": 178337,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 76,\n      \"lr\": 2.0721541066527486e-05,\n      \"weight_decay\": 3.963788873286078e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 8303.317385911942,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 3,\n    \"experiment_tag\": \"17___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=76,lr=2.0722e-05,weight_decay=3.9638e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655032738.1142256,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 4146.993567943573,\n      \"min\": 29.387187480926514,\n      \"avg\": 2767.772461970647,\n      \"last\": 4146.993567943573,\n      \"last-5-avg\": 2767.7724619706473,\n      \"last-10-avg\": 2767.7724619706473\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.3333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.3333333333333333,\n      \"last-10-avg\": 0.3333333333333333\n    },\n    \"training_iteration\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"time_total_s\": {\n      \"max\": 8303.317385911942,\n      \"min\": 29.387187480926514,\n      \"avg\": 4163.009463787079,\n      \"last\": 8303.317385911942,\n      \"last-5-avg\": 4163.009463787079,\n      \"last-10-avg\": 4163.009463787079\n    },\n    \"time_since_restore\": {\n      \"max\": 8303.317385911942,\n      \"min\": 29.387187480926514,\n      \"avg\": 4163.009463787079,\n      \"last\": 8303.317385911942,\n      \"last-5-avg\": 4163.009463787079,\n      \"last-10-avg\": 4163.009463787079\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403d631eb80000004740b01eefc70400004740b032fe5a780000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403d631eb80000004740b01eefc70400004740b032fe5a780000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403d631eb80000004740b03c52e5bc00004740c037a8a01a0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403d631eb80000004740b03c52e5bc00004740c037a8a01a0000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403d631eb80000004740b03c52e5bc00004740c037a8a01a0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403d631eb80000004740b03c52e5bc00004740c037a8a01a0000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655024424.073589,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_b7dc375a_17___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=76,lr=2.0722e-05,weight_decay_2022-06-12_14-41-41\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"1871516e\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 56,\n    \"lr\": 2.8177913749503724e-06,\n    \"weight_decay\": 9.917782753469662e-06,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 56,\n    \"lr\": 2.8177913749503724e-06,\n    \"weight_decay\": 9.917782753469662e-06,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"18___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=56,lr=2.8178e-06,weight_decay=9.9178e-06\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834313636373435367102580300000063707571034b014e747104512e80025d7100580e00000039343732393834313636373435367101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 32.94889855384827,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"1871516e\",\n    \"experiment_id\": \"b31f382c7eab4b03b8824a7a970c9aa8\",\n    \"date\": \"2022-06-12_17-37-28\",\n    \"timestamp\": 1655026648,\n    \"time_total_s\": 32.94889855384827,\n    \"pid\": 94140,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 56,\n      \"lr\": 2.8177913749503724e-06,\n      \"weight_decay\": 9.917782753469662e-06,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 32.94889855384827,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"18___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=56,lr=2.8178e-06,weight_decay=9.9178e-06\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655026648.1041148,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 32.94889855384827,\n      \"min\": 32.94889855384827,\n      \"avg\": 32.94889855384827,\n      \"last\": 32.94889855384827,\n      \"last-5-avg\": 32.94889855384827,\n      \"last-10-avg\": 32.94889855384827\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 32.94889855384827,\n      \"min\": 32.94889855384827,\n      \"avg\": 32.94889855384827,\n      \"last\": 32.94889855384827,\n      \"last-5-avg\": 32.94889855384827,\n      \"last-10-avg\": 32.94889855384827\n    },\n    \"time_since_restore\": {\n      \"max\": 32.94889855384827,\n      \"min\": 32.94889855384827,\n      \"avg\": 32.94889855384827,\n      \"last\": 32.94889855384827,\n      \"last-5-avg\": 32.94889855384827,\n      \"last-10-avg\": 32.94889855384827\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474040797582000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474040797582000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474040797582000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474040797582000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474040797582000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474040797582000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655026607.043471,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_1871516e_18___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=56,lr=2.8178e-06,weight_decay_2022-06-12_17-00-24\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"2d95992e\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 336,\n    \"lr\": 2.0149662868349367e-07,\n    \"weight_decay\": 8.571434454223852e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 336,\n    \"lr\": 2.0149662868349367e-07,\n    \"weight_decay\": 8.571434454223852e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"19___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=336,lr=2.015e-07,weight_decay=8.5714e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834383532303838307102580300000063707571034b014e747104512e80025d7100580e00000039343732393834383532303838307101612e0100000000000000ef49af3e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 3554.51678109169,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 3,\n    \"trial_id\": \"2d95992e\",\n    \"experiment_id\": \"29312a7525cf4404a9953d346d4137d6\",\n    \"date\": \"2022-06-12_19-36-51\",\n    \"timestamp\": 1655033811,\n    \"time_total_s\": 7150.315975666046,\n    \"pid\": 134414,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 336,\n      \"lr\": 2.0149662868349367e-07,\n      \"weight_decay\": 8.571434454223852e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 7150.315975666046,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 3,\n    \"experiment_tag\": \"19___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=336,lr=2.015e-07,weight_decay=8.5714e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655033811.0583978,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 3567.5071918964386,\n      \"min\": 28.29200267791748,\n      \"avg\": 2383.4386585553484,\n      \"last\": 3554.51678109169,\n      \"last-5-avg\": 2383.438658555349,\n      \"last-10-avg\": 2383.438658555349\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.3333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.3333333333333333,\n      \"last-10-avg\": 0.3333333333333333\n    },\n    \"training_iteration\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"time_total_s\": {\n      \"max\": 7150.315975666046,\n      \"min\": 28.29200267791748,\n      \"avg\": 3591.4690576394396,\n      \"last\": 7150.315975666046,\n      \"last-5-avg\": 3591.46905763944,\n      \"last-10-avg\": 3591.46905763944\n    },\n    \"time_since_restore\": {\n      \"max\": 7150.315975666046,\n      \"min\": 28.29200267791748,\n      \"avg\": 3591.4690576394396,\n      \"last\": 7150.315975666046,\n      \"last-5-avg\": 3591.46905763944,\n      \"last-10-avg\": 3591.46905763944\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403c4ac0b00000004740abdf03aea800004740abc50897880000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403c4ac0b00000004740abdf03aea800004740abc50897880000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403c4ac0b00000004740ac1799300800004740bbee50e3c80000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403c4ac0b00000004740ac1799300800004740bbee50e3c80000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403c4ac0b00000004740ac1799300800004740bbee50e3c80000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403c4ac0b00000004740ac1799300800004740bbee50e3c80000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655026651.1302629,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_2d95992e_19___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=336,lr=2.015e-07,weight_decay_2022-06-12_17-36-47\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"47dbf13e\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 25,\n    \"lr\": 3.7708996179615107e-06,\n    \"weight_decay\": 9.460820197108547e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 25,\n    \"lr\": 3.7708996179615107e-06,\n    \"weight_decay\": 9.460820197108547e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"20___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=25,lr=3.7709e-06,weight_decay=9.4608e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834313934363034387102580300000063707571034b014e747104512e80025d7100580e00000039343732393834313934363034387101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 34.135388135910034,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"47dbf13e\",\n    \"experiment_id\": \"fed66fc2d3d44544b2551f56a03f068a\",\n    \"date\": \"2022-06-12_17-42-19\",\n    \"timestamp\": 1655026939,\n    \"time_total_s\": 34.135388135910034,\n    \"pid\": 135827,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 25,\n      \"lr\": 3.7708996179615107e-06,\n      \"weight_decay\": 9.460820197108547e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 34.135388135910034,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"20___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=25,lr=3.7709e-06,weight_decay=9.4608e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655026939.9658,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 34.135388135910034,\n      \"min\": 34.135388135910034,\n      \"avg\": 34.135388135910034,\n      \"last\": 34.135388135910034,\n      \"last-5-avg\": 34.135388135910034,\n      \"last-10-avg\": 34.135388135910034\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 34.135388135910034,\n      \"min\": 34.135388135910034,\n      \"avg\": 34.135388135910034,\n      \"last\": 34.135388135910034,\n      \"last-5-avg\": 34.135388135910034,\n      \"last-10-avg\": 34.135388135910034\n    },\n    \"time_since_restore\": {\n      \"max\": 34.135388135910034,\n      \"min\": 34.135388135910034,\n      \"avg\": 34.135388135910034,\n      \"last\": 34.135388135910034,\n      \"last-5-avg\": 34.135388135910034,\n      \"last-10-avg\": 34.135388135910034\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474041115466000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474041115466000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474041115466000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474041115466000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474041115466000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474041115466000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655026898.420953,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_47dbf13e_20___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=25,lr=3.7709e-06,weight_decay_2022-06-12_17-37-31\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"db4081ec\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 40,\n    \"lr\": 1.796271647074889e-05,\n    \"weight_decay\": 6.226864315020362e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 40,\n    \"lr\": 1.796271647074889e-05,\n    \"weight_decay\": 6.226864315020362e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"21___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=40,lr=1.7963e-05,weight_decay=6.2269e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834323130373837327102580300000063707571034b014e747104512e80025d7100580e00000039343732393834323130373837327101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 34.07725405693054,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"db4081ec\",\n    \"experiment_id\": \"87693e424ab84f3d9a2cef408cc7bf65\",\n    \"date\": \"2022-06-12_17-43-05\",\n    \"timestamp\": 1655026985,\n    \"time_total_s\": 34.07725405693054,\n    \"pid\": 142345,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 40,\n      \"lr\": 1.796271647074889e-05,\n      \"weight_decay\": 6.226864315020362e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 34.07725405693054,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"21___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=40,lr=1.7963e-05,weight_decay=6.2269e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655026985.32689,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 34.07725405693054,\n      \"min\": 34.07725405693054,\n      \"avg\": 34.07725405693054,\n      \"last\": 34.07725405693054,\n      \"last-5-avg\": 34.07725405693054,\n      \"last-10-avg\": 34.07725405693054\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 34.07725405693054,\n      \"min\": 34.07725405693054,\n      \"avg\": 34.07725405693054,\n      \"last\": 34.07725405693054,\n      \"last-5-avg\": 34.07725405693054,\n      \"last-10-avg\": 34.07725405693054\n    },\n    \"time_since_restore\": {\n      \"max\": 34.07725405693054,\n      \"min\": 34.07725405693054,\n      \"avg\": 34.07725405693054,\n      \"last\": 34.07725405693054,\n      \"last-5-avg\": 34.07725405693054,\n      \"last-10-avg\": 34.07725405693054\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447404109e376000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447404109e376000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447404109e376000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447404109e376000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447404109e376000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447404109e376000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655026943.1468523,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_db4081ec_21___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=40,lr=1.7963e-05,weight_decay_2022-06-12_17-41-38\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"f5eb72fe\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 22,\n    \"lr\": 8.207914338007087e-07,\n    \"weight_decay\": 7.160908509768797e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 22,\n    \"lr\": 8.207914338007087e-07,\n    \"weight_decay\": 7.160908509768797e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"22___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=22,lr=8.2079e-07,weight_decay=7.1609e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834373239303537367102580300000063707571034b014e747104512e80025d7100580e00000039343732393834373239303537367101612e0100000000000000c324a53e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 6195.138062953949,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 2,\n    \"trial_id\": \"f5eb72fe\",\n    \"experiment_id\": \"5e8c507d6689416abd236514713713df\",\n    \"date\": \"2022-06-12_19-27-06\",\n    \"timestamp\": 1655033226,\n    \"time_total_s\": 6229.784660577774,\n    \"pid\": 143680,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 22,\n      \"lr\": 8.207914338007087e-07,\n      \"weight_decay\": 7.160908509768797e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 6229.784660577774,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"22___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=22,lr=8.2079e-07,weight_decay=7.1609e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655033226.2882674,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 6195.138062953949,\n      \"min\": 34.64659762382507,\n      \"avg\": 3114.892330288887,\n      \"last\": 6195.138062953949,\n      \"last-5-avg\": 3114.892330288887,\n      \"last-10-avg\": 3114.892330288887\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_total_s\": {\n      \"max\": 6229.784660577774,\n      \"min\": 34.64659762382507,\n      \"avg\": 3132.2156291007996,\n      \"last\": 6229.784660577774,\n      \"last-5-avg\": 3132.2156291007996,\n      \"last-10-avg\": 3132.2156291007996\n    },\n    \"time_since_restore\": {\n      \"max\": 6229.784660577774,\n      \"min\": 34.64659762382507,\n      \"avg\": 3132.2156291007996,\n      \"last\": 6229.784660577774,\n      \"last-5-avg\": 3132.2156291007996,\n      \"last-10-avg\": 3132.2156291007996\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404152c3b60000004740b8332358180000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404152c3b60000004740b8332358180000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404152c3b60000004740b855c8df840000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404152c3b60000004740b855c8df840000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404152c3b60000004740b855c8df840000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404152c3b60000004740b855c8df840000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655026988.3599641,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_f5eb72fe_22___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=22,lr=8.2079e-07,weight_decay_2022-06-12_17-42-23\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"10dda0d2\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 21,\n    \"lr\": 7.673208632799687e-07,\n    \"weight_decay\": 9.958612199363257e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 21,\n    \"lr\": 7.673208632799687e-07,\n    \"weight_decay\": 9.958612199363257e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"23___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=21,lr=7.6732e-07,weight_decay=9.9586e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834383532303735327102580300000063707571034b014e747104512e80025d7100580e00000039343732393834383532303735327101612e0100000000000000ef49af3e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 6370.35480761528,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 3,\n    \"trial_id\": \"10dda0d2\",\n    \"experiment_id\": \"a2800533f3ee4851964946e245ed1a26\",\n    \"date\": \"2022-06-12_22-51-18\",\n    \"timestamp\": 1655045478,\n    \"time_total_s\": 12712.947754383087,\n    \"pid\": 144962,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 21,\n      \"lr\": 7.673208632799687e-07,\n      \"weight_decay\": 9.958612199363257e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 12712.947754383087,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 3,\n    \"experiment_tag\": \"23___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=21,lr=7.6732e-07,weight_decay=9.9586e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655045478.6667974,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 6370.35480761528,\n      \"min\": 34.91026282310486,\n      \"avg\": 4237.649251461029,\n      \"last\": 6370.35480761528,\n      \"last-5-avg\": 4237.649251461029,\n      \"last-10-avg\": 4237.649251461029\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.3333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.3333333333333333,\n      \"last-10-avg\": 0.3333333333333333\n    },\n    \"training_iteration\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"time_total_s\": {\n      \"max\": 12712.947754383087,\n      \"min\": 34.91026282310486,\n      \"avg\": 6363.483654657999,\n      \"last\": 12712.947754383087,\n      \"last-5-avg\": 6363.483654658,\n      \"last-10-avg\": 6363.483654658\n    },\n    \"time_since_restore\": {\n      \"max\": 12712.947754383087,\n      \"min\": 34.91026282310486,\n      \"avg\": 6363.483654657999,\n      \"last\": 12712.947754383087,\n      \"last-5-avg\": 6363.483654658,\n      \"last-10-avg\": 6363.483654658\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404174837e0000004740b8a3aec46000004740b8e25ad4ac0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404174837e0000004740b8a3aec46000004740b8e25ad4ac0000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404174837e0000004740b8c697cb5c00004740c8d47950040000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404174837e0000004740b8c697cb5c00004740c8d47950040000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404174837e0000004740b8c697cb5c00004740c8d47950040000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404174837e0000004740b8c697cb5c00004740c8d47950040000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655032741.1986427,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_10dda0d2_23___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=21,lr=7.6732e-07,weight_decay_2022-06-12_17-43-08\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"75d6909a\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 29,\n    \"lr\": 3.9540033126288985e-07,\n    \"weight_decay\": 4.6555750233511604e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 29,\n    \"lr\": 3.9540033126288985e-07,\n    \"weight_decay\": 4.6555750233511604e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"24___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=29,lr=3.954e-07,weight_decay=4.6556e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834323130393437327102580300000063707571034b014e747104512e80025d7100580e00000039343732393834323130393437327101612e0100000000000000ef49af3e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 5507.17541384697,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 3,\n    \"trial_id\": \"75d6909a\",\n    \"experiment_id\": \"beeae7db0aa740f2a45948195e627513\",\n    \"date\": \"2022-06-12_22-31-10\",\n    \"timestamp\": 1655044270,\n    \"time_total_s\": 11033.578928470612,\n    \"pid\": 46883,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 29,\n      \"lr\": 3.9540033126288985e-07,\n      \"weight_decay\": 4.6555750233511604e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 11033.578928470612,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 3,\n    \"experiment_tag\": \"24___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=29,lr=3.954e-07,weight_decay=4.6556e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655044270.9955034,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 5507.17541384697,\n      \"min\": 33.01665735244751,\n      \"avg\": 3677.859642823537,\n      \"last\": 5507.17541384697,\n      \"last-5-avg\": 3677.8596428235373,\n      \"last-10-avg\": 3677.8596428235373\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.3333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.3333333333333333,\n      \"last-10-avg\": 0.3333333333333333\n    },\n    \"training_iteration\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"time_total_s\": {\n      \"max\": 11033.578928470612,\n      \"min\": 33.01665735244751,\n      \"avg\": 5530.9997001489,\n      \"last\": 11033.578928470612,\n      \"last-5-avg\": 5530.9997001489,\n      \"last-10-avg\": 5530.9997001489\n    },\n    \"time_since_restore\": {\n      \"max\": 11033.578928470612,\n      \"min\": 33.01665735244751,\n      \"avg\": 5530.9997001489,\n      \"last\": 11033.578928470612,\n      \"last-5-avg\": 5530.9997001489,\n      \"last-10-avg\": 5530.9997001489\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740408221d40000004740b57563091400004740b5832ce7ec0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740408221d40000004740b57563091400004740b5832ce7ec0000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740408221d40000004740b596674cbc00004740c58cca1a540000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740408221d40000004740b596674cbc00004740c58cca1a540000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740408221d40000004740b596674cbc00004740c58cca1a540000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740408221d40000004740b596674cbc00004740c58cca1a540000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655033229.3856335,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_75d6909a_24___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=29,lr=3.954e-07,weight_decay=_2022-06-12_19-19-01\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"98ce31ce\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 54,\n    \"lr\": 2.91898125306743e-07,\n    \"weight_decay\": 7.024707534147024e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 54,\n    \"lr\": 2.91898125306743e-07,\n    \"weight_decay\": 7.024707534147024e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"25___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=54,lr=2.919e-07,weight_decay=7.0247e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834313732303132387102580300000063707571034b014e747104512e80025d7100580e00000039343732393834313732303132387101612e0100000000000000ef49af3e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 4446.313087463379,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 3,\n    \"trial_id\": \"98ce31ce\",\n    \"experiment_id\": \"59af6a9a018b451ca29d1101414ee387\",\n    \"date\": \"2022-06-12_22-06-04\",\n    \"timestamp\": 1655042764,\n    \"time_total_s\": 8943.723993778229,\n    \"pid\": 58500,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 54,\n      \"lr\": 2.91898125306743e-07,\n      \"weight_decay\": 7.024707534147024e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 8943.723993778229,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 3,\n    \"experiment_tag\": \"25___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=54,lr=2.919e-07,weight_decay=7.0247e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655042764.4829457,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 4467.229762554169,\n      \"min\": 30.181143760681152,\n      \"avg\": 2981.2413312594094,\n      \"last\": 4446.313087463379,\n      \"last-5-avg\": 2981.2413312594094,\n      \"last-10-avg\": 2981.2413312594094\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.3333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.3333333333333333,\n      \"last-10-avg\": 0.3333333333333333\n    },\n    \"training_iteration\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"time_total_s\": {\n      \"max\": 8943.723993778229,\n      \"min\": 30.181143760681152,\n      \"avg\": 4490.438681284586,\n      \"last\": 8943.723993778229,\n      \"last-5-avg\": 4490.438681284587,\n      \"last-10-avg\": 4490.438681284587\n    },\n    \"time_since_restore\": {\n      \"max\": 8943.723993778229,\n      \"min\": 30.181143760681152,\n      \"avg\": 4490.438681284586,\n      \"last\": 8943.723993778229,\n      \"last-5-avg\": 4490.438681284587,\n      \"last-10-avg\": 4490.438681284587\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403e2e5f700000004740b1733ad1b800004740b15e5026800000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403e2e5f700000004740b1733ad1b800004740b15e5026800000652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403e2e5f700000004740b19169312800004740c177dcabd40000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403e2e5f700000004740b19169312800004740c177dcabd40000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403e2e5f700000004740b19169312800004740c177dcabd40000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403e2e5f700000004740b19169312800004740c177dcabd40000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655033814.1540139,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_98ce31ce_25___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=54,lr=2.919e-07,weight_decay=_2022-06-12_19-27-09\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"f55cb1f8\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 39,\n    \"lr\": 4.3537438829548634e-05,\n    \"weight_decay\": 5.802254809552258e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 39,\n    \"lr\": 4.3537438829548634e-05,\n    \"weight_decay\": 5.802254809552258e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"26___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=39,lr=4.3537e-05,weight_decay=5.8023e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834313732303132387102580300000063707571034b014e747104512e80025d7100580e00000039343732393834313732303132387101612e01000000000000000000203f94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 30.915626764297485,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"f55cb1f8\",\n    \"experiment_id\": \"36cc2e2b3a2e4bd5a83fba9ff8ff1269\",\n    \"date\": \"2022-06-12_22-06-51\",\n    \"timestamp\": 1655042811,\n    \"time_total_s\": 30.915626764297485,\n    \"pid\": 69394,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 39,\n      \"lr\": 4.3537438829548634e-05,\n      \"weight_decay\": 5.802254809552258e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 30.915626764297485,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"26___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=39,lr=4.3537e-05,weight_decay=5.8023e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655042811.1261342,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 30.915626764297485,\n      \"min\": 30.915626764297485,\n      \"avg\": 30.915626764297485,\n      \"last\": 30.915626764297485,\n      \"last-5-avg\": 30.915626764297485,\n      \"last-10-avg\": 30.915626764297485\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 30.915626764297485,\n      \"min\": 30.915626764297485,\n      \"avg\": 30.915626764297485,\n      \"last\": 30.915626764297485,\n      \"last-5-avg\": 30.915626764297485,\n      \"last-10-avg\": 30.915626764297485\n    },\n    \"time_since_restore\": {\n      \"max\": 30.915626764297485,\n      \"min\": 30.915626764297485,\n      \"avg\": 30.915626764297485,\n      \"last\": 30.915626764297485,\n      \"last-5-avg\": 30.915626764297485,\n      \"last-10-avg\": 30.915626764297485\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403eea6684000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403eea6684000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403eea6684000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403eea6684000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403eea6684000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403eea6684000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1655042767.7321448,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_f55cb1f8_26___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=39,lr=4.3537e-05,weight_decay_2022-06-12_19-36-54\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"ce1ebbd0\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 147,\n    \"lr\": 1.734209178075043e-05,\n    \"weight_decay\": 4.449139671656402e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 147,\n    \"lr\": 1.734209178075043e-05,\n    \"weight_decay\": 4.449139671656402e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"27___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=147,lr=1.7342e-05,weight_decay=4.4491e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834313638363139327102580300000063707571034b014e747104512e80025d7100580e00000039343732393834313638363139327101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 35.23354935646057,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"ce1ebbd0\",\n    \"experiment_id\": \"8b0f3991ed944e61b199e801a52cf18c\",\n    \"date\": \"2022-06-12_22-31-58\",\n    \"timestamp\": 1655044318,\n    \"time_total_s\": 35.23354935646057,\n    \"pid\": 34118,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 147,\n      \"lr\": 1.734209178075043e-05,\n      \"weight_decay\": 4.449139671656402e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 35.23354935646057,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"27___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=147,lr=1.7342e-05,weight_decay=4.4491e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655044318.5008671,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 35.23354935646057,\n      \"min\": 35.23354935646057,\n      \"avg\": 35.23354935646057,\n      \"last\": 35.23354935646057,\n      \"last-5-avg\": 35.23354935646057,\n      \"last-10-avg\": 35.23354935646057\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 35.23354935646057,\n      \"min\": 35.23354935646057,\n      \"avg\": 35.23354935646057,\n      \"last\": 35.23354935646057,\n      \"last-5-avg\": 35.23354935646057,\n      \"last-10-avg\": 35.23354935646057\n    },\n    \"time_since_restore\": {\n      \"max\": 35.23354935646057,\n      \"min\": 35.23354935646057,\n      \"avg\": 35.23354935646057,\n      \"last\": 35.23354935646057,\n      \"last-5-avg\": 35.23354935646057,\n      \"last-10-avg\": 35.23354935646057\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740419de4f2000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740419de4f2000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740419de4f2000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740419de4f2000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740419de4f2000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740419de4f2000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655044274.033246,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_ce1ebbd0_27___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=147,lr=1.7342e-05,weight_deca_2022-06-12_22-06-07\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"4fecaea8\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 618,\n    \"lr\": 2.5169950220560275e-07,\n    \"weight_decay\": 4.8969618448332515e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 618,\n    \"lr\": 2.5169950220560275e-07,\n    \"weight_decay\": 4.8969618448332515e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"28___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=618,lr=2.517e-07,weight_decay=4.897e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834313639303931327102580300000063707571034b014e747104512e80025d7100580e00000039343732393834313639303931327101612e01000000000000000000203f94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 25.906445026397705,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"4fecaea8\",\n    \"experiment_id\": \"74266cd052bf4692bbc387c62029ef4b\",\n    \"date\": \"2022-06-12_22-32-36\",\n    \"timestamp\": 1655044356,\n    \"time_total_s\": 25.906445026397705,\n    \"pid\": 67573,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 618,\n      \"lr\": 2.5169950220560275e-07,\n      \"weight_decay\": 4.8969618448332515e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 25.906445026397705,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"28___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=618,lr=2.517e-07,weight_decay=4.897e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655044356.3209863,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 25.906445026397705,\n      \"min\": 25.906445026397705,\n      \"avg\": 25.906445026397705,\n      \"last\": 25.906445026397705,\n      \"last-5-avg\": 25.906445026397705,\n      \"last-10-avg\": 25.906445026397705\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 25.906445026397705,\n      \"min\": 25.906445026397705,\n      \"avg\": 25.906445026397705,\n      \"last\": 25.906445026397705,\n      \"last-5-avg\": 25.906445026397705,\n      \"last-10-avg\": 25.906445026397705\n    },\n    \"time_since_restore\": {\n      \"max\": 25.906445026397705,\n      \"min\": 25.906445026397705,\n      \"avg\": 25.906445026397705,\n      \"last\": 25.906445026397705,\n      \"last-5-avg\": 25.906445026397705,\n      \"last-10-avg\": 25.906445026397705\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474039e80cc8000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474039e80cc8000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474039e80cc8000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474039e80cc8000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474039e80cc8000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474039e80cc8000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655044321.7981818,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_4fecaea8_28___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=618,lr=2.517e-07,weight_decay_2022-06-12_22-31-14\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_4fecaea8_28___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=618,lr=2.517e-07,weight_decay_2022-06-12_22-31-14/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=67573, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=67573, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 387, in forward\\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 328, in forward\\n    attention_scores = attention_scores / math.sqrt(self.attention_head_size)\\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 15.78 GiB total capacity; 2.06 GiB already allocated; 12.50 MiB free; 2.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"6c655026\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 289,\n    \"lr\": 1.1937746283349054e-07,\n    \"weight_decay\": 9.02197107926515e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 289,\n    \"lr\": 1.1937746283349054e-07,\n    \"weight_decay\": 9.02197107926515e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"29___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=289,lr=1.1938e-07,weight_decay=9.022e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834313639313930347102580300000063707571034b014e747104512e80025d7100580e00000039343732393834313639313930347101612e01000000000000000000203f94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 29.285935878753662,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"6c655026\",\n    \"experiment_id\": \"465ee85ee41f4eec96e1e764a28d5c25\",\n    \"date\": \"2022-06-12_22-33-22\",\n    \"timestamp\": 1655044402,\n    \"time_total_s\": 29.285935878753662,\n    \"pid\": 68807,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 289,\n      \"lr\": 1.1937746283349054e-07,\n      \"weight_decay\": 9.02197107926515e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 29.285935878753662,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"29___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=289,lr=1.1938e-07,weight_decay=9.022e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655044402.280125,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 29.285935878753662,\n      \"min\": 29.285935878753662,\n      \"avg\": 29.285935878753662,\n      \"last\": 29.285935878753662,\n      \"last-5-avg\": 29.285935878753662,\n      \"last-10-avg\": 29.285935878753662\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 29.285935878753662,\n      \"min\": 29.285935878753662,\n      \"avg\": 29.285935878753662,\n      \"last\": 29.285935878753662,\n      \"last-5-avg\": 29.285935878753662,\n      \"last-10-avg\": 29.285935878753662\n    },\n    \"time_since_restore\": {\n      \"max\": 29.285935878753662,\n      \"min\": 29.285935878753662,\n      \"avg\": 29.285935878753662,\n      \"last\": 29.285935878753662,\n      \"last-5-avg\": 29.285935878753662,\n      \"last-10-avg\": 29.285935878753662\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403d493318000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403d493318000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403d493318000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403d493318000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403d493318000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403d493318000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655044365.6993709,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_6c655026_29___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=289,lr=1.1938e-07,weight_deca_2022-06-12_22-32-01\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_6c655026_29___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=289,lr=1.1938e-07,weight_deca_2022-06-12_22-32-01/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=68807, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=68807, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 387, in forward\\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 327, in forward\\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 15.78 GiB total capacity; 2.00 GiB already allocated; 66.50 MiB free; 2.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"869065da\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 682,\n    \"lr\": 3.242390406539479e-07,\n    \"weight_decay\": 4.7962332540454096e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 682,\n    \"lr\": 3.242390406539479e-07,\n    \"weight_decay\": 4.7962332540454096e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"30___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=682,lr=3.2424e-07,weight_decay=4.7962e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834323330353132307102580300000063707571034b014e747104512e80025d7100580e00000039343732393834323330353132307101612e01000000000000000000203f94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 24.71556282043457,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"869065da\",\n    \"experiment_id\": \"17cef2d5c9fb4b6e98b7dd17159648c7\",\n    \"date\": \"2022-06-12_22-34-03\",\n    \"timestamp\": 1655044443,\n    \"time_total_s\": 24.71556282043457,\n    \"pid\": 70127,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 682,\n      \"lr\": 3.242390406539479e-07,\n      \"weight_decay\": 4.7962332540454096e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 24.71556282043457,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"30___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=682,lr=3.2424e-07,weight_decay=4.7962e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655044443.6918004,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 24.71556282043457,\n      \"min\": 24.71556282043457,\n      \"avg\": 24.71556282043457,\n      \"last\": 24.71556282043457,\n      \"last-5-avg\": 24.71556282043457,\n      \"last-10-avg\": 24.71556282043457\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 24.71556282043457,\n      \"min\": 24.71556282043457,\n      \"avg\": 24.71556282043457,\n      \"last\": 24.71556282043457,\n      \"last-5-avg\": 24.71556282043457,\n      \"last-10-avg\": 24.71556282043457\n    },\n    \"time_since_restore\": {\n      \"max\": 24.71556282043457,\n      \"min\": 24.71556282043457,\n      \"avg\": 24.71556282043457,\n      \"last\": 24.71556282043457,\n      \"last-5-avg\": 24.71556282043457,\n      \"last-10-avg\": 24.71556282043457\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474038b72f20000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474038b72f20000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474038b72f20000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474038b72f20000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474038b72f20000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474038b72f20000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655044410.919928,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_869065da_30___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=682,lr=3.2424e-07,weight_deca_2022-06-12_22-32-45\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_869065da_30___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=682,lr=3.2424e-07,weight_deca_2022-06-12_22-32-45/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=70127, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=70127, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 387, in forward\\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 328, in forward\\n    attention_scores = attention_scores / math.sqrt(self.attention_head_size)\\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 15.78 GiB total capacity; 2.05 GiB already allocated; 12.50 MiB free; 2.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"a18537b2\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 279,\n    \"lr\": 1.120360005086871e-07,\n    \"weight_decay\": 9.4990338981971e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 279,\n    \"lr\": 1.120360005086871e-07,\n    \"weight_decay\": 9.4990338981971e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"31___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=279,lr=1.1204e-07,weight_decay=9.499e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834313730363335327102580300000063707571034b014e747104512e80025d7100580e00000039343732393834313730363335327101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 27.496485948562622,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"a18537b2\",\n    \"experiment_id\": \"61622710246a4c0580057d63c42a3839\",\n    \"date\": \"2022-06-12_22-34-46\",\n    \"timestamp\": 1655044486,\n    \"time_total_s\": 27.496485948562622,\n    \"pid\": 71454,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 279,\n      \"lr\": 1.120360005086871e-07,\n      \"weight_decay\": 9.4990338981971e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 27.496485948562622,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"31___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=279,lr=1.1204e-07,weight_decay=9.499e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655044486.7430887,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 27.496485948562622,\n      \"min\": 27.496485948562622,\n      \"avg\": 27.496485948562622,\n      \"last\": 27.496485948562622,\n      \"last-5-avg\": 27.496485948562622,\n      \"last-10-avg\": 27.496485948562622\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 27.496485948562622,\n      \"min\": 27.496485948562622,\n      \"avg\": 27.496485948562622,\n      \"last\": 27.496485948562622,\n      \"last-5-avg\": 27.496485948562622,\n      \"last-10-avg\": 27.496485948562622\n    },\n    \"time_since_restore\": {\n      \"max\": 27.496485948562622,\n      \"min\": 27.496485948562622,\n      \"avg\": 27.496485948562622,\n      \"last\": 27.496485948562622,\n      \"last-5-avg\": 27.496485948562622,\n      \"last-10-avg\": 27.496485948562622\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403b7f19b4000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403b7f19b4000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403b7f19b4000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403b7f19b4000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403b7f19b4000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403b7f19b4000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655044450.9521058,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_a18537b2_31___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=279,lr=1.1204e-07,weight_deca_2022-06-12_22-33-31\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"b9607414\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 690,\n    \"lr\": 3.937315183165102e-07,\n    \"weight_decay\": 4.847790698935012e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 690,\n    \"lr\": 3.937315183165102e-07,\n    \"weight_decay\": 4.847790698935012e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"32___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=690,lr=3.9373e-07,weight_decay=4.8478e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834313639313830387102580300000063707571034b014e747104512e80025d7100580e00000039343732393834313639313830387101612e01000000000000000000a03e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 29.72238564491272,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"b9607414\",\n    \"experiment_id\": \"5b0da99a8e1248e59b62fd7df014bf99\",\n    \"date\": \"2022-06-12_22-35-25\",\n    \"timestamp\": 1655044525,\n    \"time_total_s\": 29.72238564491272,\n    \"pid\": 72658,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 690,\n      \"lr\": 3.937315183165102e-07,\n      \"weight_decay\": 4.847790698935012e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 29.72238564491272,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"32___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=690,lr=3.9373e-07,weight_decay=4.8478e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655044525.0775898,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 29.72238564491272,\n      \"min\": 29.72238564491272,\n      \"avg\": 29.72238564491272,\n      \"last\": 29.72238564491272,\n      \"last-5-avg\": 29.72238564491272,\n      \"last-10-avg\": 29.72238564491272\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 29.72238564491272,\n      \"min\": 29.72238564491272,\n      \"avg\": 29.72238564491272,\n      \"last\": 29.72238564491272,\n      \"last-5-avg\": 29.72238564491272,\n      \"last-10-avg\": 29.72238564491272\n    },\n    \"time_since_restore\": {\n      \"max\": 29.72238564491272,\n      \"min\": 29.72238564491272,\n      \"avg\": 29.72238564491272,\n      \"last\": 29.72238564491272,\n      \"last-5-avg\": 29.72238564491272,\n      \"last-10-avg\": 29.72238564491272\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403db8ee44000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403db8ee44000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403db8ee44000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403db8ee44000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403db8ee44000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403db8ee44000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655044489.7759914,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_b9607414_32___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=690,lr=3.9373e-07,weight_deca_2022-06-12_22-34-11\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"d083f29c\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 57,\n    \"lr\": 7.21260153541437e-06,\n    \"weight_decay\": 5.597505939632876e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 57,\n    \"lr\": 7.21260153541437e-06,\n    \"weight_decay\": 5.597505939632876e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"33___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=57,lr=7.2126e-06,weight_decay=5.5975e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834373636383431367102580300000063707571034b014e747104512e80025d7100580e00000039343732393834373636383431367101612e01000000000000000000203f94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 34.357091665267944,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"d083f29c\",\n    \"experiment_id\": \"e8b0c1ed64ee4d6ca2ba865647b74c0c\",\n    \"date\": \"2022-06-12_22-36-10\",\n    \"timestamp\": 1655044570,\n    \"time_total_s\": 34.357091665267944,\n    \"pid\": 73767,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 57,\n      \"lr\": 7.21260153541437e-06,\n      \"weight_decay\": 5.597505939632876e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 34.357091665267944,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"33___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=57,lr=7.2126e-06,weight_decay=5.5975e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655044570.3914115,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 34.357091665267944,\n      \"min\": 34.357091665267944,\n      \"avg\": 34.357091665267944,\n      \"last\": 34.357091665267944,\n      \"last-5-avg\": 34.357091665267944,\n      \"last-10-avg\": 34.357091665267944\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 34.357091665267944,\n      \"min\": 34.357091665267944,\n      \"avg\": 34.357091665267944,\n      \"last\": 34.357091665267944,\n      \"last-5-avg\": 34.357091665267944,\n      \"last-10-avg\": 34.357091665267944\n    },\n    \"time_since_restore\": {\n      \"max\": 34.357091665267944,\n      \"min\": 34.357091665267944,\n      \"avg\": 34.357091665267944,\n      \"last\": 34.357091665267944,\n      \"last-5-avg\": 34.357091665267944,\n      \"last-10-avg\": 34.357091665267944\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740412db52e000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740412db52e000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740412db52e000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740412db52e000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740412db52e000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740412db52e000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655044528.2202356,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_d083f29c_33___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=57,lr=7.2126e-06,weight_decay_2022-06-12_22-34-49\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_d083f29c_33___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=57,lr=7.2126e-06,weight_decay_2022-06-12_22-34-49/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=73767, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=73767, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 401, in ff_chunk\\n    ffn_output = self.activation(ffn_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/activations.py\\\", line 34, in forward\\n    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 15.78 GiB total capacity; 2.02 GiB already allocated; 26.50 MiB free; 2.08 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"e76e7d4c\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 94,\n    \"lr\": 1.3199737279135663e-06,\n    \"weight_decay\": 3.849080555974188e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 94,\n    \"lr\": 1.3199737279135663e-06,\n    \"weight_decay\": 3.849080555974188e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"34___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=94,lr=1.32e-06,weight_decay=3.8491e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834313638363635367102580300000063707571034b014e747104512e80025d7100580e00000039343732393834313638363635367101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 30.168725967407227,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"e76e7d4c\",\n    \"experiment_id\": \"b3e88bc9192545889ddd80a34e361886\",\n    \"date\": \"2022-06-12_22-37-05\",\n    \"timestamp\": 1655044625,\n    \"time_total_s\": 30.168725967407227,\n    \"pid\": 74909,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 94,\n      \"lr\": 1.3199737279135663e-06,\n      \"weight_decay\": 3.849080555974188e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 30.168725967407227,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"34___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=94,lr=1.32e-06,weight_decay=3.8491e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655044625.573103,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 30.168725967407227,\n      \"min\": 30.168725967407227,\n      \"avg\": 30.168725967407227,\n      \"last\": 30.168725967407227,\n      \"last-5-avg\": 30.168725967407227,\n      \"last-10-avg\": 30.168725967407227\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 30.168725967407227,\n      \"min\": 30.168725967407227,\n      \"avg\": 30.168725967407227,\n      \"last\": 30.168725967407227,\n      \"last-5-avg\": 30.168725967407227,\n      \"last-10-avg\": 30.168725967407227\n    },\n    \"time_since_restore\": {\n      \"max\": 30.168725967407227,\n      \"min\": 30.168725967407227,\n      \"avg\": 30.168725967407227,\n      \"last\": 30.168725967407227,\n      \"last-5-avg\": 30.168725967407227,\n      \"last-10-avg\": 30.168725967407227\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403e2b31a0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403e2b31a0000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403e2b31a0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403e2b31a0000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403e2b31a0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403e2b31a0000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655044587.0086749,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_e76e7d4c_34___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=94,lr=1.32e-06,weight_decay=3_2022-06-12_22-35-28\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"0a77ff3e\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 226,\n    \"lr\": 1.7786238853918732e-05,\n    \"weight_decay\": 6.88869282572205e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 226,\n    \"lr\": 1.7786238853918732e-05,\n    \"weight_decay\": 6.88869282572205e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"35___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=226,lr=1.7786e-05,weight_decay=6.8887e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834313730363139327102580300000063707571034b014e747104512e80025d7100580e00000039343732393834313730363139327101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 22.774059295654297,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"0a77ff3e\",\n    \"experiment_id\": \"90be7e5a853940cfa24940ee7f4592ad\",\n    \"date\": \"2022-06-12_22-37-39\",\n    \"timestamp\": 1655044659,\n    \"time_total_s\": 22.774059295654297,\n    \"pid\": 76486,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 226,\n      \"lr\": 1.7786238853918732e-05,\n      \"weight_decay\": 6.88869282572205e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 22.774059295654297,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"35___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=226,lr=1.7786e-05,weight_decay=6.8887e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655044659.8971817,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 22.774059295654297,\n      \"min\": 22.774059295654297,\n      \"avg\": 22.774059295654297,\n      \"last\": 22.774059295654297,\n      \"last-5-avg\": 22.774059295654297,\n      \"last-10-avg\": 22.774059295654297\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 22.774059295654297,\n      \"min\": 22.774059295654297,\n      \"avg\": 22.774059295654297,\n      \"last\": 22.774059295654297,\n      \"last-5-avg\": 22.774059295654297,\n      \"last-10-avg\": 22.774059295654297\n    },\n    \"time_since_restore\": {\n      \"max\": 22.774059295654297,\n      \"min\": 22.774059295654297,\n      \"avg\": 22.774059295654297,\n      \"last\": 22.774059295654297,\n      \"last-5-avg\": 22.774059295654297,\n      \"last-10-avg\": 22.774059295654297\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474036c628c0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474036c628c0000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474036c628c0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474036c628c0000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474036c628c0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474036c628c0000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655044628.9252267,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_0a77ff3e_35___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=226,lr=1.7786e-05,weight_deca_2022-06-12_22-36-27\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"2374e286\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 73,\n    \"lr\": 1.0052752991648087e-05,\n    \"weight_decay\": 5.7017001892130536e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 73,\n    \"lr\": 1.0052752991648087e-05,\n    \"weight_decay\": 5.7017001892130536e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"36___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=73,lr=1.0053e-05,weight_decay=5.7017e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834343334353736307102580300000063707571034b014e747104512e80025d7100580e00000039343732393834343334353736307101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 26.629260063171387,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"2374e286\",\n    \"experiment_id\": \"5c179a533928469d809243770e5c5c4b\",\n    \"date\": \"2022-06-12_22-38-16\",\n    \"timestamp\": 1655044696,\n    \"time_total_s\": 26.629260063171387,\n    \"pid\": 77664,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 73,\n      \"lr\": 1.0052752991648087e-05,\n      \"weight_decay\": 5.7017001892130536e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 26.629260063171387,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"36___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=73,lr=1.0053e-05,weight_decay=5.7017e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655044696.426087,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 26.629260063171387,\n      \"min\": 26.629260063171387,\n      \"avg\": 26.629260063171387,\n      \"last\": 26.629260063171387,\n      \"last-5-avg\": 26.629260063171387,\n      \"last-10-avg\": 26.629260063171387\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 26.629260063171387,\n      \"min\": 26.629260063171387,\n      \"avg\": 26.629260063171387,\n      \"last\": 26.629260063171387,\n      \"last-5-avg\": 26.629260063171387,\n      \"last-10-avg\": 26.629260063171387\n    },\n    \"time_since_restore\": {\n      \"max\": 26.629260063171387,\n      \"min\": 26.629260063171387,\n      \"avg\": 26.629260063171387,\n      \"last\": 26.629260063171387,\n      \"last-5-avg\": 26.629260063171387,\n      \"last-10-avg\": 26.629260063171387\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403aa11730000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403aa11730000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403aa11730000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403aa11730000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403aa11730000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403aa11730000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655044662.9249303,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_2374e286_36___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=73,lr=1.0053e-05,weight_decay_2022-06-12_22-37-08\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"37ba616c\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 64,\n    \"lr\": 8.82046810763464e-06,\n    \"weight_decay\": 5.3232545601015106e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 64,\n    \"lr\": 8.82046810763464e-06,\n    \"weight_decay\": 5.3232545601015106e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"37___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=64,lr=8.8205e-06,weight_decay=5.3233e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834383734383336387102580300000063707571034b014e747104512e80025d7100580e00000039343732393834383734383336387101612e01000000000000000000203f94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 28.499870538711548,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"37ba616c\",\n    \"experiment_id\": \"fa7aa87a78ce490a8d7af0e6d6ca1440\",\n    \"date\": \"2022-06-12_22-38-55\",\n    \"timestamp\": 1655044735,\n    \"time_total_s\": 28.499870538711548,\n    \"pid\": 78670,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 64,\n      \"lr\": 8.82046810763464e-06,\n      \"weight_decay\": 5.3232545601015106e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 28.499870538711548,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"37___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=64,lr=8.8205e-06,weight_decay=5.3233e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655044735.216381,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 28.499870538711548,\n      \"min\": 28.499870538711548,\n      \"avg\": 28.499870538711548,\n      \"last\": 28.499870538711548,\n      \"last-5-avg\": 28.499870538711548,\n      \"last-10-avg\": 28.499870538711548\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 28.499870538711548,\n      \"min\": 28.499870538711548,\n      \"avg\": 28.499870538711548,\n      \"last\": 28.499870538711548,\n      \"last-5-avg\": 28.499870538711548,\n      \"last-10-avg\": 28.499870538711548\n    },\n    \"time_since_restore\": {\n      \"max\": 28.499870538711548,\n      \"min\": 28.499870538711548,\n      \"avg\": 28.499870538711548,\n      \"last\": 28.499870538711548,\n      \"last-5-avg\": 28.499870538711548,\n      \"last-10-avg\": 28.499870538711548\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403c7ff784000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403c7ff784000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403c7ff784000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403c7ff784000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403c7ff784000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403c7ff784000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655044699.447091,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_37ba616c_37___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=64,lr=8.8205e-06,weight_decay_2022-06-12_22-37-43\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_37ba616c_37___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=64,lr=8.8205e-06,weight_decay_2022-06-12_22-37-43/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=78670, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=78670, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 401, in ff_chunk\\n    ffn_output = self.activation(ffn_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/activations.py\\\", line 34, in forward\\n    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 15.78 GiB total capacity; 2.03 GiB already allocated; 22.50 MiB free; 2.09 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"4d7ca78a\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 44,\n    \"lr\": 4.427926977433004e-05,\n    \"weight_decay\": 2.9064232625321348e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 44,\n    \"lr\": 4.427926977433004e-05,\n    \"weight_decay\": 2.9064232625321348e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"38___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=44,lr=4.4279e-05,weight_decay=2.9064e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834373838303139327102580300000063707571034b014e747104512e80025d7100580e00000039343732393834373838303139327101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 33.32303810119629,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"4d7ca78a\",\n    \"experiment_id\": \"bf71c4ee848c4a4b9b233c0465671289\",\n    \"date\": \"2022-06-12_22-39-51\",\n    \"timestamp\": 1655044791,\n    \"time_total_s\": 33.32303810119629,\n    \"pid\": 79784,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 44,\n      \"lr\": 4.427926977433004e-05,\n      \"weight_decay\": 2.9064232625321348e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 33.32303810119629,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"38___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=44,lr=4.4279e-05,weight_decay=2.9064e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655044791.9405868,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 33.32303810119629,\n      \"min\": 33.32303810119629,\n      \"avg\": 33.32303810119629,\n      \"last\": 33.32303810119629,\n      \"last-5-avg\": 33.32303810119629,\n      \"last-10-avg\": 33.32303810119629\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 33.32303810119629,\n      \"min\": 33.32303810119629,\n      \"avg\": 33.32303810119629,\n      \"last\": 33.32303810119629,\n      \"last-5-avg\": 33.32303810119629,\n      \"last-10-avg\": 33.32303810119629\n    },\n    \"time_since_restore\": {\n      \"max\": 33.32303810119629,\n      \"min\": 33.32303810119629,\n      \"avg\": 33.32303810119629,\n      \"last\": 33.32303810119629,\n      \"last-5-avg\": 33.32303810119629,\n      \"last-10-avg\": 33.32303810119629\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474040a95950000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474040a95950000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474040a95950000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474040a95950000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474040a95950000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474040a95950000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655044750.9872675,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_4d7ca78a_38___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=44,lr=4.4279e-05,weight_decay_2022-06-12_22-38-19\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"6c376e8a\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 59,\n    \"lr\": 7.758498080470458e-05,\n    \"weight_decay\": 7.610618357463311e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 59,\n    \"lr\": 7.758498080470458e-05,\n    \"weight_decay\": 7.610618357463311e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"39___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=59,lr=7.7585e-05,weight_decay=7.6106e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834373633393536387102580300000063707571034b014e747104512e80025d7100580e00000039343732393834373633393536387101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 27.836668968200684,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"6c376e8a\",\n    \"experiment_id\": \"281b6078e9a74eebae5eb7c9a8fd104f\",\n    \"date\": \"2022-06-12_22-40-30\",\n    \"timestamp\": 1655044830,\n    \"time_total_s\": 27.836668968200684,\n    \"pid\": 81220,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 59,\n      \"lr\": 7.758498080470458e-05,\n      \"weight_decay\": 7.610618357463311e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 27.836668968200684,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"39___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=59,lr=7.7585e-05,weight_decay=7.6106e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655044831.0121288,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 27.836668968200684,\n      \"min\": 27.836668968200684,\n      \"avg\": 27.836668968200684,\n      \"last\": 27.836668968200684,\n      \"last-5-avg\": 27.836668968200684,\n      \"last-10-avg\": 27.836668968200684\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 27.836668968200684,\n      \"min\": 27.836668968200684,\n      \"avg\": 27.836668968200684,\n      \"last\": 27.836668968200684,\n      \"last-5-avg\": 27.836668968200684,\n      \"last-10-avg\": 27.836668968200684\n    },\n    \"time_since_restore\": {\n      \"max\": 27.836668968200684,\n      \"min\": 27.836668968200684,\n      \"avg\": 27.836668968200684,\n      \"last\": 27.836668968200684,\n      \"last-5-avg\": 27.836668968200684,\n      \"last-10-avg\": 27.836668968200684\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403bd62ff0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403bd62ff0000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403bd62ff0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403bd62ff0000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403bd62ff0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403bd62ff0000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655044794.984228,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_6c376e8a_39___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=59,lr=7.7585e-05,weight_decay_2022-06-12_22-39-11\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"866f2cf2\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 186,\n    \"lr\": 2.7246251765968607e-05,\n    \"weight_decay\": 6.424925104006967e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 186,\n    \"lr\": 2.7246251765968607e-05,\n    \"weight_decay\": 6.424925104006967e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"40___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=186,lr=2.7246e-05,weight_decay=6.4249e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834323131343532387102580300000063707571034b014e747104512e80025d7100580e00000039343732393834323131343532387101612e01000000000000000000203f94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 24.757375955581665,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"866f2cf2\",\n    \"experiment_id\": \"ac7eccf7e53246e0b8498429beabb872\",\n    \"date\": \"2022-06-12_22-41-06\",\n    \"timestamp\": 1655044866,\n    \"time_total_s\": 24.757375955581665,\n    \"pid\": 82400,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 186,\n      \"lr\": 2.7246251765968607e-05,\n      \"weight_decay\": 6.424925104006967e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 24.757375955581665,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"40___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=186,lr=2.7246e-05,weight_decay=6.4249e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655044866.3353431,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 24.757375955581665,\n      \"min\": 24.757375955581665,\n      \"avg\": 24.757375955581665,\n      \"last\": 24.757375955581665,\n      \"last-5-avg\": 24.757375955581665,\n      \"last-10-avg\": 24.757375955581665\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 24.757375955581665,\n      \"min\": 24.757375955581665,\n      \"avg\": 24.757375955581665,\n      \"last\": 24.757375955581665,\n      \"last-5-avg\": 24.757375955581665,\n      \"last-10-avg\": 24.757375955581665\n    },\n    \"time_since_restore\": {\n      \"max\": 24.757375955581665,\n      \"min\": 24.757375955581665,\n      \"avg\": 24.757375955581665,\n      \"last\": 24.757375955581665,\n      \"last-5-avg\": 24.757375955581665,\n      \"last-10-avg\": 24.757375955581665\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474038c1e364000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474038c1e364000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474038c1e364000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474038c1e364000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474038c1e364000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474038c1e364000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655044834.035352,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_866f2cf2_40___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=186,lr=2.7246e-05,weight_deca_2022-06-12_22-39-55\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_866f2cf2_40___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=186,lr=2.7246e-05,weight_deca_2022-06-12_22-39-55/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=82400, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=82400, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 387, in forward\\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 327, in forward\\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 15.78 GiB total capacity; 2.04 GiB already allocated; 24.50 MiB free; 2.09 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"9db55e68\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 31,\n    \"lr\": 1.4458441414359883e-06,\n    \"weight_decay\": 8.355133586795106e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 31,\n    \"lr\": 1.4458441414359883e-06,\n    \"weight_decay\": 8.355133586795106e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"41___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=31,lr=1.4458e-06,weight_decay=8.3551e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834383531363937367102580300000063707571034b014e747104512e80025d7100580e00000039343732393834383531363937367101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 32.83943319320679,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"9db55e68\",\n    \"experiment_id\": \"3003bbe8ebda428bb996cdc2cd7a9e51\",\n    \"date\": \"2022-06-12_22-41-54\",\n    \"timestamp\": 1655044914,\n    \"time_total_s\": 32.83943319320679,\n    \"pid\": 83574,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 31,\n      \"lr\": 1.4458441414359883e-06,\n      \"weight_decay\": 8.355133586795106e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 32.83943319320679,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"41___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=31,lr=1.4458e-06,weight_decay=8.3551e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655044914.7199793,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 32.83943319320679,\n      \"min\": 32.83943319320679,\n      \"avg\": 32.83943319320679,\n      \"last\": 32.83943319320679,\n      \"last-5-avg\": 32.83943319320679,\n      \"last-10-avg\": 32.83943319320679\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 32.83943319320679,\n      \"min\": 32.83943319320679,\n      \"avg\": 32.83943319320679,\n      \"last\": 32.83943319320679,\n      \"last-5-avg\": 32.83943319320679,\n      \"last-10-avg\": 32.83943319320679\n    },\n    \"time_since_restore\": {\n      \"max\": 32.83943319320679,\n      \"min\": 32.83943319320679,\n      \"avg\": 32.83943319320679,\n      \"last\": 32.83943319320679,\n      \"last-5-avg\": 32.83943319320679,\n      \"last-10-avg\": 32.83943319320679\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740406b728c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740406b728c000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740406b728c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740406b728c000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740406b728c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740406b728c000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655044874.7285252,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_9db55e68_41___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=31,lr=1.4458e-06,weight_decay_2022-06-12_22-40-34\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"b5f7060c\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 21,\n    \"lr\": 1.185194545248894e-08,\n    \"weight_decay\": 8.964298059563261e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 21,\n    \"lr\": 1.185194545248894e-08,\n    \"weight_decay\": 8.964298059563261e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"42___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=21,lr=1.1852e-08,weight_decay=8.9643e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834313733393133367102580300000063707571034b014e747104512e80025d7100580e00000039343732393834313733393133367101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 38.51629567146301,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"b5f7060c\",\n    \"experiment_id\": \"0324a4d54411485cb4752a85b45731a7\",\n    \"date\": \"2022-06-12_22-42-44\",\n    \"timestamp\": 1655044964,\n    \"time_total_s\": 38.51629567146301,\n    \"pid\": 84836,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 21,\n      \"lr\": 1.185194545248894e-08,\n      \"weight_decay\": 8.964298059563261e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 38.51629567146301,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"42___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=21,lr=1.1852e-08,weight_decay=8.9643e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655044964.9601285,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 38.51629567146301,\n      \"min\": 38.51629567146301,\n      \"avg\": 38.51629567146301,\n      \"last\": 38.51629567146301,\n      \"last-5-avg\": 38.51629567146301,\n      \"last-10-avg\": 38.51629567146301\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 38.51629567146301,\n      \"min\": 38.51629567146301,\n      \"avg\": 38.51629567146301,\n      \"last\": 38.51629567146301,\n      \"last-5-avg\": 38.51629567146301,\n      \"last-10-avg\": 38.51629567146301\n    },\n    \"time_since_restore\": {\n      \"max\": 38.51629567146301,\n      \"min\": 38.51629567146301,\n      \"avg\": 38.51629567146301,\n      \"last\": 38.51629567146301,\n      \"last-5-avg\": 38.51629567146301,\n      \"last-10-avg\": 38.51629567146301\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740434215fa000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740434215fa000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740434215fa000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740434215fa000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740434215fa000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740434215fa000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655044918.0709078,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_b5f7060c_42___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=21,lr=1.1852e-08,weight_decay_2022-06-12_22-41-14\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"cfcc4a24\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 53,\n    \"lr\": 6.592911888654979e-08,\n    \"weight_decay\": 6.48014630982669e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 53,\n    \"lr\": 6.592911888654979e-08,\n    \"weight_decay\": 6.48014630982669e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"43___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=53,lr=6.5929e-08,weight_decay=6.4801e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834313734303038307102580300000063707571034b014e747104512e80025d7100580e00000039343732393834313734303038307101612e01000000000000000000203f94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 29.894397497177124,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"cfcc4a24\",\n    \"experiment_id\": \"db40ace9dc7f4cf196e19fb1d5ddfa84\",\n    \"date\": \"2022-06-12_22-43-24\",\n    \"timestamp\": 1655045004,\n    \"time_total_s\": 29.894397497177124,\n    \"pid\": 85982,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 53,\n      \"lr\": 6.592911888654979e-08,\n      \"weight_decay\": 6.48014630982669e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 29.894397497177124,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"43___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=53,lr=6.5929e-08,weight_decay=6.4801e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655045004.6051161,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 29.894397497177124,\n      \"min\": 29.894397497177124,\n      \"avg\": 29.894397497177124,\n      \"last\": 29.894397497177124,\n      \"last-5-avg\": 29.894397497177124,\n      \"last-10-avg\": 29.894397497177124\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 29.894397497177124,\n      \"min\": 29.894397497177124,\n      \"avg\": 29.894397497177124,\n      \"last\": 29.894397497177124,\n      \"last-5-avg\": 29.894397497177124,\n      \"last-10-avg\": 29.894397497177124\n    },\n    \"time_since_restore\": {\n      \"max\": 29.894397497177124,\n      \"min\": 29.894397497177124,\n      \"avg\": 29.894397497177124,\n      \"last\": 29.894397497177124,\n      \"last-5-avg\": 29.894397497177124,\n      \"last-10-avg\": 29.894397497177124\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403de4f73c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403de4f73c000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403de4f73c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403de4f73c000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403de4f73c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403de4f73c000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655044967.984062,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_cfcc4a24_43___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=53,lr=6.5929e-08,weight_decay_2022-06-12_22-41-58\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_cfcc4a24_43___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=53,lr=6.5929e-08,weight_decay_2022-06-12_22-41-58/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=85982, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=85982, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 401, in ff_chunk\\n    ffn_output = self.activation(ffn_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/activations.py\\\", line 34, in forward\\n    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 15.78 GiB total capacity; 2.05 GiB already allocated; 12.50 MiB free; 2.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"ed8d4874\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 419,\n    \"lr\": 1.5705980567965978e-07,\n    \"weight_decay\": 7.628555108837157e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 419,\n    \"lr\": 1.5705980567965978e-07,\n    \"weight_decay\": 7.628555108837157e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"44___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=419,lr=1.5706e-07,weight_decay=7.6286e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834323433373133367102580300000063707571034b014e747104512e80025d7100580e00000039343732393834323433373133367101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 24.140329122543335,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"ed8d4874\",\n    \"experiment_id\": \"f0201fa56780478ba4f1612d62d97809\",\n    \"date\": \"2022-06-12_22-44-06\",\n    \"timestamp\": 1655045046,\n    \"time_total_s\": 24.140329122543335,\n    \"pid\": 87338,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 419,\n      \"lr\": 1.5705980567965978e-07,\n      \"weight_decay\": 7.628555108837157e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 24.140329122543335,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"44___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=419,lr=1.5706e-07,weight_decay=7.6286e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655045046.7542307,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 24.140329122543335,\n      \"min\": 24.140329122543335,\n      \"avg\": 24.140329122543335,\n      \"last\": 24.140329122543335,\n      \"last-5-avg\": 24.140329122543335,\n      \"last-10-avg\": 24.140329122543335\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 24.140329122543335,\n      \"min\": 24.140329122543335,\n      \"avg\": 24.140329122543335,\n      \"last\": 24.140329122543335,\n      \"last-5-avg\": 24.140329122543335,\n      \"last-10-avg\": 24.140329122543335\n    },\n    \"time_since_restore\": {\n      \"max\": 24.140329122543335,\n      \"min\": 24.140329122543335,\n      \"avg\": 24.140329122543335,\n      \"last\": 24.140329122543335,\n      \"last-5-avg\": 24.140329122543335,\n      \"last-10-avg\": 24.140329122543335\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403823ec9c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403823ec9c000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403823ec9c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403823ec9c000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403823ec9c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403823ec9c000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655045014.5340016,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_ed8d4874_44___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=419,lr=1.5706e-07,weight_deca_2022-06-12_22-42-48\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"094b4b10\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 224,\n    \"lr\": 5.887162086391595e-08,\n    \"weight_decay\": 6.415902936387766e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 224,\n    \"lr\": 5.887162086391595e-08,\n    \"weight_decay\": 6.415902936387766e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"45___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=224,lr=5.8872e-08,weight_decay=6.4159e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834373837313034307102580300000063707571034b014e747104512e80025d7100580e00000039343732393834373837313034307101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 27.503618240356445,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"094b4b10\",\n    \"experiment_id\": \"f02656e34b644a36be6fe317845cdda8\",\n    \"date\": \"2022-06-12_22-44-45\",\n    \"timestamp\": 1655045085,\n    \"time_total_s\": 27.503618240356445,\n    \"pid\": 88702,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 224,\n      \"lr\": 5.887162086391595e-08,\n      \"weight_decay\": 6.415902936387766e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 27.503618240356445,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"45___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=224,lr=5.8872e-08,weight_decay=6.4159e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655045085.1471746,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 27.503618240356445,\n      \"min\": 27.503618240356445,\n      \"avg\": 27.503618240356445,\n      \"last\": 27.503618240356445,\n      \"last-5-avg\": 27.503618240356445,\n      \"last-10-avg\": 27.503618240356445\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 27.503618240356445,\n      \"min\": 27.503618240356445,\n      \"avg\": 27.503618240356445,\n      \"last\": 27.503618240356445,\n      \"last-5-avg\": 27.503618240356445,\n      \"last-10-avg\": 27.503618240356445\n    },\n    \"time_since_restore\": {\n      \"max\": 27.503618240356445,\n      \"min\": 27.503618240356445,\n      \"avg\": 27.503618240356445,\n      \"last\": 27.503618240356445,\n      \"last-5-avg\": 27.503618240356445,\n      \"last-10-avg\": 27.503618240356445\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403b80ed20000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403b80ed20000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403b80ed20000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403b80ed20000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403b80ed20000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403b80ed20000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655045049.9002619,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_094b4b10_45___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=224,lr=5.8872e-08,weight_deca_2022-06-12_22-43-34\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"1e615170\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 417,\n    \"lr\": 4.397579369842964e-08,\n    \"weight_decay\": 9.117150274005953e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 417,\n    \"lr\": 4.397579369842964e-08,\n    \"weight_decay\": 9.117150274005953e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"46___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=417,lr=4.3976e-08,weight_decay=9.1172e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834373837383431367102580300000063707571034b014e747104512e80025d7100580e00000039343732393834373837383431367101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 30.145951747894287,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"1e615170\",\n    \"experiment_id\": \"5b151ffeef4644e78a86ac3b9d944680\",\n    \"date\": \"2022-06-12_22-45-26\",\n    \"timestamp\": 1655045126,\n    \"time_total_s\": 30.145951747894287,\n    \"pid\": 89765,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 417,\n      \"lr\": 4.397579369842964e-08,\n      \"weight_decay\": 9.117150274005953e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 30.145951747894287,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"46___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=417,lr=4.3976e-08,weight_decay=9.1172e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655045126.325551,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 30.145951747894287,\n      \"min\": 30.145951747894287,\n      \"avg\": 30.145951747894287,\n      \"last\": 30.145951747894287,\n      \"last-5-avg\": 30.145951747894287,\n      \"last-10-avg\": 30.145951747894287\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 30.145951747894287,\n      \"min\": 30.145951747894287,\n      \"avg\": 30.145951747894287,\n      \"last\": 30.145951747894287,\n      \"last-5-avg\": 30.145951747894287,\n      \"last-10-avg\": 30.145951747894287\n    },\n    \"time_since_restore\": {\n      \"max\": 30.145951747894287,\n      \"min\": 30.145951747894287,\n      \"avg\": 30.145951747894287,\n      \"last\": 30.145951747894287,\n      \"last-5-avg\": 30.145951747894287,\n      \"last-10-avg\": 30.145951747894287\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403e255d18000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403e255d18000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403e255d18000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403e255d18000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403e255d18000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403e255d18000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655045088.437762,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_1e615170_46___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=417,lr=4.3976e-08,weight_deca_2022-06-12_22-44-10\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_1e615170_46___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=417,lr=4.3976e-08,weight_deca_2022-06-12_22-44-10/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=89765, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=89765, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 387, in forward\\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 327, in forward\\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 15.78 GiB total capacity; 1.98 GiB already allocated; 90.50 MiB free; 2.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"355ca65e\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 181,\n    \"lr\": 2.1292067683648545e-08,\n    \"weight_decay\": 8.02228088658556e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 181,\n    \"lr\": 2.1292067683648545e-08,\n    \"weight_decay\": 8.02228088658556e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"47___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=181,lr=2.1292e-08,weight_decay=8.0223e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834323433373233327102580300000063707571034b014e747104512e80025d7100580e00000039343732393834323433373233327101612e01000000000000000000203f94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 28.28447937965393,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"355ca65e\",\n    \"experiment_id\": \"76aac26509ab422cbc416ba78e8e5a68\",\n    \"date\": \"2022-06-12_22-46-11\",\n    \"timestamp\": 1655045171,\n    \"time_total_s\": 28.28447937965393,\n    \"pid\": 90946,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 181,\n      \"lr\": 2.1292067683648545e-08,\n      \"weight_decay\": 8.02228088658556e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 28.28447937965393,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"47___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=181,lr=2.1292e-08,weight_decay=8.0223e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655045171.1743793,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 28.28447937965393,\n      \"min\": 28.28447937965393,\n      \"avg\": 28.28447937965393,\n      \"last\": 28.28447937965393,\n      \"last-5-avg\": 28.28447937965393,\n      \"last-10-avg\": 28.28447937965393\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 28.28447937965393,\n      \"min\": 28.28447937965393,\n      \"avg\": 28.28447937965393,\n      \"last\": 28.28447937965393,\n      \"last-5-avg\": 28.28447937965393,\n      \"last-10-avg\": 28.28447937965393\n    },\n    \"time_since_restore\": {\n      \"max\": 28.28447937965393,\n      \"min\": 28.28447937965393,\n      \"avg\": 28.28447937965393,\n      \"last\": 28.28447937965393,\n      \"last-5-avg\": 28.28447937965393,\n      \"last-10-avg\": 28.28447937965393\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403c48d3a4000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403c48d3a4000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403c48d3a4000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403c48d3a4000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403c48d3a4000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403c48d3a4000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655045134.8025799,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_355ca65e_47___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=181,lr=2.1292e-08,weight_deca_2022-06-12_22-44-48\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_355ca65e_47___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=181,lr=2.1292e-08,weight_deca_2022-06-12_22-44-48/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=90946, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=90946, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 387, in forward\\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 327, in forward\\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 15.78 GiB total capacity; 2.04 GiB already allocated; 20.50 MiB free; 2.09 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"50fadeb2\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 453,\n    \"lr\": 4.820469586271586e-08,\n    \"weight_decay\": 9.038985506589518e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 453,\n    \"lr\": 4.820469586271586e-08,\n    \"weight_decay\": 9.038985506589518e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"48___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=453,lr=4.8205e-08,weight_decay=9.039e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834323437333538347102580300000063707571034b014e747104512e80025d7100580e00000039343732393834323437333538347101612e01000000000000000000803e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 27.0477511882782,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"50fadeb2\",\n    \"experiment_id\": \"1f77f17d385444bcacbf6e52e372147c\",\n    \"date\": \"2022-06-12_22-46-53\",\n    \"timestamp\": 1655045213,\n    \"time_total_s\": 27.0477511882782,\n    \"pid\": 92421,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 453,\n      \"lr\": 4.820469586271586e-08,\n      \"weight_decay\": 9.038985506589518e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 27.0477511882782,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"48___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=453,lr=4.8205e-08,weight_decay=9.039e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655045213.767825,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 27.0477511882782,\n      \"min\": 27.0477511882782,\n      \"avg\": 27.0477511882782,\n      \"last\": 27.0477511882782,\n      \"last-5-avg\": 27.0477511882782,\n      \"last-10-avg\": 27.0477511882782\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 27.0477511882782,\n      \"min\": 27.0477511882782,\n      \"avg\": 27.0477511882782,\n      \"last\": 27.0477511882782,\n      \"last-5-avg\": 27.0477511882782,\n      \"last-10-avg\": 27.0477511882782\n    },\n    \"time_since_restore\": {\n      \"max\": 27.0477511882782,\n      \"min\": 27.0477511882782,\n      \"avg\": 27.0477511882782,\n      \"last\": 27.0477511882782,\n      \"last-5-avg\": 27.0477511882782,\n      \"last-10-avg\": 27.0477511882782\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403b0c396c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403b0c396c000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403b0c396c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403b0c396c000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403b0c396c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403b0c396c000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655045179.1426706,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_50fadeb2_48___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=453,lr=4.8205e-08,weight_deca_2022-06-12_22-45-34\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_50fadeb2_48___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=453,lr=4.8205e-08,weight_deca_2022-06-12_22-45-34/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=92421, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=92421, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 387, in forward\\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 327, in forward\\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 15.78 GiB total capacity; 1.97 GiB already allocated; 92.50 MiB free; 2.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"6b6b0038\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 202,\n    \"lr\": 1.84836614680022e-08,\n    \"weight_decay\": 6.528337849222632e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 202,\n    \"lr\": 1.84836614680022e-08,\n    \"weight_decay\": 6.528337849222632e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"49___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=202,lr=1.8484e-08,weight_decay=6.5283e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834383838363635367102580300000063707571034b014e747104512e80025d7100580e00000039343732393834383838363635367101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 26.8613178730011,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"6b6b0038\",\n    \"experiment_id\": \"b5d6933d992c4aaa9f06472247d22a21\",\n    \"date\": \"2022-06-12_22-47-36\",\n    \"timestamp\": 1655045256,\n    \"time_total_s\": 26.8613178730011,\n    \"pid\": 93855,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 202,\n      \"lr\": 1.84836614680022e-08,\n      \"weight_decay\": 6.528337849222632e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 26.8613178730011,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"49___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=202,lr=1.8484e-08,weight_decay=6.5283e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655045256.7649198,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 26.8613178730011,\n      \"min\": 26.8613178730011,\n      \"avg\": 26.8613178730011,\n      \"last\": 26.8613178730011,\n      \"last-5-avg\": 26.8613178730011,\n      \"last-10-avg\": 26.8613178730011\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 26.8613178730011,\n      \"min\": 26.8613178730011,\n      \"avg\": 26.8613178730011,\n      \"last\": 26.8613178730011,\n      \"last-5-avg\": 26.8613178730011,\n      \"last-10-avg\": 26.8613178730011\n    },\n    \"time_since_restore\": {\n      \"max\": 26.8613178730011,\n      \"min\": 26.8613178730011,\n      \"avg\": 26.8613178730011,\n      \"last\": 26.8613178730011,\n      \"last-5-avg\": 26.8613178730011,\n      \"last-10-avg\": 26.8613178730011\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403adc7f54000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403adc7f54000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403adc7f54000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403adc7f54000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403adc7f54000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403adc7f54000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1655045222.455998,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_6b6b0038_49___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=202,lr=1.8484e-08,weight_deca_2022-06-12_22-46-19\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"853b2402\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 418,\n    \"lr\": 4.863090485067512e-08,\n    \"weight_decay\": 8.879566626338624e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 418,\n    \"lr\": 4.863090485067512e-08,\n    \"weight_decay\": 8.879566626338624e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"50___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=418,lr=4.8631e-08,weight_decay=8.8796e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834313738363730347102580300000063707571034b014e747104512e80025d7100580e00000039343732393834313738363730347101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 24.645142555236816,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"853b2402\",\n    \"experiment_id\": \"84fdd05a667f463e95838257cb7f1351\",\n    \"date\": \"2022-06-12_22-48-12\",\n    \"timestamp\": 1655045292,\n    \"time_total_s\": 24.645142555236816,\n    \"pid\": 95250,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 418,\n      \"lr\": 4.863090485067512e-08,\n      \"weight_decay\": 8.879566626338624e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 24.645142555236816,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"50___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=418,lr=4.8631e-08,weight_decay=8.8796e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655045292.953823,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 24.645142555236816,\n      \"min\": 24.645142555236816,\n      \"avg\": 24.645142555236816,\n      \"last\": 24.645142555236816,\n      \"last-5-avg\": 24.645142555236816,\n      \"last-10-avg\": 24.645142555236816\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 24.645142555236816,\n      \"min\": 24.645142555236816,\n      \"avg\": 24.645142555236816,\n      \"last\": 24.645142555236816,\n      \"last-5-avg\": 24.645142555236816,\n      \"last-10-avg\": 24.645142555236816\n    },\n    \"time_since_restore\": {\n      \"max\": 24.645142555236816,\n      \"min\": 24.645142555236816,\n      \"avg\": 24.645142555236816,\n      \"last\": 24.645142555236816,\n      \"last-5-avg\": 24.645142555236816,\n      \"last-10-avg\": 24.645142555236816\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474038a52810000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474038a52810000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474038a52810000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474038a52810000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474038a52810000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474038a52810000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655045260.1226864,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_853b2402_50___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=418,lr=4.8631e-08,weight_deca_2022-06-12_22-47-02\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_853b2402_50___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=418,lr=4.8631e-08,weight_deca_2022-06-12_22-47-02/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=95250, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=95250, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 387, in forward\\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 327, in forward\\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 15.78 GiB total capacity; 1.98 GiB already allocated; 90.50 MiB free; 2.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"9badf188\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 598,\n    \"lr\": 5.927693673547657e-07,\n    \"weight_decay\": 8.959184899627047e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 598,\n    \"lr\": 5.927693673547657e-07,\n    \"weight_decay\": 8.959184899627047e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"51___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=598,lr=5.9277e-07,weight_decay=8.9592e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834383733383230387102580300000063707571034b014e747104512e80025d7100580e00000039343732393834383733383230387101612e01000000000000000000803e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 16.81061887741089,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"9badf188\",\n    \"experiment_id\": \"da2eb5d8c3ae4c3daf8e754add898b0e\",\n    \"date\": \"2022-06-12_22-48-45\",\n    \"timestamp\": 1655045325,\n    \"time_total_s\": 16.81061887741089,\n    \"pid\": 96445,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 598,\n      \"lr\": 5.927693673547657e-07,\n      \"weight_decay\": 8.959184899627047e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 16.81061887741089,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"51___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=598,lr=5.9277e-07,weight_decay=8.9592e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655045325.7835443,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 16.81061887741089,\n      \"min\": 16.81061887741089,\n      \"avg\": 16.81061887741089,\n      \"last\": 16.81061887741089,\n      \"last-5-avg\": 16.81061887741089,\n      \"last-10-avg\": 16.81061887741089\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 16.81061887741089,\n      \"min\": 16.81061887741089,\n      \"avg\": 16.81061887741089,\n      \"last\": 16.81061887741089,\n      \"last-5-avg\": 16.81061887741089,\n      \"last-10-avg\": 16.81061887741089\n    },\n    \"time_since_restore\": {\n      \"max\": 16.81061887741089,\n      \"min\": 16.81061887741089,\n      \"avg\": 16.81061887741089,\n      \"last\": 16.81061887741089,\n      \"last-5-avg\": 16.81061887741089,\n      \"last-10-avg\": 16.81061887741089\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474030cf84b8000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474030cf84b8000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474030cf84b8000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474030cf84b8000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474030cf84b8000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474030cf84b8000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655045301.85131,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_9badf188_51___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=598,lr=5.9277e-07,weight_deca_2022-06-12_22-47-40\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_9badf188_51___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=598,lr=5.9277e-07,weight_deca_2022-06-12_22-47-40/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=96445, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=96445, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 387, in forward\\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 328, in forward\\n    attention_scores = attention_scores / math.sqrt(self.attention_head_size)\\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 15.78 GiB total capacity; 2.05 GiB already allocated; 12.50 MiB free; 2.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"b48d23ae\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 398,\n    \"lr\": 4.493908668962399e-08,\n    \"weight_decay\": 8.825718789613899e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 398,\n    \"lr\": 4.493908668962399e-08,\n    \"weight_decay\": 8.825718789613899e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"52___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=398,lr=4.4939e-08,weight_decay=8.8257e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834313734393536387102580300000063707571034b014e747104512e80025d7100580e00000039343732393834313734393536387101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 24.779791355133057,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"b48d23ae\",\n    \"experiment_id\": \"c9cc988c9e1e4f41ab49a4c67ce7b997\",\n    \"date\": \"2022-06-12_22-49-24\",\n    \"timestamp\": 1655045364,\n    \"time_total_s\": 24.779791355133057,\n    \"pid\": 97836,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 398,\n      \"lr\": 4.493908668962399e-08,\n      \"weight_decay\": 8.825718789613899e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 24.779791355133057,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"52___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=398,lr=4.4939e-08,weight_decay=8.8257e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655045364.042496,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 24.779791355133057,\n      \"min\": 24.779791355133057,\n      \"avg\": 24.779791355133057,\n      \"last\": 24.779791355133057,\n      \"last-5-avg\": 24.779791355133057,\n      \"last-10-avg\": 24.779791355133057\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 24.779791355133057,\n      \"min\": 24.779791355133057,\n      \"avg\": 24.779791355133057,\n      \"last\": 24.779791355133057,\n      \"last-5-avg\": 24.779791355133057,\n      \"last-10-avg\": 24.779791355133057\n    },\n    \"time_since_restore\": {\n      \"max\": 24.779791355133057,\n      \"min\": 24.779791355133057,\n      \"avg\": 24.779791355133057,\n      \"last\": 24.779791355133057,\n      \"last-5-avg\": 24.779791355133057,\n      \"last-10-avg\": 24.779791355133057\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474038c7a068000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474038c7a068000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474038c7a068000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474038c7a068000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474038c7a068000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474038c7a068000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655045332.592859,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_b48d23ae_52___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=398,lr=4.4939e-08,weight_deca_2022-06-12_22-48-21\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_b48d23ae_52___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=398,lr=4.4939e-08,weight_deca_2022-06-12_22-48-21/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=97836, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=97836, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 387, in forward\\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 327, in forward\\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 15.78 GiB total capacity; 1.98 GiB already allocated; 86.50 MiB free; 2.03 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"c6df09f0\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 663,\n    \"lr\": 8.06432309848732e-08,\n    \"weight_decay\": 7.898111551265894e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 663,\n    \"lr\": 8.06432309848732e-08,\n    \"weight_decay\": 7.898111551265894e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"53___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=663,lr=8.0643e-08,weight_decay=7.8981e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834313735353230307102580300000063707571034b014e747104512e80025d7100580e00000039343732393834313735353230307101612e01000000000000000000103f94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 48.53908443450928,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"c6df09f0\",\n    \"experiment_id\": \"b5c2b500a98640eda58f8a83897df756\",\n    \"date\": \"2022-06-12_22-50-27\",\n    \"timestamp\": 1655045427,\n    \"time_total_s\": 48.53908443450928,\n    \"pid\": 98988,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 663,\n      \"lr\": 8.06432309848732e-08,\n      \"weight_decay\": 7.898111551265894e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 48.53908443450928,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"53___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=663,lr=8.0643e-08,weight_decay=7.8981e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655045427.2780838,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 48.53908443450928,\n      \"min\": 48.53908443450928,\n      \"avg\": 48.53908443450928,\n      \"last\": 48.53908443450928,\n      \"last-5-avg\": 48.53908443450928,\n      \"last-10-avg\": 48.53908443450928\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 48.53908443450928,\n      \"min\": 48.53908443450928,\n      \"avg\": 48.53908443450928,\n      \"last\": 48.53908443450928,\n      \"last-5-avg\": 48.53908443450928,\n      \"last-10-avg\": 48.53908443450928\n    },\n    \"time_since_restore\": {\n      \"max\": 48.53908443450928,\n      \"min\": 48.53908443450928,\n      \"avg\": 48.53908443450928,\n      \"last\": 48.53908443450928,\n      \"last-5-avg\": 48.53908443450928,\n      \"last-10-avg\": 48.53908443450928\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740484500b8000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740484500b8000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740484500b8000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740484500b8000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740484500b8000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740484500b8000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655045372.6380422,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_c6df09f0_53___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=663,lr=8.0643e-08,weight_deca_2022-06-12_22-48-52\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_c6df09f0_53___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=663,lr=8.0643e-08,weight_deca_2022-06-12_22-48-52/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=98988, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=98988, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 387, in forward\\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 328, in forward\\n    attention_scores = attention_scores / math.sqrt(self.attention_head_size)\\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 15.78 GiB total capacity; 2.05 GiB already allocated; 10.50 MiB free; 2.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"dec0999e\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 413,\n    \"lr\": 3.665675423532597e-08,\n    \"weight_decay\": 8.71337166644887e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 413,\n    \"lr\": 3.665675423532597e-08,\n    \"weight_decay\": 8.71337166644887e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"54___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=413,lr=3.6657e-08,weight_decay=8.7134e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834343332313337367102580300000063707571034b014e747104512e80025d7100580e00000039343732393834343332313337367101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 40.848592042922974,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"dec0999e\",\n    \"experiment_id\": \"e9ce63b3452a4abbbd45ba9faec3bd92\",\n    \"date\": \"2022-06-12_22-51-24\",\n    \"timestamp\": 1655045484,\n    \"time_total_s\": 40.848592042922974,\n    \"pid\": 100348,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 413,\n      \"lr\": 3.665675423532597e-08,\n      \"weight_decay\": 8.71337166644887e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 40.848592042922974,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"54___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=413,lr=3.6657e-08,weight_decay=8.7134e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655045484.4717875,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 40.848592042922974,\n      \"min\": 40.848592042922974,\n      \"avg\": 40.848592042922974,\n      \"last\": 40.848592042922974,\n      \"last-5-avg\": 40.848592042922974,\n      \"last-10-avg\": 40.848592042922974\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 40.848592042922974,\n      \"min\": 40.848592042922974,\n      \"avg\": 40.848592042922974,\n      \"last\": 40.848592042922974,\n      \"last-5-avg\": 40.848592042922974,\n      \"last-10-avg\": 40.848592042922974\n    },\n    \"time_since_restore\": {\n      \"max\": 40.848592042922974,\n      \"min\": 40.848592042922974,\n      \"avg\": 40.848592042922974,\n      \"last\": 40.848592042922974,\n      \"last-5-avg\": 40.848592042922974,\n      \"last-10-avg\": 40.848592042922974\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740446c9eaa000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740446c9eaa000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740446c9eaa000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740446c9eaa000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740446c9eaa000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740446c9eaa000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655045435.756121,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_dec0999e_54___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=413,lr=3.6657e-08,weight_deca_2022-06-12_22-49-32\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_dec0999e_54___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=413,lr=3.6657e-08,weight_deca_2022-06-12_22-49-32/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=100348, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=100348, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 387, in forward\\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 327, in forward\\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 15.78 GiB total capacity; 1.98 GiB already allocated; 90.50 MiB free; 2.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"045e9426\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 641,\n    \"lr\": 5.527262615736493e-07,\n    \"weight_decay\": 7.940859225599713e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 641,\n    \"lr\": 5.527262615736493e-07,\n    \"weight_decay\": 7.940859225599713e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"55___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=641,lr=5.5273e-07,weight_decay=7.9409e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834343332313337367102580300000063707571034b014e747104512e80025d7100580e00000039343732393834343332313337367101612e01000000000000000000c03e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 27.60946011543274,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"045e9426\",\n    \"experiment_id\": \"ba8d29f89bc54e71b7f31ba3a161dcd3\",\n    \"date\": \"2022-06-12_22-51-57\",\n    \"timestamp\": 1655045517,\n    \"time_total_s\": 27.60946011543274,\n    \"pid\": 102217,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 641,\n      \"lr\": 5.527262615736493e-07,\n      \"weight_decay\": 7.940859225599713e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 27.60946011543274,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"55___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=641,lr=5.5273e-07,weight_decay=7.9409e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655045517.2609475,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 27.60946011543274,\n      \"min\": 27.60946011543274,\n      \"avg\": 27.60946011543274,\n      \"last\": 27.60946011543274,\n      \"last-5-avg\": 27.60946011543274,\n      \"last-10-avg\": 27.60946011543274\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 27.60946011543274,\n      \"min\": 27.60946011543274,\n      \"avg\": 27.60946011543274,\n      \"last\": 27.60946011543274,\n      \"last-5-avg\": 27.60946011543274,\n      \"last-10-avg\": 27.60946011543274\n    },\n    \"time_since_restore\": {\n      \"max\": 27.60946011543274,\n      \"min\": 27.60946011543274,\n      \"avg\": 27.60946011543274,\n      \"last\": 27.60946011543274,\n      \"last-5-avg\": 27.60946011543274,\n      \"last-10-avg\": 27.60946011543274\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403b9c0594000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403b9c0594000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403b9c0594000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403b9c0594000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403b9c0594000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403b9c0594000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1655045481.7689302,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_045e9426_55___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=641,lr=5.5273e-07,weight_deca_2022-06-12_22-50-35\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"1fca801c\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 34,\n    \"lr\": 5.2343508564925885e-06,\n    \"weight_decay\": 5.463546415216214e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 34,\n    \"lr\": 5.2343508564925885e-06,\n    \"weight_decay\": 5.463546415216214e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"56___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=34,lr=5.2344e-06,weight_decay=5.4635e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834313739343531327102580300000063707571034b014e747104512e80025d7100580e00000039343732393834313739343531327101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 57.74179267883301,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"1fca801c\",\n    \"experiment_id\": \"0af3ad9563ea445f91785b6c222df4a8\",\n    \"date\": \"2022-06-12_22-52-38\",\n    \"timestamp\": 1655045558,\n    \"time_total_s\": 57.74179267883301,\n    \"pid\": 103615,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 34,\n      \"lr\": 5.2343508564925885e-06,\n      \"weight_decay\": 5.463546415216214e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 57.74179267883301,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"56___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=34,lr=5.2344e-06,weight_decay=5.4635e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655045558.9959,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 57.74179267883301,\n      \"min\": 57.74179267883301,\n      \"avg\": 57.74179267883301,\n      \"last\": 57.74179267883301,\n      \"last-5-avg\": 57.74179267883301,\n      \"last-10-avg\": 57.74179267883301\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 57.74179267883301,\n      \"min\": 57.74179267883301,\n      \"avg\": 57.74179267883301,\n      \"last\": 57.74179267883301,\n      \"last-5-avg\": 57.74179267883301,\n      \"last-10-avg\": 57.74179267883301\n    },\n    \"time_since_restore\": {\n      \"max\": 57.74179267883301,\n      \"min\": 57.74179267883301,\n      \"avg\": 57.74179267883301,\n      \"last\": 57.74179267883301,\n      \"last-5-avg\": 57.74179267883301,\n      \"last-10-avg\": 57.74179267883301\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447404cdef310000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447404cdef310000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447404cdef310000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447404cdef310000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447404cdef310000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447404cdef310000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655045492.913192,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_1fca801c_56___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=34,lr=5.2344e-06,weight_decay_2022-06-12_22-51-21\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_1fca801c_56___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=34,lr=5.2344e-06,weight_decay_2022-06-12_22-51-21/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=103615, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=103615, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 387, in forward\\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 327, in forward\\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 15.78 GiB total capacity; 2.03 GiB already allocated; 50.50 MiB free; 2.06 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"266f6ec8\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 48,\n    \"lr\": 9.2343422905094e-06,\n    \"weight_decay\": 5.099229306081046e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 48,\n    \"lr\": 9.2343422905094e-06,\n    \"weight_decay\": 5.099229306081046e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"57___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=48,lr=9.2343e-06,weight_decay=5.0992e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834393139353737367102580300000063707571034b014e747104512e80025d7100580e00000039343732393834393139353737367101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 34.85411071777344,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"266f6ec8\",\n    \"experiment_id\": \"e6f5dca8a2044f14ae2f863d1e615b27\",\n    \"date\": \"2022-06-12_22-53-30\",\n    \"timestamp\": 1655045610,\n    \"time_total_s\": 34.85411071777344,\n    \"pid\": 103903,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 48,\n      \"lr\": 9.2343422905094e-06,\n      \"weight_decay\": 5.099229306081046e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 34.85411071777344,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"57___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=48,lr=9.2343e-06,weight_decay=5.0992e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655045610.8387325,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 34.85411071777344,\n      \"min\": 34.85411071777344,\n      \"avg\": 34.85411071777344,\n      \"last\": 34.85411071777344,\n      \"last-5-avg\": 34.85411071777344,\n      \"last-10-avg\": 34.85411071777344\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 34.85411071777344,\n      \"min\": 34.85411071777344,\n      \"avg\": 34.85411071777344,\n      \"last\": 34.85411071777344,\n      \"last-5-avg\": 34.85411071777344,\n      \"last-10-avg\": 34.85411071777344\n    },\n    \"time_since_restore\": {\n      \"max\": 34.85411071777344,\n      \"min\": 34.85411071777344,\n      \"avg\": 34.85411071777344,\n      \"last\": 34.85411071777344,\n      \"last-5-avg\": 34.85411071777344,\n      \"last-10-avg\": 34.85411071777344\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740416d5380000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740416d5380000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740416d5380000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740416d5380000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740416d5380000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740416d5380000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655045567.4986722,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_266f6ec8_57___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=48,lr=9.2343e-06,weight_decay_2022-06-12_22-51-33\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_266f6ec8_57___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=48,lr=9.2343e-06,weight_decay_2022-06-12_22-51-33/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=103903, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=103903, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 387, in forward\\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 362, in forward\\n    context_layer = context_layer.transpose(2, 1).flatten(2)\\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 15.78 GiB total capacity; 2.05 GiB already allocated; 8.50 MiB free; 2.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"52e381e2\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 140,\n    \"lr\": 6.572074907911839e-06,\n    \"weight_decay\": 5.2842008682808074e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 140,\n    \"lr\": 6.572074907911839e-06,\n    \"weight_decay\": 5.2842008682808074e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"58___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=140,lr=6.5721e-06,weight_decay=5.2842e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834393334343039367102580300000063707571034b014e747104512e80025d7100580e00000039343732393834393334343039367101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 25.233400344848633,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"52e381e2\",\n    \"experiment_id\": \"2f68aa976b204a5fb4ea46d62c6b8dc5\",\n    \"date\": \"2022-06-12_22-54-11\",\n    \"timestamp\": 1655045651,\n    \"time_total_s\": 25.233400344848633,\n    \"pid\": 106189,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 140,\n      \"lr\": 6.572074907911839e-06,\n      \"weight_decay\": 5.2842008682808074e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 25.233400344848633,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"58___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=140,lr=6.5721e-06,weight_decay=5.2842e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655045651.740031,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 25.233400344848633,\n      \"min\": 25.233400344848633,\n      \"avg\": 25.233400344848633,\n      \"last\": 25.233400344848633,\n      \"last-5-avg\": 25.233400344848633,\n      \"last-10-avg\": 25.233400344848633\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 25.233400344848633,\n      \"min\": 25.233400344848633,\n      \"avg\": 25.233400344848633,\n      \"last\": 25.233400344848633,\n      \"last-5-avg\": 25.233400344848633,\n      \"last-10-avg\": 25.233400344848633\n    },\n    \"time_since_restore\": {\n      \"max\": 25.233400344848633,\n      \"min\": 25.233400344848633,\n      \"avg\": 25.233400344848633,\n      \"last\": 25.233400344848633,\n      \"last-5-avg\": 25.233400344848633,\n      \"last-10-avg\": 25.233400344848633\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740393bc020000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740393bc020000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740393bc020000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740393bc020000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740393bc020000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740393bc020000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655045619.8610258,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_52e381e2_58___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=140,lr=6.5721e-06,weight_deca_2022-06-12_22-52-47\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_52e381e2_58___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=140,lr=6.5721e-06,weight_deca_2022-06-12_22-52-47/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=106189, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=106189, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 387, in forward\\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 327, in forward\\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 15.78 GiB total capacity; 2.05 GiB already allocated; 12.50 MiB free; 2.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"7218cdc4\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 32,\n    \"lr\": 4.880853301105732e-06,\n    \"weight_decay\": 6.121907296942992e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 32,\n    \"lr\": 4.880853301105732e-06,\n    \"weight_decay\": 6.121907296942992e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"59___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=32,lr=4.8809e-06,weight_decay=6.1219e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834383832323132387102580300000063707571034b014e747104512e80025d7100580e00000039343732393834383832323132387101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 32.026729345321655,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"7218cdc4\",\n    \"experiment_id\": \"c22e32976480493a972650beb9d6f556\",\n    \"date\": \"2022-06-12_22-55-00\",\n    \"timestamp\": 1655045700,\n    \"time_total_s\": 32.026729345321655,\n    \"pid\": 107697,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 32,\n      \"lr\": 4.880853301105732e-06,\n      \"weight_decay\": 6.121907296942992e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 32.026729345321655,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"59___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=32,lr=4.8809e-06,weight_decay=6.1219e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655045700.386812,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 32.026729345321655,\n      \"min\": 32.026729345321655,\n      \"avg\": 32.026729345321655,\n      \"last\": 32.026729345321655,\n      \"last-5-avg\": 32.026729345321655,\n      \"last-10-avg\": 32.026729345321655\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 32.026729345321655,\n      \"min\": 32.026729345321655,\n      \"avg\": 32.026729345321655,\n      \"last\": 32.026729345321655,\n      \"last-5-avg\": 32.026729345321655,\n      \"last-10-avg\": 32.026729345321655\n    },\n    \"time_since_restore\": {\n      \"max\": 32.026729345321655,\n      \"min\": 32.026729345321655,\n      \"avg\": 32.026729345321655,\n      \"last\": 32.026729345321655,\n      \"last-5-avg\": 32.026729345321655,\n      \"last-10-avg\": 32.026729345321655\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474040036bde000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474040036bde000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474040036bde000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474040036bde000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474040036bde000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474040036bde000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655045659.7696257,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_7218cdc4_59___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=32,lr=4.8809e-06,weight_decay_2022-06-12_22-53-39\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_7218cdc4_59___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=32,lr=4.8809e-06,weight_decay_2022-06-12_22-53-39/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=107697, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=107697, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 387, in forward\\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 327, in forward\\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 15.78 GiB total capacity; 2.05 GiB already allocated; 10.50 MiB free; 2.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"89e4df38\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 92,\n    \"lr\": 2.8605358587930106e-05,\n    \"weight_decay\": 5.0904334595111714e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 92,\n    \"lr\": 2.8605358587930106e-05,\n    \"weight_decay\": 5.0904334595111714e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"60___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=92,lr=2.8605e-05,weight_decay=5.0904e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834313831343936307102580300000063707571034b014e747104512e80025d7100580e00000039343732393834313831343936307101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 31.45621657371521,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"89e4df38\",\n    \"experiment_id\": \"564929e4091341b3b51a5d8807727b7b\",\n    \"date\": \"2022-06-12_22-55-50\",\n    \"timestamp\": 1655045750,\n    \"time_total_s\": 31.45621657371521,\n    \"pid\": 108972,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 92,\n      \"lr\": 2.8605358587930106e-05,\n      \"weight_decay\": 5.0904334595111714e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 31.45621657371521,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"60___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=92,lr=2.8605e-05,weight_decay=5.0904e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655045751.0094118,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 31.45621657371521,\n      \"min\": 31.45621657371521,\n      \"avg\": 31.45621657371521,\n      \"last\": 31.45621657371521,\n      \"last-5-avg\": 31.45621657371521,\n      \"last-10-avg\": 31.45621657371521\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 31.45621657371521,\n      \"min\": 31.45621657371521,\n      \"avg\": 31.45621657371521,\n      \"last\": 31.45621657371521,\n      \"last-5-avg\": 31.45621657371521,\n      \"last-10-avg\": 31.45621657371521\n    },\n    \"time_since_restore\": {\n      \"max\": 31.45621657371521,\n      \"min\": 31.45621657371521,\n      \"avg\": 31.45621657371521,\n      \"last\": 31.45621657371521,\n      \"last-5-avg\": 31.45621657371521,\n      \"last-10-avg\": 31.45621657371521\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403f74ca9c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403f74ca9c000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403f74ca9c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403f74ca9c000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403f74ca9c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403f74ca9c000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655045709.200805,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_89e4df38_60___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=92,lr=2.8605e-05,weight_decay_2022-06-12_22-54-19\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_89e4df38_60___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=92,lr=2.8605e-05,weight_decay_2022-06-12_22-54-19/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=108972, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=108972, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 401, in ff_chunk\\n    ffn_output = self.activation(ffn_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/activations.py\\\", line 34, in forward\\n    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 15.78 GiB total capacity; 2.03 GiB already allocated; 36.50 MiB free; 2.07 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"a759cfe2\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 136,\n    \"lr\": 5.813220172981006e-06,\n    \"weight_decay\": 5.958411405790899e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 136,\n    \"lr\": 5.813220172981006e-06,\n    \"weight_decay\": 5.958411405790899e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"61___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=136,lr=5.8132e-06,weight_decay=5.9584e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834383930383730347102580300000063707571034b014e747104512e80025d7100580e00000039343732393834383930383730347101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 27.35220742225647,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"a759cfe2\",\n    \"experiment_id\": \"a5cc3ed4c7224cf4af59b4a1116fea18\",\n    \"date\": \"2022-06-12_22-56-34\",\n    \"timestamp\": 1655045794,\n    \"time_total_s\": 27.35220742225647,\n    \"pid\": 110504,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 136,\n      \"lr\": 5.813220172981006e-06,\n      \"weight_decay\": 5.958411405790899e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 27.35220742225647,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"61___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=136,lr=5.8132e-06,weight_decay=5.9584e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655045794.142065,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 27.35220742225647,\n      \"min\": 27.35220742225647,\n      \"avg\": 27.35220742225647,\n      \"last\": 27.35220742225647,\n      \"last-5-avg\": 27.35220742225647,\n      \"last-10-avg\": 27.35220742225647\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 27.35220742225647,\n      \"min\": 27.35220742225647,\n      \"avg\": 27.35220742225647,\n      \"last\": 27.35220742225647,\n      \"last-5-avg\": 27.35220742225647,\n      \"last-10-avg\": 27.35220742225647\n    },\n    \"time_since_restore\": {\n      \"max\": 27.35220742225647,\n      \"min\": 27.35220742225647,\n      \"avg\": 27.35220742225647,\n      \"last\": 27.35220742225647,\n      \"last-5-avg\": 27.35220742225647,\n      \"last-10-avg\": 27.35220742225647\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403b5a2a44000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403b5a2a44000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403b5a2a44000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403b5a2a44000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403b5a2a44000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403b5a2a44000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655045759.120289,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_a759cfe2_61___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=136,lr=5.8132e-06,weight_deca_2022-06-12_22-55-09\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_a759cfe2_61___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=136,lr=5.8132e-06,weight_deca_2022-06-12_22-55-09/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=110504, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=110504, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 387, in forward\\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 327, in forward\\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 15.78 GiB total capacity; 2.07 GiB already allocated; 6.50 MiB free; 2.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"c51b3368\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 90,\n    \"lr\": 3.1201528591276634e-05,\n    \"weight_decay\": 5.173700182854227e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 90,\n    \"lr\": 3.1201528591276634e-05,\n    \"weight_decay\": 5.173700182854227e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"62___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=90,lr=3.1202e-05,weight_decay=5.1737e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834383131353732387102580300000063707571034b014e747104512e80025d7100580e00000039343732393834383131353732387101612e01000000000000000000203f94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 29.097458600997925,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"c51b3368\",\n    \"experiment_id\": \"a2f9ee90cbd54649a015dabaa8789715\",\n    \"date\": \"2022-06-12_22-57-19\",\n    \"timestamp\": 1655045839,\n    \"time_total_s\": 29.097458600997925,\n    \"pid\": 111900,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 90,\n      \"lr\": 3.1201528591276634e-05,\n      \"weight_decay\": 5.173700182854227e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 29.097458600997925,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"62___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=90,lr=3.1202e-05,weight_decay=5.1737e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655045839.5546317,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 29.097458600997925,\n      \"min\": 29.097458600997925,\n      \"avg\": 29.097458600997925,\n      \"last\": 29.097458600997925,\n      \"last-5-avg\": 29.097458600997925,\n      \"last-10-avg\": 29.097458600997925\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 29.097458600997925,\n      \"min\": 29.097458600997925,\n      \"avg\": 29.097458600997925,\n      \"last\": 29.097458600997925,\n      \"last-5-avg\": 29.097458600997925,\n      \"last-10-avg\": 29.097458600997925\n    },\n    \"time_since_restore\": {\n      \"max\": 29.097458600997925,\n      \"min\": 29.097458600997925,\n      \"avg\": 29.097458600997925,\n      \"last\": 29.097458600997925,\n      \"last-5-avg\": 29.097458600997925,\n      \"last-10-avg\": 29.097458600997925\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403d18f30c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403d18f30c000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403d18f30c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403d18f30c000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403d18f30c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403d18f30c000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655045801.6993134,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_c51b3368_62___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=90,lr=3.1202e-05,weight_decay_2022-06-12_22-55-59\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_c51b3368_62___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=90,lr=3.1202e-05,weight_decay_2022-06-12_22-55-59/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=111900, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=111900, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 393, in forward\\n    attention_output[0],\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/modeling_utils.py\\\", line 2928, in apply_chunking_to_forward\\n    return forward_fn(*input_tensors)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 401, in ff_chunk\\n    ffn_output = self.activation(ffn_output)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/activations.py\\\", line 34, in forward\\n    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 15.78 GiB total capacity; 2.03 GiB already allocated; 22.50 MiB free; 2.09 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"de7f80ca\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 143,\n    \"lr\": 5.138196747459491e-06,\n    \"weight_decay\": 5.9479370673175874e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 143,\n    \"lr\": 5.138196747459491e-06,\n    \"weight_decay\": 5.9479370673175874e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"63___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=143,lr=5.1382e-06,weight_decay=5.9479e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834393139353930347102580300000063707571034b014e747104512e80025d7100580e00000039343732393834393139353930347101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 31.73620295524597,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"de7f80ca\",\n    \"experiment_id\": \"a1b1a6262b5441c194180fd5b12c9893\",\n    \"date\": \"2022-06-12_22-58-10\",\n    \"timestamp\": 1655045890,\n    \"time_total_s\": 31.73620295524597,\n    \"pid\": 113243,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 143,\n      \"lr\": 5.138196747459491e-06,\n      \"weight_decay\": 5.9479370673175874e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 31.73620295524597,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"63___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=143,lr=5.1382e-06,weight_decay=5.9479e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655045890.059576,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 31.73620295524597,\n      \"min\": 31.73620295524597,\n      \"avg\": 31.73620295524597,\n      \"last\": 31.73620295524597,\n      \"last-5-avg\": 31.73620295524597,\n      \"last-10-avg\": 31.73620295524597\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 31.73620295524597,\n      \"min\": 31.73620295524597,\n      \"avg\": 31.73620295524597,\n      \"last\": 31.73620295524597,\n      \"last-5-avg\": 31.73620295524597,\n      \"last-10-avg\": 31.73620295524597\n    },\n    \"time_since_restore\": {\n      \"max\": 31.73620295524597,\n      \"min\": 31.73620295524597,\n      \"avg\": 31.73620295524597,\n      \"last\": 31.73620295524597,\n      \"last-5-avg\": 31.73620295524597,\n      \"last-10-avg\": 31.73620295524597\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403fbc77cc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403fbc77cc000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403fbc77cc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403fbc77cc000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403fbc77cc000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403fbc77cc000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655045851.2968962,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_de7f80ca_63___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=143,lr=5.1382e-06,weight_deca_2022-06-12_22-56-41\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_de7f80ca_63___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=143,lr=5.1382e-06,weight_deca_2022-06-12_22-56-41/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=113243, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=113243, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 387, in forward\\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 327, in forward\\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 15.78 GiB total capacity; 2.05 GiB already allocated; 12.50 MiB free; 2.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"fc0be336\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 34,\n    \"lr\": 9.953634319403092e-06,\n    \"weight_decay\": 5.394442892276063e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 34,\n    \"lr\": 9.953634319403092e-06,\n    \"weight_decay\": 5.394442892276063e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"64___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=34,lr=9.9536e-06,weight_decay=5.3944e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834393335363934347102580300000063707571034b014e747104512e80025d7100580e00000039343732393834393335363934347101612e01000000000000000000203f94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 32.60718059539795,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"fc0be336\",\n    \"experiment_id\": \"b9bdb973a1d14b4e8d1f5b9fc7eb5d64\",\n    \"date\": \"2022-06-12_22-58-57\",\n    \"timestamp\": 1655045937,\n    \"time_total_s\": 32.60718059539795,\n    \"pid\": 114684,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 34,\n      \"lr\": 9.953634319403092e-06,\n      \"weight_decay\": 5.394442892276063e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 32.60718059539795,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"64___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=34,lr=9.9536e-06,weight_decay=5.3944e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655045937.9003232,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 32.60718059539795,\n      \"min\": 32.60718059539795,\n      \"avg\": 32.60718059539795,\n      \"last\": 32.60718059539795,\n      \"last-5-avg\": 32.60718059539795,\n      \"last-10-avg\": 32.60718059539795\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 32.60718059539795,\n      \"min\": 32.60718059539795,\n      \"avg\": 32.60718059539795,\n      \"last\": 32.60718059539795,\n      \"last-5-avg\": 32.60718059539795,\n      \"last-10-avg\": 32.60718059539795\n    },\n    \"time_since_restore\": {\n      \"max\": 32.60718059539795,\n      \"min\": 32.60718059539795,\n      \"avg\": 32.60718059539795,\n      \"last\": 32.60718059539795,\n      \"last-5-avg\": 32.60718059539795,\n      \"last-10-avg\": 32.60718059539795\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740404db818000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740404db818000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740404db818000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740404db818000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740404db818000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740404db818000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655045897.28056,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_fc0be336_64___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=34,lr=9.9536e-06,weight_decay_2022-06-12_22-57-31\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_fc0be336_64___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=34,lr=9.9536e-06,weight_decay_2022-06-12_22-57-31/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=114684, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=114684, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 387, in forward\\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 327, in forward\\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 15.78 GiB total capacity; 2.03 GiB already allocated; 50.50 MiB free; 2.06 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"17744d02\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 139,\n    \"lr\": 4.6829815235081155e-06,\n    \"weight_decay\": 4.4001440292932824e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 139,\n    \"lr\": 4.6829815235081155e-06,\n    \"weight_decay\": 4.4001440292932824e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"65___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=139,lr=4.683e-06,weight_decay=4.4001e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834383931323235367102580300000063707571034b014e747104512e80025d7100580e00000039343732393834383931323235367101612e01000000000000000000203f94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 21.302192449569702,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"17744d02\",\n    \"experiment_id\": \"d2e1b9b2d1c046449bedecb5506ce9e4\",\n    \"date\": \"2022-06-12_22-59-36\",\n    \"timestamp\": 1655045976,\n    \"time_total_s\": 21.302192449569702,\n    \"pid\": 116114,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 139,\n      \"lr\": 4.6829815235081155e-06,\n      \"weight_decay\": 4.4001440292932824e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 21.302192449569702,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"65___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=139,lr=4.683e-06,weight_decay=4.4001e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655045976.645121,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 21.302192449569702,\n      \"min\": 21.302192449569702,\n      \"avg\": 21.302192449569702,\n      \"last\": 21.302192449569702,\n      \"last-5-avg\": 21.302192449569702,\n      \"last-10-avg\": 21.302192449569702\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 21.302192449569702,\n      \"min\": 21.302192449569702,\n      \"avg\": 21.302192449569702,\n      \"last\": 21.302192449569702,\n      \"last-5-avg\": 21.302192449569702,\n      \"last-10-avg\": 21.302192449569702\n    },\n    \"time_since_restore\": {\n      \"max\": 21.302192449569702,\n      \"min\": 21.302192449569702,\n      \"avg\": 21.302192449569702,\n      \"last\": 21.302192449569702,\n      \"last-5-avg\": 21.302192449569702,\n      \"last-10-avg\": 21.302192449569702\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740354d5c7c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740354d5c7c000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740354d5c7c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740354d5c7c000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740354d5c7c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740354d5c7c000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655045946.774671,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_17744d02_65___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=139,lr=4.683e-06,weight_decay_2022-06-12_22-58-17\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_17744d02_65___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=139,lr=4.683e-06,weight_decay_2022-06-12_22-58-17/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=116114, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=116114, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 387, in forward\\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 327, in forward\\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 15.78 GiB total capacity; 2.05 GiB already allocated; 12.50 MiB free; 2.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"34f57982\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 34,\n    \"lr\": 5.74707138794805e-06,\n    \"weight_decay\": 5.5767341207232705e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 34,\n    \"lr\": 5.74707138794805e-06,\n    \"weight_decay\": 5.5767341207232705e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"66___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=34,lr=5.7471e-06,weight_decay=5.5767e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834393238373339327102580300000063707571034b014e747104512e80025d7100580e00000039343732393834393238373339327101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 32.77506732940674,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"34f57982\",\n    \"experiment_id\": \"f4a03fa3ae7445a2b337c2100f7539fe\",\n    \"date\": \"2022-06-12_23-00-25\",\n    \"timestamp\": 1655046025,\n    \"time_total_s\": 32.77506732940674,\n    \"pid\": 117557,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 34,\n      \"lr\": 5.74707138794805e-06,\n      \"weight_decay\": 5.5767341207232705e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 32.77506732940674,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"66___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=34,lr=5.7471e-06,weight_decay=5.5767e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655046025.6862419,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 32.77506732940674,\n      \"min\": 32.77506732940674,\n      \"avg\": 32.77506732940674,\n      \"last\": 32.77506732940674,\n      \"last-5-avg\": 32.77506732940674,\n      \"last-10-avg\": 32.77506732940674\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 32.77506732940674,\n      \"min\": 32.77506732940674,\n      \"avg\": 32.77506732940674,\n      \"last\": 32.77506732940674,\n      \"last-5-avg\": 32.77506732940674,\n      \"last-10-avg\": 32.77506732940674\n    },\n    \"time_since_restore\": {\n      \"max\": 32.77506732940674,\n      \"min\": 32.77506732940674,\n      \"avg\": 32.77506732940674,\n      \"last\": 32.77506732940674,\n      \"last-5-avg\": 32.77506732940674,\n      \"last-10-avg\": 32.77506732940674\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474040633568000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474040633568000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474040633568000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474040633568000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474040633568000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474040633568000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655045984.4013667,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_34f57982_66___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=34,lr=5.7471e-06,weight_decay_2022-06-12_22-59-06\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_34f57982_66___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=34,lr=5.7471e-06,weight_decay_2022-06-12_22-59-06/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=117557, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=117557, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 387, in forward\\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 327, in forward\\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 15.78 GiB total capacity; 2.03 GiB already allocated; 50.50 MiB free; 2.06 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"4b60fd7c\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 135,\n    \"lr\": 2.8796138845446818e-05,\n    \"weight_decay\": 6.061444721836039e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 135,\n    \"lr\": 2.8796138845446818e-05,\n    \"weight_decay\": 6.061444721836039e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"67___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=135,lr=2.8796e-05,weight_decay=6.0614e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834393330393932307102580300000063707571034b014e747104512e80025d7100580e00000039343732393834393330393932307101612e01000000000000000000403e94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 26.022971630096436,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"4b60fd7c\",\n    \"experiment_id\": \"1aa148a544c54ff6bcc4223cc99447cf\",\n    \"date\": \"2022-06-12_23-01-08\",\n    \"timestamp\": 1655046068,\n    \"time_total_s\": 26.022971630096436,\n    \"pid\": 118746,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 135,\n      \"lr\": 2.8796138845446818e-05,\n      \"weight_decay\": 6.061444721836039e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 26.022971630096436,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"67___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=135,lr=2.8796e-05,weight_decay=6.0614e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655046068.93979,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 26.022971630096436,\n      \"min\": 26.022971630096436,\n      \"avg\": 26.022971630096436,\n      \"last\": 26.022971630096436,\n      \"last-5-avg\": 26.022971630096436,\n      \"last-10-avg\": 26.022971630096436\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 26.022971630096436,\n      \"min\": 26.022971630096436,\n      \"avg\": 26.022971630096436,\n      \"last\": 26.022971630096436,\n      \"last-5-avg\": 26.022971630096436,\n      \"last-10-avg\": 26.022971630096436\n    },\n    \"time_since_restore\": {\n      \"max\": 26.022971630096436,\n      \"min\": 26.022971630096436,\n      \"avg\": 26.022971630096436,\n      \"last\": 26.022971630096436,\n      \"last-5-avg\": 26.022971630096436,\n      \"last-10-avg\": 26.022971630096436\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403a05e178000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403a05e178000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403a05e178000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403a05e178000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403a05e178000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403a05e178000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655046034.226135,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_4b60fd7c_67___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=135,lr=2.8796e-05,weight_deca_2022-06-12_22-59-44\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_4b60fd7c_67___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=135,lr=2.8796e-05,weight_deca_2022-06-12_22-59-44/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=118746, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=118746, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 387, in forward\\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 327, in forward\\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 15.78 GiB total capacity; 2.06 GiB already allocated; 6.50 MiB free; 2.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"6915fb4c\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 33,\n    \"lr\": 5.523760575153226e-06,\n    \"weight_decay\": 5.1267216247824845e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 33,\n    \"lr\": 5.523760575153226e-06,\n    \"weight_decay\": 5.1267216247824845e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"68___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=33,lr=5.5238e-06,weight_decay=5.1267e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834393330393932307102580300000063707571034b014e747104512e80025d7100580e00000039343732393834393330393932307101612e01000000000000000000203f94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 34.51114797592163,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"6915fb4c\",\n    \"experiment_id\": \"3a3280bc5ccc4c3eb89b4908f49087cf\",\n    \"date\": \"2022-06-12_23-01-59\",\n    \"timestamp\": 1655046119,\n    \"time_total_s\": 34.51114797592163,\n    \"pid\": 120236,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 33,\n      \"lr\": 5.523760575153226e-06,\n      \"weight_decay\": 5.1267216247824845e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 34.51114797592163,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"68___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=33,lr=5.5238e-06,weight_decay=5.1267e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655046119.9787538,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 34.51114797592163,\n      \"min\": 34.51114797592163,\n      \"avg\": 34.51114797592163,\n      \"last\": 34.51114797592163,\n      \"last-5-avg\": 34.51114797592163,\n      \"last-10-avg\": 34.51114797592163\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 34.51114797592163,\n      \"min\": 34.51114797592163,\n      \"avg\": 34.51114797592163,\n      \"last\": 34.51114797592163,\n      \"last-5-avg\": 34.51114797592163,\n      \"last-10-avg\": 34.51114797592163\n    },\n    \"time_since_restore\": {\n      \"max\": 34.51114797592163,\n      \"min\": 34.51114797592163,\n      \"avg\": 34.51114797592163,\n      \"last\": 34.51114797592163,\n      \"last-5-avg\": 34.51114797592163,\n      \"last-10-avg\": 34.51114797592163\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474041416d4c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474041416d4c000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474041416d4c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474041416d4c000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474041416d4c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474041416d4c000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655046078.6246977,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_6915fb4c_68___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=33,lr=5.5238e-06,weight_decay_2022-06-12_23-00-34\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_6915fb4c_68___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=33,lr=5.5238e-06,weight_decay_2022-06-12_23-00-34/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=120236, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=120236, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 387, in forward\\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 327, in forward\\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 15.78 GiB total capacity; 2.04 GiB already allocated; 20.50 MiB free; 2.09 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"838d3a3a\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 47,\n    \"lr\": 1.0146978248915939e-05,\n    \"weight_decay\": 5.6919688522755034e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 47,\n    \"lr\": 1.0146978248915939e-05,\n    \"weight_decay\": 5.6919688522755034e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"69___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=47,lr=1.0147e-05,weight_decay=5.692e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834313833393734347102580300000063707571034b014e747104512e80025d7100580e00000039343732393834313833393734347101612e01000000000000000000203f94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 35.529460430145264,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"838d3a3a\",\n    \"experiment_id\": \"3899a7d7069c4a7eb25e4f109c5a6324\",\n    \"date\": \"2022-06-12_23-02-53\",\n    \"timestamp\": 1655046173,\n    \"time_total_s\": 35.529460430145264,\n    \"pid\": 121608,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 47,\n      \"lr\": 1.0146978248915939e-05,\n      \"weight_decay\": 5.6919688522755034e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 35.529460430145264,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"69___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=47,lr=1.0147e-05,weight_decay=5.692e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655046173.1237602,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 35.529460430145264,\n      \"min\": 35.529460430145264,\n      \"avg\": 35.529460430145264,\n      \"last\": 35.529460430145264,\n      \"last-5-avg\": 35.529460430145264,\n      \"last-10-avg\": 35.529460430145264\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 35.529460430145264,\n      \"min\": 35.529460430145264,\n      \"avg\": 35.529460430145264,\n      \"last\": 35.529460430145264,\n      \"last-5-avg\": 35.529460430145264,\n      \"last-10-avg\": 35.529460430145264\n    },\n    \"time_since_restore\": {\n      \"max\": 35.529460430145264,\n      \"min\": 35.529460430145264,\n      \"avg\": 35.529460430145264,\n      \"last\": 35.529460430145264,\n      \"last-5-avg\": 35.529460430145264,\n      \"last-10-avg\": 35.529460430145264\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474041c3c55c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474041c3c55c000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474041c3c55c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474041c3c55c000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474041c3c55c000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474041c3c55c000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655046128.756763,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_838d3a3a_69___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=47,lr=1.0147e-05,weight_decay_2022-06-12_23-01-18\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_838d3a3a_69___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=47,lr=1.0147e-05,weight_decay_2022-06-12_23-01-18/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=121608, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=121608, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 387, in forward\\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 362, in forward\\n    context_layer = context_layer.transpose(2, 1).flatten(2)\\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 15.78 GiB total capacity; 2.07 GiB already allocated; 6.50 MiB free; 2.10 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"a16e2d16\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 34,\n    \"lr\": 5.2520046431619915e-06,\n    \"weight_decay\": 5.329561980919222e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 34,\n    \"lr\": 5.2520046431619915e-06,\n    \"weight_decay\": 5.329561980919222e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"70___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=34,lr=5.252e-06,weight_decay=5.3296e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834343434353533367102580300000063707571034b014e747104512e80025d7100580e00000039343732393834343434353533367101612e01000000000000000000203f94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 27.976380348205566,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"a16e2d16\",\n    \"experiment_id\": \"bb733bcafdd7445c80d7f826c7055feb\",\n    \"date\": \"2022-06-12_23-03-38\",\n    \"timestamp\": 1655046218,\n    \"time_total_s\": 27.976380348205566,\n    \"pid\": 123045,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 34,\n      \"lr\": 5.2520046431619915e-06,\n      \"weight_decay\": 5.329561980919222e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 27.976380348205566,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"70___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=34,lr=5.252e-06,weight_decay=5.3296e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655046218.5543904,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 27.976380348205566,\n      \"min\": 27.976380348205566,\n      \"avg\": 27.976380348205566,\n      \"last\": 27.976380348205566,\n      \"last-5-avg\": 27.976380348205566,\n      \"last-10-avg\": 27.976380348205566\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 27.976380348205566,\n      \"min\": 27.976380348205566,\n      \"avg\": 27.976380348205566,\n      \"last\": 27.976380348205566,\n      \"last-5-avg\": 27.976380348205566,\n      \"last-10-avg\": 27.976380348205566\n    },\n    \"time_since_restore\": {\n      \"max\": 27.976380348205566,\n      \"min\": 27.976380348205566,\n      \"avg\": 27.976380348205566,\n      \"last\": 27.976380348205566,\n      \"last-5-avg\": 27.976380348205566,\n      \"last-10-avg\": 27.976380348205566\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403bf9f410000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403bf9f410000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403bf9f410000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403bf9f410000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447403bf9f410000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447403bf9f410000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655046182.2076783,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_a16e2d16_70___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=34,lr=5.252e-06,weight_decay=_2022-06-12_23-02-08\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_a16e2d16_70___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=34,lr=5.252e-06,weight_decay=_2022-06-12_23-02-08/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=123045, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=123045, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 387, in forward\\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 327, in forward\\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 15.78 GiB total capacity; 2.03 GiB already allocated; 50.50 MiB free; 2.06 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"c1486e26\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 45,\n    \"lr\": 1.0253126160073621e-05,\n    \"weight_decay\": 4.2256765276889774e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 45,\n    \"lr\": 1.0253126160073621e-05,\n    \"weight_decay\": 4.2256765276889774e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"71___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=45,lr=1.0253e-05,weight_decay=4.2257e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"validation_mean\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005957d010000000000008c0c746f7263682e5f7574696c73948c125f72656275696c645f74656e736f725f7632949394288c0d746f7263682e73746f72616765948c105f6c6f61645f66726f6d5f627974657394939443ff80028a0a6cfc9c46f9206aa850192e80024de9032e80027d710028581000000070726f746f636f6c5f76657273696f6e71014de903580d0000006c6974746c655f656e6469616e710288580a000000747970655f73697a657371037d710428580500000073686f727471054b025803000000696e7471064b0458040000006c6f6e6771074b0475752e800228580700000073746f72616765710063746f7263680a466c6f617453746f726167650a7101580e00000039343732393834393830353837327102580300000063707571034b014e747104512e80025d7100580e00000039343732393834393830353837327101612e01000000000000000000203f94859452944b002929898c0b636f6c6c656374696f6e73948c0b4f72646572656444696374949394295294749452942e\"\n    },\n    \"time_this_iter_s\": 32.20201563835144,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"trial_id\": \"c1486e26\",\n    \"experiment_id\": \"83818d6545bf49498d16cbae4293e997\",\n    \"date\": \"2022-06-12_23-04-21\",\n    \"timestamp\": 1655046261,\n    \"time_total_s\": 32.20201563835144,\n    \"pid\": 124549,\n    \"hostname\": \"localhost.localdomain\",\n    \"node_ip\": \"192.168.249.74\",\n    \"config\": {\n      \"batch_size\": 8,\n      \"beta1\": 0.9,\n      \"beta2\": 0.999,\n      \"classfication_dim_stride\": 45,\n      \"lr\": 1.0253126160073621e-05,\n      \"weight_decay\": 4.2256765276889774e-05,\n      \"__trial_index__\": 0\n    },\n    \"time_since_restore\": 32.20201563835144,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"71___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=45,lr=1.0253e-05,weight_decay=4.2257e-05\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1655046261.6777642,\n  \"metric_analysis\": {\n    \"time_this_iter_s\": {\n      \"max\": 32.20201563835144,\n      \"min\": 32.20201563835144,\n      \"avg\": 32.20201563835144,\n      \"last\": 32.20201563835144,\n      \"last-5-avg\": 32.20201563835144,\n      \"last-10-avg\": 32.20201563835144\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 32.20201563835144,\n      \"min\": 32.20201563835144,\n      \"avg\": 32.20201563835144,\n      \"last\": 32.20201563835144,\n      \"last-5-avg\": 32.20201563835144,\n      \"last-10-avg\": 32.20201563835144\n    },\n    \"time_since_restore\": {\n      \"max\": 32.20201563835144,\n      \"min\": 32.20201563835144,\n      \"avg\": 32.20201563835144,\n      \"last\": 32.20201563835144,\n      \"last-5-avg\": 32.20201563835144,\n      \"last-10-avg\": 32.20201563835144\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447404019dba6000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447404019dba6000000612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447404019dba6000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447404019dba6000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447404019dba6000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447404019dba6000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1655046224.759537,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_c1486e26_71___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=45,lr=1.0253e-05,weight_decay_2022-06-12_23-03-02\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_c1486e26_71___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=45,lr=1.0253e-05,weight_decay_2022-06-12_23-03-02/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trial_runner.py\\\", line 886, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\\\", line 675, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/worker.py\\\", line 1763, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(TuneError): \\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=124549, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/trainable.py\\\", line 319, in train\\n    result = self.step()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 381, in step\\n    self._report_thread_runner_error(block=True)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 532, in _report_thread_runner_error\\n    (\\\"Trial raised an exception. Traceback:\\\\n{}\\\".format(err_tb_str)\\nray.tune.error.TuneError: Trial raised an exception. Traceback:\\n\\u001b[36mray::ImplicitFunc.train()\\u001b[39m (pid=124549, ip=192.168.249.74, repr=train_tune)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 262, in run\\n    self._entrypoint()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 331, in entrypoint\\n    self._status_reporter.get_checkpoint())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/function_runner.py\\\", line 600, in _trainable_func\\n    output = fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/ray/tune/utils/trainable.py\\\", line 371, in inner\\n    trainable(config, **fn_kwargs)\\n  File \\\"train.py\\\", line 565, in train_tune\\n    trainer.fit(model)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 741, in fit\\n    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 685, in _call_and_handle_interrupt\\n    return trainer_fn(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 777, in _fit_impl\\n    self._run(model, ckpt_path=ckpt_path)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1199, in _run\\n    self._dispatch()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1279, in _dispatch\\n    self.training_type_plugin.start_training(self)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 202, in start_training\\n    self._results = trainer.run_stage()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1289, in run_stage\\n    return self._run_train()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\\\", line 1319, in _run_train\\n    self.fit_loop.run()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\\\", line 234, in advance\\n    self.epoch_loop.run(data_fetcher)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\\\", line 193, in advance\\n    batch_output = self.batch_loop.run(batch, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\\\", line 88, in advance\\n    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\\\", line 145, in run\\n    self.advance(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 219, in advance\\n    self.optimizer_idx,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 266, in _run_optimization\\n    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 386, in _optimizer_step\\n    using_lbfgs=is_lbfgs,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\\\", line 1652, in optimizer_step\\n    optimizer.step(closure=optimizer_closure)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\\\", line 164, in step\\n    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 339, in optimizer_step\\n    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 163, in optimizer_step\\n    optimizer.step(closure=closure, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/optimizer.py\\\", line 88, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/autograd/grad_mode.py\\\", line 28, in decorate_context\\n    return func(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/optim/adam.py\\\", line 92, in step\\n    loss = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\\\", line 148, in _wrap_closure\\n    closure_result = closure()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 160, in __call__\\n    self._result = self.closure(*args, **kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 142, in closure\\n    step_output = self._step_fn()\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\\\", line 435, in _training_step\\n    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\\\", line 219, in training_step\\n    return self.training_type_plugin.training_step(*step_kwargs.values())\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\\\", line 213, in training_step\\n    return self.model.training_step(*args, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/net.py\\\", line 278, in training_step\\n    x2 = self.bert(inputs_embeds=x2)[1]\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 726, in forward\\n    return_dict=return_dict,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 472, in forward\\n    output_hidden_states,\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 419, in forward\\n    layer_output = albert_layer(hidden_states, attention_mask, head_mask[layer_index], output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 387, in forward\\n    attention_output = self.attention(hidden_states, attention_mask, head_mask, output_attentions)\\n  File \\\"/home/xwm/anaconda3/envs/SV/lib/python3.6/site-packages/torch/nn/modules/module.py\\\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/xwm/DeepSVFilter/code/transformers/models/albert/modeling_albert.py\\\", line 361, in forward\\n    context_layer = torch.matmul(attention_probs, value_layer)\\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 15.78 GiB total capacity; 2.06 GiB already allocated; 4.50 MiB free; 2.11 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"daa64438\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 34,\n    \"lr\": 5.035803863078245e-06,\n    \"weight_decay\": 5.2122052760861286e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 34,\n    \"lr\": 5.035803863078245e-06,\n    \"weight_decay\": 5.2122052760861286e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"72___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=34,lr=5.0358e-06,weight_decay=5.2122e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"trial_id\": \"daa64438\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1655046270.5187063,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_daa64438_72___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=34,lr=5.0358e-06,weight_decay_2022-06-12_23-03-44\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"train_tune\",\n  \"trial_id\": \"f5ebd866\",\n  \"config\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 48,\n    \"lr\": 9.313060384361518e-06,\n    \"weight_decay\": 5.9976302372647086e-05,\n    \"__trial_index__\": 0\n  },\n  \"local_dir\": \"/home/xwm/DeepSVFilter/code/tune_asha\",\n  \"evaluated_params\": {\n    \"batch_size\": 8,\n    \"beta1\": 0.9,\n    \"beta2\": 0.999,\n    \"classfication_dim_stride\": 48,\n    \"lr\": 9.313060384361518e-06,\n    \"weight_decay\": 5.9976302372647086e-05,\n    \"__trial_index__\": 0\n  },\n  \"experiment_tag\": \"73___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=48,lr=9.3131e-06,weight_decay=5.9976e-05\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595b6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740140000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"trial_id\": \"f5ebd866\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"start_time\": null,\n  \"logdir\": \"/home/xwm/DeepSVFilter/code/tune_asha/train_tune_f5ebd866_73___trial_index__=0,batch_size=8,beta1=0.9,beta2=0.999,classfication_dim_stride=48,lr=9.3131e-06,weight_decay_2022-06-12_23-04-30\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"error_msg\": null,\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059583010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d948c056f72646572944b0075628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9468134b0075628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f948c0a5f6375725f6f72646572944b0075622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_insufficient_resources_manager": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059588000000000000008c277261792e74756e652e696e73756666696369656e745f7265736f75726365735f6d616e61676572948c1c496e73756666696369656e745265736f75726365734d616e616765729493942981947d94288c185f6e6f5f72756e6e696e675f747269616c735f73696e6365944affffffff8c0f5f6c6173745f747269616c5f6e756d944b0175622e"
    },
    "_max_pending_trials": 1,
    "_metric": null,
    "_total_time": 129581.37763834,
    "_iteration": 46306,
    "_has_errored": true,
    "_fail_fast": false,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_updated_queue": false,
    "_result_wait_time": 1,
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "/home/xwm/DeepSVFilter/code/tune_asha",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "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"
    },
    "_resumed": false,
    "_start_time": 1655001334.492541,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2022-06-12_10-35-34",
    "checkpoint_file": "/home/xwm/DeepSVFilter/code/tune_asha/experiment_state-2022-06-12_10-35-34.json",
    "_checkpoint_period": "auto",
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1655001334.492541,
    "timestamp": 1655046295.1600652
  }
}